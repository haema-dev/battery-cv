======Starting Run on Compute======
The run ID for the run on compute is imgbldrun_2d3ca86

Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_2d3ca86?wsid=/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourcegroups/8ai-final-team6/workspaces/vision&tid=5fb256f0-fbf2-40d2-81d5-bac1b32c419d


user_logs/std_log.txt : 
----
2026-02-04T02:53:11: Logging into Docker registry: 375c688203014d1cb3273695ae3932f9.azurecr.io
2026-02-04T02:53:11: WARNING! Using --password via the CLI is insecure. Use --password-stdin.
2026-02-04T02:53:11: Login Succeeded

2026-02-04T02:53:11: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.
2026-02-04T02:53:11: Configure a credential helper to remove this warning. See
2026-02-04T02:53:11: https://docs.docker.com/go/credential-store/



2026-02-04T02:53:11: Running: ['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e:1']
2026-02-04T02:53:11: #0 building with "default" instance using docker driver

2026-02-04T02:53:11: #1 [internal] load .dockerignore
2026-02-04T02:53:11: #1 transferring context: 2B done
2026-02-04T02:53:11: #1 DONE 0.1s

2026-02-04T02:53:11: #2 [internal] load build definition from Dockerfile
2026-02-04T02:53:11: #2 transferring dockerfile: 1.01kB done
2026-02-04T02:53:11: #2 DONE 0.2s

2026-02-04T02:53:11: #3 [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
2026-02-04T02:53:12: #3 ...

2026-02-04T02:53:12: #4 [internal] load metadata for ghcr.io/astral-sh/uv:latest
2026-02-04T02:53:12: #4 DONE 0.6s

2026-02-04T02:53:12: #3 [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
2026-02-04T02:53:13: #3 DONE 1.3s

2026-02-04T02:53:13: #5 [stage-0  1/10] FROM docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04@sha256:f3a7fb39fa3ffbe54da713dd2e93063885e5be2f4586a705c39031b8284d379a
2026-02-04T02:53:13: #5 DONE 0.0s

2026-02-04T02:53:13: #6 FROM ghcr.io/astral-sh/uv:latest@sha256:db9370c2b0b837c74f454bea914343da9f29232035aa7632a1b14dc03add9edb
2026-02-04T02:53:13: #6 DONE 0.0s

2026-02-04T02:53:13: #7 [internal] load build context
2026-02-04T02:53:13: #7 transferring context: 1.74kB done
2026-02-04T02:53:13: #7 DONE 0.1s

2026-02-04T02:53:13: #8 [stage-0  4/10] COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/
2026-02-04T02:53:13: #8 CACHED

2026-02-04T02:53:13: #9 [stage-0  2/10] RUN apt-get update && apt-get install -y     python3.10     python3.10-dev     python3.10-venv     python3-pip     && rm -rf /var/lib/apt/lists/*
2026-02-04T02:53:13: #9 CACHED

2026-02-04T02:53:13: #10 [stage-0  3/10] RUN python3.10 -m pip install --upgrade pip
2026-02-04T02:53:13: #10 CACHED

2026-02-04T02:53:13: #11 [stage-0  5/10] WORKDIR /app
2026-02-04T02:53:13: #11 CACHED

2026-02-04T02:53:13: #12 [stage-0  6/10] COPY pyproject.toml uv.lock* ./
2026-02-04T02:53:13: #12 DONE 0.3s

2026-02-04T02:53:13: #13 [stage-0  7/10] RUN python3.10 -m pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0     --index-url https://download.pytorch.org/whl/cu121
2026-02-04T02:53:14: #13 0.797 Looking in indexes: https://download.pytorch.org/whl/cu121
2026-02-04T02:53:15: #13 1.832 ERROR: Could not find a version that satisfies the requirement torch==2.6.0 (from versions: 2.1.0+cu121, 2.1.1+cu121, 2.1.2+cu121, 2.2.0+cu121, 2.2.1+cu121, 2.2.2+cu121, 2.3.0+cu121, 2.3.1+cu121, 2.4.0+cu121, 2.4.1+cu121, 2.5.0+cu121, 2.5.1+cu121)
2026-02-04T02:53:16: #13 2.717 ERROR: No matching distribution found for torch==2.6.0
2026-02-04T02:53:16: #13 ERROR: process "/bin/sh -c python3.10 -m pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0     --index-url https://download.pytorch.org/whl/cu121" did not complete successfully: exit code: 1
2026-02-04T02:53:16: ------
2026-02-04T02:53:16:  > [stage-0  7/10] RUN python3.10 -m pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0     --index-url https://download.pytorch.org/whl/cu121:
2026-02-04T02:53:16: 0.797 Looking in indexes: https://download.pytorch.org/whl/cu121
2026-02-04T02:53:16: 1.832 ERROR: Could not find a version that satisfies the requirement torch==2.6.0 (from versions: 2.1.0+cu121, 2.1.1+cu121, 2.1.2+cu121, 2.2.0+cu121, 2.2.1+cu121, 2.2.2+cu121, 2.3.0+cu121, 2.3.1+cu121, 2.4.0+cu121, 2.4.1+cu121, 2.5.0+cu121, 2.5.1+cu121)
2026-02-04T02:53:16: 2.717 ERROR: No matching distribution found for torch==2.6.0
2026-02-04T02:53:16: ------
2026-02-04T02:53:16: Dockerfile:23
2026-02-04T02:53:16: --------------------
2026-02-04T02:53:16:   22 |     # PyTorch GPU 버전 설치 (CUDA 12.1)
2026-02-04T02:53:16:   23 | >>> RUN python3.10 -m pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \
2026-02-04T02:53:16:   24 | >>>     --index-url https://download.pytorch.org/whl/cu121
2026-02-04T02:53:16:   25 |     
2026-02-04T02:53:16: --------------------
2026-02-04T02:53:16: ERROR: failed to solve: process "/bin/sh -c python3.10 -m pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0     --index-url https://download.pytorch.org/whl/cu121" did not complete successfully: exit code: 1


2026-02-04T02:53:16: CalledProcessError(1, ['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e:1'])

2026-02-04T02:53:16: Building docker image failed with exit code: 1

2026-02-04T02:53:16: Logging out of Docker registry: 375c688203014d1cb3273695ae3932f9.azurecr.io
2026-02-04T02:53:16: Removing login credentials for https://index.docker.io/v1/


2026-02-04T02:53:16: Traceback (most recent call last):
  File "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py", line 152, in _docker_build_or_error
    docker_execute_function(docker_command, build_command, print_command_args=True)
  File "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py", line 23, in docker_execute_function
    return killable_subprocess.check_call(command_args, *popen_args,
  File "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/killable_subprocess.py", line 261, in check_call
    raise subprocess.CalledProcessError(process.returncode, cmd)
subprocess.CalledProcessError: Command '['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_15d61d4a588cdf3df823a6aa752d998e:1']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "script.py", line 162, in <module>
    docker_utilities._docker_build_or_error(
  File "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py", line 156, in _docker_build_or_error
    _write_error_and_exit(error_msg, error_file_path=error_file_path)
  File "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py", line 217, in _write_error_and_exit
    sys.exit(1)
SystemExit: 1


system_logs/cs_capability/cs-capability.log : 
----
INFO 2026-02-04 02:53:10,326 initializer.py:55 [1] - job_telemetry_init {'artifact_type': 'installed', 'branch': '2385e2bab64', 'build_time': '2026-01-23 10:33:52.893301', 'ci_name': 'CommonRuntime-RuntimeTeam-Linux-Prod-Build', 'ci_number': '20260123.1', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,327 tracer.py:31 [1] - Setting up tracer {'branch': '2385e2bab64', 'commit': '2385e2b', 'component_name': 'cs-capability', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'telemetry_config': '{"collector": {"receiver": null, "exporter": {"appinsights": {"instrumentation_key": "4b76bc22-b2b3-4c36-9f73-ea1500bfc9fb", "endpoint_suffix": "services.visualstudio.com", "ingestion_endpoint": null, "aad_audience": null}, "jaeger": null, "prometheus": null, "timeout_millis": null, "level": null}}, "logger": {"console": {"sink": "stdout", "level": "info", "enabled": true, "ansi": false}, "appinsights": {"instrumentation_key": "4b76bc22-b2b3-4c36-9f73-ea1500bfc9fb", "level": "info", "enabled": true, "endpoint_suffix": "services.visualstudio.com", "ingestion_endpoint": null, "aad_audience": null}, "file": {"extension": "log", "level": "info", "enabled": true}}, "node_rank": null, "node_id": "tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d", "disable_sensitive_scrub": null, "attempt_id": null}', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,342 tracer.py:57 [1] - Setting up appinsights exporter {'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,344 initializer.py:65 [1] - Tracer initialized {'artifact_type': 'installed', 'branch': '2385e2bab64', 'build_time': '2026-01-23 10:33:52.893301', 'ci_name': 'CommonRuntime-RuntimeTeam-Linux-Prod-Build', 'ci_number': '20260123.1', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,344 tracer.py:127 [1] - [tracer][get_ambient_parent_ctx] parent ctx: {'current-span-201e261d-5ae6-4fec-93b7-d713e01ca45a': NonRecordingSpan(SpanContext(trace_id=0x0ea524981c619ab6627ece9508c4e574, span_id=0x5eeb225f51ff66a2, trace_flags=0x01, trace_state=[], is_remote=True))} {'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,349 service.py:317 [1] - [start_services]: starting service {'SpanId': 'f6d91db02cd26602', 'TraceFlags': '01', 'TraceId': '0ea524981c619ab6627ece9508c4e574', 'address': 'unix:///mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'max_workers': 2, 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': 'f6d91db02cd26602', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '0ea524981c619ab6627ece9508c4e574', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,358 service.py:349 [1] - [start_services]: waiting on end_event {'SpanId': 'f6d91db02cd26602', 'TraceFlags': '01', 'TraceId': '0ea524981c619ab6627ece9508c4e574', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'max_attempts': 3, 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'retry_delay_secs': 5, 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'server_start_attempt': 0, 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': 'f6d91db02cd26602', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '0ea524981c619ab6627ece9508c4e574', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,436 service.py:56 [1] - [start] Extracting Snapshots: None {'SpanId': '6c68184651d2149a', 'TraceFlags': '01', 'TraceId': 'b08d24961fbff043c54d5b692c72e9cb', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '6c68184651d2149a', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'b08d24961fbff043c54d5b692c72e9cb', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,440 service.py:86 [1] - [start] Entering context managers {'SpanId': '6c68184651d2149a', 'TraceFlags': '01', 'TraceId': 'b08d24961fbff043c54d5b692c72e9cb', 'branch': '2385e2bab64', 'commit': '2385e2b', 'context_managers': [], 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '6c68184651d2149a', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'b08d24961fbff043c54d5b692c72e9cb', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:10,441 context_manager.py:71 [1] - enter_contexts {'SpanId': '6c68184651d2149a', 'TraceFlags': '01', 'TraceId': 'b08d24961fbff043c54d5b692c72e9cb', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '6c68184651d2149a', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'success': True, 'traceId': 'b08d24961fbff043c54d5b692c72e9cb', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:17,693 service.py:125 [1] - [end] logging run finalizing {'SpanId': '73454f9399ae915e', 'TraceFlags': '01', 'TraceId': 'cb90bbe999c9098802358c015de62640', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '73454f9399ae915e', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'cb90bbe999c9098802358c015de62640', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:17,792 context_manager.py:93 [1] - exit_contexts {'SpanId': '73454f9399ae915e', 'TraceFlags': '01', 'TraceId': 'cb90bbe999c9098802358c015de62640', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '73454f9399ae915e', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'cb90bbe999c9098802358c015de62640', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:53:17,793 context_manager.py:100 [1] - exit_contexts {'SpanId': '73454f9399ae915e', 'TraceFlags': '01', 'TraceId': 'cb90bbe999c9098802358c015de62640', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_2d3ca86', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_2d3ca86', 'run_id': 'imgbldrun_2d3ca86', 'session_id': 'aceec37f-3103-474d-bfbd-9c856a0a8ace', 'source': 'common_runtime.cs-capability', 'spanId': '73454f9399ae915e', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'success': True, 'traceId': 'cb90bbe999c9098802358c015de62640', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}

system_logs/hosttools_capability/hosttools-capability.log : 
----
2026-02-04T02:53:09.541446Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:31:11.198476
2026-02-04T02:53:09.541861Z  INFO hosttools-capability::do_main: hosttools_capability::resource_limit: Current limit for number of open file: soft=262144, hard=262144 soft_limit=262144 hard_limit=262144
2026-02-04T02:53:09.542278Z  INFO hosttools-capability::do_main: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:53:09.542554Z  INFO hosttools-capability::do_main: hosttools_capability: Hosttools cap config ht_cap_config={"dirs":[{"relative_path":"azureml-logs","environment_name":"AZUREML_CR_HT_CAP_azureml_logs_PATH","streamable":true},{"relative_path":"user_logs","environment_name":"AZUREML_CR_HT_CAP_user_logs_PATH","streamable":true},{"relative_path":"outputs","environment_name":"AZUREML_CR_HT_CAP_outputs_PATH","streamable":false},{"relative_path":"logs","environment_name":"AZUREML_CR_HT_CAP_logs_PATH","streamable":true}],"metrics":{"enabled":false,"polling_interval_sec":30,"send_to_history_interval_sec":60},"use_block_blob_in_blob_streamer":true,"log_filtering_policy":null,"disable_system_log_blob_streaming":false}
2026-02-04T02:53:09.543148Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: cr_core::config_parser: Failed to get distributed config from env exception=GetEnvVarFailed("AZUREML_CR_DISTRIBUTED_CONFIG")
2026-02-04T02:53:09.543688Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: hosttools_capability::config_parser: appinsights instrumentation key is set in telemetry config
2026-02-04T02:53:09.544053Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config:hosttools-capability.add_cert_env_vars_from_file{path="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/cert_info.txt"}: hosttools_capability::config_parser: Cert envs from cert_file was successful
2026-02-04T02:53:09.544305Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config:hosttools-capability.add_cert_env_vars_from_file{path="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/cert_info.txt"}: hosttools_capability::config_parser: close time.busy=279µs time.idle=19.2µs
2026-02-04T02:53:09.544409Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: hosttools_capability::config_parser: close time.busy=1.46ms time.idle=17.8µs
2026-02-04T02:53:09.546183Z  INFO hosttools-capability::do_main:hosttools-capability.start_hosttools{task="outputManager"}: grpc_utils::utils: child spawned child=Child { child: Child(ChildDropGuard { inner: Child { pid: 12 }, kill_on_drop: false }), stdin: None, stdout: Some(ChildStdout { inner: PollEvented { io: Some(Pipe { fd: File { fd: 10, path: "pipe:[49788]", read: true, write: false } }) } }), stderr: Some(ChildStderr { inner: PollEvented { io: Some(Pipe { fd: File { fd: 12, path: "pipe:[49789]", read: true, write: false } }) } }) }
2026-02-04T02:53:09.546589Z  INFO hosttools-capability::do_main:hosttools-capability.start_hosttools{task="outputManager"}: hosttools_capability::hosttools: close time.busy=1.85ms time.idle=7.00µs
2026-02-04T02:53:09.561268Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Error opening env file:  open LS_root/jobs/config/.dynamic_config: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Error opening env file:  open LS_root/jobs/config/.dynamic_config: no such file or directory"
2026-02-04T02:53:09.567129Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Scrubber is not initialize, System Log will be disabled command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Scrubber is not initialize, System Log will be disabled"
2026-02-04T02:53:09.567855Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Starting App Insight Logger for task:  outputManager command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Starting App Insight Logger for task:  outputManager"
2026-02-04T02:53:09.568040Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Version:  Branch:  Commit:  command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Version:  Branch:  Commit: "
2026-02-04T02:53:09.568081Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Is launched from common runtime?: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Is launched from common runtime?: true"
2026-02-04T02:53:09.568108Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Soft rlimit is 262144 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Soft rlimit is 262144"
2026-02-04T02:53:09.568137Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Setting soft rlimit to 1048576 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Setting soft rlimit to 1048576"
2026-02-04T02:53:09.568168Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 rlimit is now {262144 262144} command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 rlimit is now {262144 262144}"
2026-02-04T02:53:09.568196Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{"Id":"azureml-logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs","Streamable":true},{"Id":"user_logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs","Streamable":true},{"Id":"outputs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs","Streamable":false},{"Id":"logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs","Streamable":true},{"Id":"lifecycler","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log","Streamable":true},{"Id":"secrets_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"metrics_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"cs_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"hosttools_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"snapshot_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log","Streamable":true}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{\"Id\":\"azureml-logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs\",\"Streamable\":true},{\"Id\":\"user_logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs\",\"Streamable\":true},{\"Id\":\"outputs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs\",\"Streamable\":false},{\"Id\":\"logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs\",\"Streamable\":true},{\"Id\":\"lifecycler\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"secrets_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"metrics_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"cs_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"hosttools_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"snapshot_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log\",\"Streamable\":true}]"
2026-02-04T02:53:09.568261Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{"Id":"azureml-logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs","Streamable":true},{"Id":"user_logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs","Streamable":true},{"Id":"outputs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs","Streamable":false},{"Id":"logs","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs","Streamable":true},{"Id":"lifecycler","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log","Streamable":true},{"Id":"secrets_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"metrics_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"cs_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"hosttools_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"snapshot_capability","Path":"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log","Streamable":true}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{\"Id\":\"azureml-logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs\",\"Streamable\":true},{\"Id\":\"user_logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs\",\"Streamable\":true},{\"Id\":\"outputs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs\",\"Streamable\":false},{\"Id\":\"logs\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs\",\"Streamable\":true},{\"Id\":\"lifecycler\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"secrets_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"metrics_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"cs_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"hosttools_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"snapshot_capability\",\"Path\":\"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log\",\"Streamable\":true}]"
2026-02-04T02:53:09.568314Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 AZUREML_CR_HT_LOG_FILTERING_POLICY:  command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 AZUREML_CR_HT_LOG_FILTERING_POLICY: "
2026-02-04T02:53:09.568340Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 AZUREML_CR_HT_LOG_FILTERING_POLICY:  command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 AZUREML_CR_HT_LOG_FILTERING_POLICY: "
2026-02-04T02:53:09.568366Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Failed to Parse Bool on commons.IsDedicatedCompute command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Failed to Parse Bool on commons.IsDedicatedCompute"
2026-02-04T02:53:09.568389Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Skip watching job temp full log cache dir as current output manager is launched by common runtime command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Skip watching job temp full log cache dir as current output manager is launched by common runtime"
2026-02-04T02:53:09.575244Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs, streamable: true"
2026-02-04T02:53:09.575416Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs"
2026-02-04T02:53:09.575504Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Skipping disk check due to err: Ephemeral Disk path not set by Batch. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Skipping disk check due to err: Ephemeral Disk path not set by Batch."
2026-02-04T02:53:09.575581Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs, streamable: true"
2026-02-04T02:53:09.575682Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs"
2026-02-04T02:53:09.575770Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory LS_root/jobs/wd/.tmp, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory LS_root/jobs/wd/.tmp, streamable: true"
2026-02-04T02:53:09.575903Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory LS_root/jobs/wd/.tmp command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory LS_root/jobs/wd/.tmp"
2026-02-04T02:53:09.575981Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 file LS_root/jobs/wd/.tmp does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 file LS_root/jobs/wd/.tmp does not exist"
2026-02-04T02:53:09.576049Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs, streamable: true"
2026-02-04T02:53:09.576164Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs"
2026-02-04T02:53:09.576320Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs, streamable: false command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs, streamable: false"
2026-02-04T02:53:09.576471Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs"
2026-02-04T02:53:09.576552Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.576699Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log"
2026-02-04T02:53:09.576880Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:53:09.576982Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.577420Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log"
2026-02-04T02:53:09.577580Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log"
2026-02-04T02:53:09.578902Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log"
2026-02-04T02:53:09.579117Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Requesting POST: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Requesting POST: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}]"
2026-02-04T02:53:09.581464Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:09.581679Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.581881Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log"
2026-02-04T02:53:09.582068Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:53:09.582152Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.582300Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log"
2026-02-04T02:53:09.582502Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log"
2026-02-04T02:53:09.582684Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Requesting POST: [{system_logs/hosttools_capability/hosttools-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Requesting POST: [{system_logs/hosttools_capability/hosttools-capability.log}]"
2026-02-04T02:53:09.582965Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:09.583216Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.584091Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log"
2026-02-04T02:53:09.584491Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log"
2026-02-04T02:53:09.584862Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Requesting POST: [{system_logs/metrics_capability/metrics-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Requesting POST: [{system_logs/metrics_capability/metrics-capability.log}]"
2026-02-04T02:53:09.584981Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:09.588899Z  INFO hosttools-capability::do_main:hosttools-capability.patch_azsecpack_resource_files_on_host: hosttools_capability::patch_azsecpack: close time.busy=42.3ms time.idle=5.50µs
2026-02-04T02:53:09.591935Z  INFO hosttools-capability::do_main: hosttools_capability: Starting gRPC server at server_addr=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0
2026-02-04T02:53:09.592049Z  INFO hosttools-capability::do_main: hosttools_capability::service: serving capability service at address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0
2026-02-04T02:53:09.592364Z  INFO hosttools-capability::do_main:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:09.593192Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 start watching directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:53:09.593491Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log"
2026-02-04T02:53:09.594002Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log"
2026-02-04T02:53:09.594353Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Requesting POST: [{system_logs/secrets_capability/secrets-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Requesting POST: [{system_logs/secrets_capability/secrets-capability.log}]"
2026-02-04T02:53:09.594675Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:09.597041Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory"
2026-02-04T02:53:09.599299Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory"
2026-02-04T02:53:09.602550Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory"
2026-02-04T02:53:09.606853Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Decrypt using CBCDecrypter"
2026-02-04T02:53:09.607011Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Initial token expires at  2026-02-25 04:33:59 +0000 UTC command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Initial token expires at  2026-02-25 04:33:59 +0000 UTC"
2026-02-04T02:53:09.607066Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Decrypt using CBCDecrypter"
2026-02-04T02:53:09.748871Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:09 Succesfully POST artifacts: [{system_logs/secrets_capability/secrets-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:09 Succesfully POST artifacts: [{system_logs/secrets_capability/secrets-capability.log}]"
2026-02-04T02:53:10.372128Z  INFO hosttools_capability::health: Watched child process is alive
2026-02-04T02:53:10.378386Z  INFO hosttools_capability::health: Watched child process is alive
2026-02-04T02:53:10.379144Z  INFO hosttools-capability.start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:53:10.379239Z  INFO hosttools-capability.start: hosttools_capability::capability_service: close time.busy=105µs time.idle=24.7µs
2026-02-04T02:53:10.597108Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Decrypt using CBCDecrypter"
2026-02-04T02:53:10.600150Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Decrypt using CBCDecrypter"
2026-02-04T02:53:10.603295Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Decrypt using CBCDecrypter"
2026-02-04T02:53:10.671499Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/metrics_capability/metrics-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/metrics_capability/metrics-capability.log}]"
2026-02-04T02:53:10.676147Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/hosttools_capability/hosttools-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/hosttools_capability/hosttools-capability.log}]"
2026-02-04T02:53:10.677462Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:10 Succesfully POST artifacts: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}]"
2026-02-04T02:53:14.561971Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:14 Not exporting to RunHistory as the exporter is either stopped or there is no data.Stopped: false; OriginalData: 12; FilteredData: 0. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:14 Not exporting to RunHistory as the exporter is either stopped or there is no data.Stopped: false; OriginalData: 12; FilteredData: 0."
2026-02-04T02:53:17.690693Z  INFO hosttools-capability.end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:53:17.691120Z  INFO hosttools-capability.end: hosttools_capability::capability_service: Flush and shutdown output manager (end)
2026-02-04T02:53:17.691301Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: Signaling output_manager to flush logs, then terminating after: None flush_timeout=None
2026-02-04T02:53:17.691708Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: send SIGTERM to outputManager child=Child { child: Child(ChildDropGuard { inner: Child { pid: 12 }, kill_on_drop: false }), stdin: None, stdout: None, stderr: None }
2026-02-04T02:53:17.691939Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: waiting for outputManager termination child=Child { child: Child(ChildDropGuard { inner: Child { pid: 12 }, kill_on_drop: false }), stdin: None, stdout: None, stderr: None } timeout_duration=None
2026-02-04T02:53:17.692950Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Received termination signal to shut down output manager. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Received termination signal to shut down output manager."
2026-02-04T02:53:17.693021Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log. No changes after termination signal."
2026-02-04T02:53:17.693058Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Streamer terminated for system_logs/lifecycler/execution-wrapper.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Streamer terminated for system_logs/lifecycler/execution-wrapper.log"
2026-02-04T02:53:17.693094Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.693138Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/logs one more time with 3 s!"
2026-02-04T02:53:17.693370Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log/snapshot-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log/snapshot-capability.log"
2026-02-04T02:53:17.693507Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log. No changes after termination signal."
2026-02-04T02:53:17.695999Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 After termination signal, we find the list of new file : snapshot-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 After termination signal, we find the list of new file : snapshot-capability.log"
2026-02-04T02:53:17.696135Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Streamer terminated for system_logs/hosttools_capability/hosttools-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Streamer terminated for system_logs/hosttools_capability/hosttools-capability.log"
2026-02-04T02:53:17.696337Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/snapshot-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.696557Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Requesting POST: [{system_logs/snapshot_capability/snapshot-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Requesting POST: [{system_logs/snapshot_capability/snapshot-capability.log}]"
2026-02-04T02:53:17.696760Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:17.696980Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log. No changes after termination signal."
2026-02-04T02:53:17.697089Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Streamer terminated for system_logs/lifecycler/lifecycler.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Streamer terminated for system_logs/lifecycler/lifecycler.log"
2026-02-04T02:53:17.697229Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.697317Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log. No changes after termination signal."
2026-02-04T02:53:17.697401Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Streamer terminated for system_logs/metrics_capability/metrics-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Streamer terminated for system_logs/metrics_capability/metrics-capability.log"
2026-02-04T02:53:17.697442Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/metrics-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.697468Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.697495Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Exiting filewatcher for streamable file /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log. No changes after termination signal."
2026-02-04T02:53:17.697518Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Streamer terminated for system_logs/secrets_capability/secrets-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Streamer terminated for system_logs/secrets_capability/secrets-capability.log"
2026-02-04T02:53:17.697544Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/azureml-logs one more time with 3 s!"
2026-02-04T02:53:17.697575Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/outputs one more time with 3 s!"
2026-02-04T02:53:17.697620Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log/cs-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log/cs-capability.log"
2026-02-04T02:53:17.697642Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 After termination signal, we find the list of new file : cs-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 After termination signal, we find the list of new file : cs-capability.log"
2026-02-04T02:53:17.697677Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/cs-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:53:17.697704Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Requesting POST: [{system_logs/cs_capability/cs-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Requesting POST: [{system_logs/cs_capability/cs-capability.log}]"
2026-02-04T02:53:17.697750Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:17.697779Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 file LS_root/jobs/wd/.tmp does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 file LS_root/jobs/wd/.tmp does not exist"
2026-02-04T02:53:17.697807Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir LS_root/jobs/wd/.tmp one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir LS_root/jobs/wd/.tmp one more time with 3 s!"
2026-02-04T02:53:17.697871Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs/std_log.txt command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 New file detected: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs/std_log.txt"
2026-02-04T02:53:17.697904Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 After termination signal, we find the list of new file : std_log.txt command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 After termination signal, we find the list of new file : std_log.txt"
2026-02-04T02:53:17.697943Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 We need to refresh the dir /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/user_logs one more time with 3 s!"
2026-02-04T02:53:17.697970Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Requesting POST: [{user_logs/std_log.txt}] command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Requesting POST: [{user_logs/std_log.txt}]"
2026-02-04T02:53:17.697991Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86 command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_2d3ca86"
2026-02-04T02:53:17.704868Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Decrypt using CBCDecrypter"
2026-02-04T02:53:17.707349Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Decrypt using CBCDecrypter"
2026-02-04T02:53:17.709308Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:53:17 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:53:17 Decrypt using CBCDecrypter"

system_logs/lifecycler/execution-wrapper.log : 
----
2026-02-04T02:53:09.536107Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:34:45.198956
2026-02-04T02:53:09.543128Z  INFO run_execution_wrapper: execution_wrapper: Successfully dumped bootstrapping environment to file
2026-02-04T02:53:09.546918Z  INFO run_execution_wrapper: execution_wrapper: Enable std log streaming is not specified in executor configuration, default to not stream logs to stdout and stderr
2026-02-04T02:53:09.546983Z  INFO run_execution_wrapper: execution_wrapper: Enable termination signal handling is not specified in executor configuration, default to ignore termination signals
2026-02-04T02:53:09.547349Z  INFO run_execution_wrapper: execution_wrapper: Executor config not provided, certificates will not be updated.
2026-02-04T02:53:09.549887Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}: execution_wrapper::service: serving execution service at executor_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0
2026-02-04T02:53:09.551516Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:53:09.551593Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:10.709536Z  INFO ExecutionServicer::run: grpc_utils::server: Got grpc request request_name="run" remote_addr=None
2026-02-04T02:53:10.709743Z  INFO ExecutionServicer::run: execution_wrapper::service: file /opt/microsoft/singularity/unasignal/StopUserNode exists: false path=/opt/microsoft/singularity/unasignal/StopUserNode
2026-02-04T02:53:10.709844Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: spawn_execution request id="96365a5f-6e79-4f22-a473-1f4a4b1adb99" client_address=Some("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0")
2026-02-04T02:53:10.709922Z  WARN ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Skip injecting legacy env vars, distributed config is None, setting only the defaults
2026-02-04T02:53:10.710013Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Injecting AZ_BATCHAI_JOB_WORK_DIR=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd working_dir="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd"
2026-02-04T02:53:10.710158Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Injecting AZUREML_PROCESS_NAME=main as default
2026-02-04T02:53:10.710324Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:get_gpu_count: execution_wrapper::common: Get ComputeContext from env success compute_context=ComputeContext { cluster_name: "990b4522-de30-451c-8db0-8671300409ca", node_id: Literal("tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d"), vm_id: Some("e2072481-2a18-4575-808f-7b0a5df232ac"), run_attempt_count: 1, gpu_count: Some(0), vm_size: Some("STANDARD_D4_V3"), readable_cluster_name: Some("Serverless"), vm_priority: Some(Dedicated), use_vnet_or_private_link: false }
2026-02-04T02:53:10.710479Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:get_gpu_count: execution_wrapper::common: close time.busy=269µs time.idle=20.6µs
2026-02-04T02:53:10.710519Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_CR_EXECUTOR_CONFIG for spawned process
2026-02-04T02:53:10.710577Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Env var AZUREML_CR_DISTRIBUTED_CONFIG is empty for current process
2026-02-04T02:53:10.710600Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_SERVICE_ENDPOINT for spawned process
2026-02-04T02:53:10.710636Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_SERVICE_CERT_ENDPOINT for spawned process
2026-02-04T02:53:10.710669Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_DISCOVERY_SERVICE_ENDPOINT for spawned process
2026-02-04T02:53:10.710699Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Env var AZUREML_DEV_URL_MLFLOW is empty for current process
2026-02-04T02:53:10.710734Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_RUN_HISTORY_SERVICE_ENDPOINT for spawned process
2026-02-04T02:53:10.710775Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: close time.busy=258µs time.idle=4.10µs
2026-02-04T02:53:10.710790Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: close time.busy=870µs time.idle=5.20µs
2026-02-04T02:53:10.711059Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::infiniband_utils: Is InfiniBand device present: false infiniband_device_path="/dev/infiniband/uverbs0"
2026-02-04T02:53:10.711200Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: Spawning execution
2026-02-04T02:53:10.711879Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::parse_commands: execution_wrapper::execution: close time.busy=162µs time.idle=5.10µs
2026-02-04T02:53:10.712419Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: Spawning target process
2026-02-04T02:53:10.713775Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: execution process spawned pid=13
2026-02-04T02:53:10.714112Z  INFO execution_wrapper::execution: start waiting for processes execution to complete num_processes=1
2026-02-04T02:53:10.714288Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from PendingExecution to PendingExecution
2026-02-04T02:53:16.676930Z ERROR Execution::wait_for_completion: execution_wrapper::execution::process_manager: Failed blocking user process detected, process name: python, process pid: 13, code: Some(1) success_return_code=Zero { additional_codes: [] } code=Some(1)
2026-02-04T02:53:16.677041Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from PendingExecution to FailureDetected
2026-02-04T02:53:16.677121Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: [FailureDetected] Successfully started sleeping task
2026-02-04T02:53:16.677244Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from FailureDetected to ExecutionCompleted
2026-02-04T02:53:17.678389Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Start collecting process exit statuses
2026-02-04T02:53:17.678493Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Successfully collected the exit status of user process pid=13 process_name=python killed_by_process_manager=false
2026-02-04T02:53:17.678540Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Process manager successfully collected the exit statuses of all user processes on current node
2026-02-04T02:53:17.678579Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from ExecutionCompleted to CleanupStreamingTasks
2026-02-04T02:53:17.678622Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Start cleaning up execution log streaming tasks
2026-02-04T02:53:17.678656Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Process manager successfully aborted all streaming tasks for current execution
2026-02-04T02:53:17.678715Z  INFO Execution::wait_for_completion: execution_wrapper::execution: The stderr path is set, starting reading stderr from file. file_path="user_logs/std_log.txt"
2026-02-04T02:53:17.679051Z  INFO Execution::wait_for_completion: execution_wrapper::execution: Gathered execution result for rank 0 process_rank=0 exit_code=1 stderr_path=Some("user_logs/std_log.txt")
2026-02-04T02:53:17.679123Z  INFO Execution::wait_for_completion: execution_wrapper::execution: [wait_for_completion] execution process completed.
2026-02-04T02:53:17.686703Z  WARN Execution::wait_for_completion: execution_wrapper::detect_error: [Execution-wrapper::ErrorDetector] Failed to search OOM error from dmesg logs exception=General("non-zero exit code Some(1) from sh: ")
2026-02-04T02:53:17.687208Z  WARN Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:17.687272Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service: execution_wrapper::service: connecting to callback endpoint: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0 client_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0
2026-02-04T02:53:17.687488Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 600s }
2026-02-04T02:53:17.687948Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0")
2026-02-04T02:53:17.688005Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: close time.busy=484µs time.idle=44.7µs
2026-02-04T02:53:17.688036Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service: execution_wrapper::service: close time.busy=736µs time.idle=35.4µs
2026-02-04T02:53:17.689237Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: execution_wrapper::service: Completed execution id=96365a5f-6e79-4f22-a473-1f4a4b1adb99
2026-02-04T02:53:17.689592Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: execution_wrapper::service: close time.busy=1.25ms time.idle=1.15ms
2026-02-04T02:53:17.689622Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit: execution_wrapper::service: close time.busy=1.28ms time.idle=1.16ms
2026-02-04T02:53:17.689637Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: close time.busy=1.76ms time.idle=6.98s
2026-02-04T02:53:17.689647Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: close time.busy=3.98ms time.idle=6.98s
2026-02-04T02:53:17.689658Z  INFO ExecutionServicer::run: execution_wrapper::service: close time.busy=4.28ms time.idle=6.98s
2026-02-04T02:53:17.689670Z  INFO Execution::wait_for_completion: execution_wrapper::execution: close time.busy=3.41ms time.idle=6.97s
2026-02-04T02:53:17.689682Z  INFO execution_wrapper::execution: process execution completed

system_logs/lifecycler/lifecycler.log : 
----
2026-02-04T02:53:08.884790Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:34:38.445489
2026-02-04T02:53:08.885193Z  INFO load_config_from_env: lifecycler::config: Resolved grpc addresses lifecycler_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0 executor_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0
2026-02-04T02:53:08.885500Z  INFO load_config_from_env:load_capability_addresses_from_env{capability_endpoints_from_config={"CS_CAPABILITY": CapabilityEndpoint { name: "CS_CAPABILITY", address: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0", type: Service }, "HOSTTOOLS_CAPABILITY": CapabilityEndpoint { name: "HOSTTOOLS_CAPABILITY", address: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0", type: Service }, "METRICS_CAPABILITY": CapabilityEndpoint { name: "METRICS_CAPABILITY", address: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0", type: Service }, "SECRETS_CAPABILITY": CapabilityEndpoint { name: "SECRETS_CAPABILITY", address: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/secrets-capability:0", type: Operation }, "SNAPSHOT_CAPABILITY": CapabilityEndpoint { name: "SNAPSHOT_CAPABILITY", address: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0", type: Service }}}: lifecycler::config: close time.busy=210µs time.idle=18.9µs
2026-02-04T02:53:08.885608Z  INFO load_config_from_env: lifecycler::config: close time.busy=610µs time.idle=26.1µs
2026-02-04T02:53:08.885774Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: lifecycler::lifecycle: distributed config is not specified, skip setting up distributed barrier
2026-02-04T02:53:08.885850Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: lifecycler::lifecycle: Trying to configure lifecycler to ignore termination signals
2026-02-04T02:53:08.885937Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:53:08.886030Z  INFO Lifecycler::run_service{lifecycler_abort_state_writer=Some(LifecyclerAbortStateWriter { lifecycler_wd: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd" })}: lifecycler::service: serving lifecycle service address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0
2026-02-04T02:53:08.886267Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:08.886291Z  INFO Lifecycler::run_service{lifecycler_abort_state_writer=Some(LifecyclerAbortStateWriter { lifecycler_wd: "/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/cap/lifecycler/wd" })}:serve_more: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:10.366705Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0")
2026-02-04T02:53:10.366945Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=20.0ms time.idle=1.46s
2026-02-04T02:53:10.367164Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.367605Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/cs-capability:0")
2026-02-04T02:53:10.367657Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=402µs time.idle=99.0µs
2026-02-04T02:53:10.367710Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: CS_CAPABILITY service_name=CS_CAPABILITY timeout=30s
2026-02-04T02:53:10.367779Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.369756Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: CS_CAPABILITY service_name=CS_CAPABILITY health_status=1
2026-02-04T02:53:10.369861Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=CS_CAPABILITY
2026-02-04T02:53:10.369942Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=415µs time.idle=1.82ms
2026-02-04T02:53:10.370093Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.370611Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0")
2026-02-04T02:53:10.370685Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=295µs time.idle=301µs
2026-02-04T02:53:10.370849Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.371291Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/hosttools-capability:0")
2026-02-04T02:53:10.371363Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=321µs time.idle=198µs
2026-02-04T02:53:10.371490Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: HOSTTOOLS_CAPABILITY service_name=HOSTTOOLS_CAPABILITY timeout=30s
2026-02-04T02:53:10.371546Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.372495Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: HOSTTOOLS_CAPABILITY service_name=HOSTTOOLS_CAPABILITY health_status=1
2026-02-04T02:53:10.372568Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=HOSTTOOLS_CAPABILITY
2026-02-04T02:53:10.372606Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=292µs time.idle=830µs
2026-02-04T02:53:10.372786Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.373119Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0")
2026-02-04T02:53:10.373191Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=309µs time.idle=102µs
2026-02-04T02:53:10.373339Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.373646Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0")
2026-02-04T02:53:10.373707Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=260µs time.idle=114µs
2026-02-04T02:53:10.373744Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: METRICS_CAPABILITY service_name=METRICS_CAPABILITY timeout=30s
2026-02-04T02:53:10.373801Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.374624Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: METRICS_CAPABILITY service_name=METRICS_CAPABILITY health_status=1
2026-02-04T02:53:10.374726Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=METRICS_CAPABILITY
2026-02-04T02:53:10.374809Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=367µs time.idle=703µs
2026-02-04T02:53:10.374972Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/secrets-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.375333Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/secrets-capability:0")
2026-02-04T02:53:10.375404Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=353µs time.idle=87.1µs
2026-02-04T02:53:10.375530Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.375982Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0")
2026-02-04T02:53:10.376079Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=365µs time.idle=188µs
2026-02-04T02:53:10.376212Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.376494Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0")
2026-02-04T02:53:10.376547Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=272µs time.idle=66.8µs
2026-02-04T02:53:10.376580Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: SNAPSHOT_CAPABILITY service_name=SNAPSHOT_CAPABILITY timeout=30s
2026-02-04T02:53:10.376619Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.377748Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: SNAPSHOT_CAPABILITY service_name=SNAPSHOT_CAPABILITY health_status=1
2026-02-04T02:53:10.377814Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=SNAPSHOT_CAPABILITY
2026-02-04T02:53:10.377869Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=528µs time.idle=765µs
2026-02-04T02:53:10.377904Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities: lifecycler::lifecycle: close time.busy=27.9ms time.idle=1.46s
2026-02-04T02:53:10.377934Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.377990Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378019Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378050Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378057Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378119Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378563Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.378929Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.379562Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.380049Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=HOSTTOOLS_CAPABILITY
2026-02-04T02:53:10.381170Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: close time.busy=1.66ms time.idle=1.47ms
2026-02-04T02:53:10.382029Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=METRICS_CAPABILITY
2026-02-04T02:53:10.382366Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: lifecycler::capability_client: close time.busy=733µs time.idle=3.08ms
2026-02-04T02:53:10.382547Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=SECRETS_CAPABILITY
2026-02-04T02:53:10.383035Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: lifecycler::capability_client: close time.busy=1.18ms time.idle=2.93ms
2026-02-04T02:53:10.443405Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=CS_CAPABILITY
2026-02-04T02:53:10.443582Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: close time.busy=375µs time.idle=65.2ms
2026-02-04T02:53:10.696959Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=SNAPSHOT_CAPABILITY
2026-02-04T02:53:10.697077Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: close time.busy=331µs time.idle=317ms
2026-02-04T02:53:10.697135Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities: lifecycler::lifecycle: close time.busy=4.84ms time.idle=314ms
2026-02-04T02:53:10.697222Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.698933Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: lifecycler::capability_client: Received success code for teardown cap_name=SECRETS_CAPABILITY
2026-02-04T02:53:10.699011Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: lifecycler::capability_client: close time.busy=364µs time.idle=1.44ms
2026-02-04T02:53:10.699045Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}: lifecycler::lifecycle: close time.busy=290µs time.idle=1.57ms
2026-02-04T02:53:10.699139Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle: lifecycler::lifecycle: exited operation caps: true
2026-02-04T02:53:10.699509Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.700148Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0")
2026-02-04T02:53:10.700221Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=319µs time.idle=399µs
2026-02-04T02:53:10.700249Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=545µs time.idle=396µs
2026-02-04T02:53:10.700524Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.701155Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0")
2026-02-04T02:53:10.701241Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=319µs time.idle=402µs
2026-02-04T02:53:10.701278Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=614µs time.idle=400µs
2026-02-04T02:53:10.701419Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:53:10.705171Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/executor:0")
2026-02-04T02:53:10.705423Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: close time.busy=1.24ms time.idle=2.77ms
2026-02-04T02:53:10.705469Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: Executor service_name=Executor timeout=30s
2026-02-04T02:53:10.705721Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.707193Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_client: Health status for service: Executor service_name=Executor health_status=1
2026-02-04T02:53:10.707250Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=Executor
2026-02-04T02:53:10.707280Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=642µs time.idle=1.17ms
2026-02-04T02:53:10.707575Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor: lifecycler::lifecycle: close time.busy=3.61ms time.idle=4.75ms
2026-02-04T02:53:10.707652Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_lifecyclers{lifecycler_addresses=None}: lifecycler::lifecycle: close time.busy=1.40µs time.idle=6.60µs
2026-02-04T02:53:10.707760Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: entering phase rank=None phase=0 is_leader=true entered_phases=false
2026-02-04T02:53:10.707902Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:barrier_sync: lifecycler::lifecycle: close time.busy=1.40µs time.idle=5.60µs
2026-02-04T02:53:10.708054Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: Successfully got AzureML Context from environment, updating Run History with new run attempt
2026-02-04T02:53:10.708135Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: Skip updating run_attempt since cannot find AZUREML_CR_ENABLE_RUN_ATTEMPT_COUNT_BY_RUN_HISTORY from environment
2026-02-04T02:53:10.708178Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: starting phase execution rank=None phase=0
2026-02-04T02:53:10.708227Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: executing phase commands rank=None phase=0
2026-02-04T02:53:10.708300Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Executing commands
2026-02-04T02:53:10.708520Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:10.708567Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: lifecycler::executor_client: Starting execution execution_id=96365a5f-6e79-4f22-a473-1f4a4b1adb99 lifecycler_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0
2026-02-04T02:53:10.714337Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: lifecycler::executor_client: close time.busy=255µs time.idle=5.69ms
2026-02-04T02:53:10.714400Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Waiting for execution completion execution_id="96365a5f-6e79-4f22-a473-1f4a4b1adb99"
2026-02-04T02:53:17.688673Z  INFO ExecutionCallbackServicer::complete_execution: grpc_utils::server: Got grpc request request_name="complete_execution" remote_addr=None
2026-02-04T02:53:17.688785Z  INFO ExecutionCallbackServicer::complete_execution: lifecycler::service: close time.busy=121µs time.idle=16.8µs
2026-02-04T02:53:17.689087Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::wait_for_execution_completion{execution_id="96365a5f-6e79-4f22-a473-1f4a4b1adb99"}: lifecycler::executor_client: close time.busy=25.0µs time.idle=6.97s
2026-02-04T02:53:17.689251Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Execution completed execution_id="96365a5f-6e79-4f22-a473-1f4a4b1adb99"
2026-02-04T02:53:17.689329Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: close time.busy=849µs time.idle=6.98s
2026-02-04T02:53:17.689354Z ERROR run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: failed to execute commands exception=ExecutionFailed(ExecutionsFailures([ExecutionFailure { exit_code: 1, error_message: "Execution failed. User process 'python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n  File \"script.py\", line 162, in <module>\n    docker_utilities._docker_build_or_error(\n  File \"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py\", line 156, in _docker_build_or_error\n    _write_error_and_exit(error_msg, error_file_path=error_file_path)\n  File \"/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd/docker_utilities.py\", line 217, in _write_error_and_exit\n    sys.exit(1)\nSystemExit: 1\n\n", process_name: "python", error_file: "user_logs/std_log.txt" }])) rank=None phase=0
2026-02-04T02:53:17.689773Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: close time.busy=1.93ms time.idle=6.98s
2026-02-04T02:53:17.689886Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="CS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:17.689952Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="HOSTTOOLS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:17.690001Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:17.690041Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:53:17.691408Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: lifecycler::capability_client: Received success code for end cap_name=METRICS_CAPABILITY
2026-02-04T02:53:17.691465Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: lifecycler::capability_client: close time.busy=137µs time.idle=1.33ms
2026-02-04T02:53:17.692790Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: Received success code for end cap_name=SNAPSHOT_CAPABILITY
2026-02-04T02:53:17.692864Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: close time.busy=212µs time.idle=2.62ms

system_logs/metrics_capability/metrics-capability.log : 
----
2026-02-04T02:53:08.169120Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:30:39.546244
2026-02-04T02:53:08.169363Z  INFO metrics-capability::do_main: metrics_capability: metrics cap config cap_config=MetricsCapConfig { polling_interval_sec: 15, send_to_history_interval_sec: 60, enabled_resource_metrics: ["CpuUtilizationPercentage", "GpuUtilizationPercentage", "GpuEnergyJoules", "GpuMemoryUtilizationPercentage", "GpuMemoryUtilizationMegabytes", "GpuMemoryCapacityMegabytes", "CpuMemoryUtilizationPercentage", "CpuMemoryUtilizationMegabytes", "CpuMemoryCapacityMegabytes", "DiskReadMegabytes", "DiskWriteMegabytes", "NetworkInputMegabytes", "NetworkOutputMegabytes", "IBReceiveMegabytes", "IBTransmitMegabytes", "DiskUsedMegabytes", "DiskAvailMegabytes", "StorageAPISuccessCount", "StorageAPIFailureCount"], reserved_disk_space_bytes: 2501743288, additional_scrape_jobs: [], prometheus_push_gateway_port: None, enable_job_cost_metrics: true }
2026-02-04T02:53:08.169516Z  INFO metrics-capability::do_main: metrics_capability: run token file created
2026-02-04T02:53:08.169556Z  INFO metrics-capability::do_main: metrics_capability: embedded file file="prometheus-template.yml"
2026-02-04T02:53:08.329392Z  INFO metrics-capability::do_main: metrics_capability: prometheus config file created
2026-02-04T02:53:08.329625Z  INFO metrics-capability::do_main: metrics_capability: No GPUs found, skipping nvidia-smi instant exporter
2026-02-04T02:53:08.329988Z  INFO metrics-capability::do_main: metrics_capability::additional_scrape_jobs_configer: created additional scrape jobs additional_scrape_jobs="- targets:\n  - localhost:9500\n"
2026-02-04T02:53:08.330060Z  INFO metrics-capability::do_main: metrics_capability: prometheus push gateway not enabled
2026-02-04T02:53:08.330139Z  INFO metrics-capability::do_main: metrics_capability: starting metrics-cap exporter thread, listen on 0.0.0.0:9500
2026-02-04T02:53:08.330339Z  INFO metrics_capability: starting node-exporter subprocess watcher task
2026-02-04T02:53:08.330378Z  INFO metrics-capability::do_main: metrics_capability: metrics capability starting service address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0
2026-02-04T02:53:08.330403Z  INFO metrics_capability: starting node-exporter subprocess: node_exporter ["--collector.disable-defaults", "--collector.infiniband", "--collector.diskstats", "--log.level=info", "--web.listen-address=0.0.0.0:9100"] retry_count=1
2026-02-04T02:53:08.330448Z  INFO metrics-capability::do_main:metrics-capability::run_service{address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0"}: metrics_capability::service: metrics capability starting service address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0
2026-02-04T02:53:08.330713Z  INFO metrics-capability::do_main:metrics-capability::run_service{address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0"}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/metrics-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:08.330895Z  INFO metrics_capability: starting prometheus subprocess watcher task
2026-02-04T02:53:08.330935Z  INFO metrics_capability: starting run token updater task
2026-02-04T02:53:08.330959Z  INFO metrics_capability: starting prometheus subprocess: prometheus ["--storage.tsdb.retention.time=30m", "--log.level=info", "--enable-feature=expand-external-labels", "--config.file=/usr/local/bin/prometheus.yml", "--web.listen-address=0.0.0.0:9090"] retry_count=1
2026-02-04T02:53:08.331091Z  INFO metrics_capability: starting disk full checker, reserved_disk_space_bytes: 2501743288
2026-02-04T02:53:08.331162Z  INFO vienna_client::run_history::refresh_run_token{service_endpoint="https://koreacentral.api.azureml.ms" run_id=RunId { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group_name: "8ai-final-team6", workspace_name: "vision", experiment_name: "prepare_image", run_id: "imgbldrun_2d3ca86" }}: vienna_client::run_history: Calling service service_endpoint="https://koreacentral.api.azureml.ms"
2026-02-04T02:53:08.331287Z  INFO metrics_capability: heartbeat: AZ_BATCH_NODE_ROOT_DIR (node_disk_available_bytes) = 99247239168 metric_name=node_disk_available_bytes value=99247239168 root_dir=/mnt/root_dir
2026-02-04T02:53:08.331419Z  INFO metrics_capability: heartbeat: starting
2026-02-04T02:53:08.331588Z  INFO metrics_capability: started node-exporter subprocess
2026-02-04T02:53:08.331643Z  INFO metrics_capability: starting cadvisor subprocess watcher task
2026-02-04T02:53:08.331671Z  INFO metrics_capability: starting cadvisor subprocess: cadvisor ["--stderrthreshold=0", "--raw_cgroup_prefix_whitelist=/system.slice/containerd.service", "--listen_ip=0.0.0.0", "--port=8081"] retry_count=1
2026-02-04T02:53:08.334009Z  INFO metrics_capability: started cadvisor subprocess
2026-02-04T02:53:08.340975Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.340Z level=INFO source=node_exporter.go:217 msg="Starting node_exporter" version="(version=, branch=, revision=2d09f79ab64ab699fc518723bcb6eca7711b9046)"
2026-02-04T02:53:08.341490Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.341Z level=INFO source=node_exporter.go:218 msg="Build context" build_context="(go=go1.24.11, platform=linux/amd64, user=, date=, tags=unknown)"
2026-02-04T02:53:08.344010Z  INFO metrics_capability: started prometheus subprocess
2026-02-04T02:53:08.344873Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.341Z level=WARN source=node_exporter.go:220 msg="Node Exporter is running as root user. This exporter is designed to run as unprivileged user, root is not required."
2026-02-04T02:53:08.352242Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.350Z level=INFO source=diskstats_common.go:108 msg="Parsed flag --collector.diskstats.device-exclude" collector=diskstats flag=^(z?ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\d+n\d+p)\d+$
2026-02-04T02:53:08.352455Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.351Z level=ERROR source=diskstats_linux.go:255 msg="Failed to open directory, disabling udev device properties" collector=diskstats path=/run/udev/data
2026-02-04T02:53:08.352660Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.351Z level=INFO source=node_exporter.go:136 msg="Enabled collectors"
2026-02-04T02:53:08.352966Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.351Z level=INFO source=node_exporter.go:142 msg=diskstats
2026-02-04T02:53:08.353198Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.351Z level=INFO source=node_exporter.go:142 msg=infiniband
2026-02-04T02:53:08.353382Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.352Z level=INFO source=tls_config.go:354 msg="Listening on" address=[::]:9100
2026-02-04T02:53:08.353535Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:53:08.352Z level=INFO source=tls_config.go:357 msg="TLS is disabled." http2=false address=[::]:9100
2026-02-04T02:53:08.367271Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.367159      17 cadvisor.go:126] enabled metrics: app,cpu,cpuLoad,disk,diskIO,memory,network,oom_event,percpu,perf_event,pressure
2026-02-04T02:53:08.367664Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.367329      17 storagedriver.go:55] Caching stats in memory for 2m0s
2026-02-04T02:53:08.367767Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.367531      17 manager.go:171] cAdvisor running in container: "/system.slice/containerd.service/cr_sys_668dc36ab7b4433da866f7070b4a9612/6ab201908901a401e14cafe08fcfcf21c9168573e13ceb6c9857137ef2d42076"
2026-02-04T02:53:08.401899Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.401Z level=WARN source=main.go:305 msg="Unknown option for --enable-feature" option=expand-external-labels
2026-02-04T02:53:08.405514Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.405Z level=INFO source=main.go:1589 msg="updated GOGC" old=100 new=75
2026-02-04T02:53:08.416214Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.416Z level=INFO source=main.go:704 msg="Leaving GOMAXPROCS=4: CPU quota undefined" component=automaxprocs
2026-02-04T02:53:08.418867Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.417Z level=INFO source=memlimit.go:198 msg="GOMEMLIMIT is updated" component=automemlimit package=github.com/KimMachineGun/automemlimit/memlimit GOMEMLIMIT=15095701094 previous=9223372036854775807
2026-02-04T02:53:08.418924Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.418Z level=INFO source=main.go:803 msg="Starting Prometheus Server" mode=server version="(version=3.8.1, branch=custom-main, revision=e5172d4d12e8a4e5fecda05599ca80a29ecdac90)"
2026-02-04T02:53:08.418949Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.418Z level=INFO source=main.go:808 msg="operational information" build_context="(go=go1.25.5, platform=linux/amd64, user=root@buildkitsandbox, date=20260123-10:33:25, tags=netgo,builtinassets)" host_details="(Linux 6.8.0-1034-azure #39~22.04.1-Ubuntu SMP Wed Aug 13 22:25:47 UTC 2025 x86_64 95c79f3b80034489aaf5f0b3430050cc000000 (none))" fd_limits="(soft=262144, hard=262144)" vm_limits="(soft=unlimited, hard=unlimited)"
2026-02-04T02:53:08.435837Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.435Z level=INFO source=web.go:684 msg="Start listening for connections" component=web address=0.0.0.0:9090
2026-02-04T02:53:08.436967Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.436Z level=INFO source=main.go:1331 msg="Starting TSDB ..."
2026-02-04T02:53:08.444297Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.444Z level=INFO source=tls_config.go:354 msg="Listening on" component=web address=[::]:9090
2026-02-04T02:53:08.444460Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.444Z level=INFO source=tls_config.go:357 msg="TLS is disabled." component=web http2=false address=[::]:9090
2026-02-04T02:53:08.448978Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.448Z level=INFO source=head.go:681 msg="Replaying on-disk memory mappable chunks if any" component=tsdb
2026-02-04T02:53:08.449084Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.448Z level=INFO source=head.go:767 msg="On-disk memory mappable chunks replay completed" component=tsdb duration=2.3µs
2026-02-04T02:53:08.449427Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.448Z level=INFO source=head.go:775 msg="Replaying WAL, this may take a while" component=tsdb
2026-02-04T02:53:08.450676Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.450Z level=INFO source=head.go:848 msg="WAL segment loaded" component=tsdb segment=0 maxSegment=0 duration=1.662514ms
2026-02-04T02:53:08.450798Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.450Z level=INFO source=head.go:885 msg="WAL replay completed" component=tsdb checkpoint_replay_duration=51.701µs wal_replay_duration=1.702614ms wbl_replay_duration=200ns chunk_snapshot_load_duration=0s mmap_chunk_replay_duration=2.3µs total_replay_duration=1.836716ms
2026-02-04T02:53:08.455687Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.454Z level=INFO source=main.go:1352 msg="filesystem information" fs_type=794c7630
2026-02-04T02:53:08.455787Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.454Z level=INFO source=main.go:1355 msg="TSDB started"
2026-02-04T02:53:08.456030Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.454Z level=INFO source=main.go:1542 msg="Loading configuration file" filename=/usr/local/bin/prometheus.yml
2026-02-04T02:53:08.461400Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.460Z level=INFO source=watcher.go:240 msg="Starting WAL watcher" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post queue=f2573f
2026-02-04T02:53:08.461536Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.460Z level=INFO source=metadata_watcher.go:90 msg="Starting scraped metadata watcher" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post
2026-02-04T02:53:08.461577Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.461Z level=INFO source=watcher.go:292 msg="Replaying WAL" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post queue=f2573f
2026-02-04T02:53:08.470695Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.470Z level=INFO source=main.go:1582 msg="Completed loading of configuration file" db_storage=1.4µs remote_storage=1.543514ms web_handler=400ns query_engine=700ns scrape=6.573957ms scrape_sd=119.201µs notify=1.9µs notify_sd=900ns rules=3.42253ms tracing=6.5µs filename=/usr/local/bin/prometheus.yml totalDuration=16.243041ms
2026-02-04T02:53:08.470907Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.470Z level=INFO source=main.go:1316 msg="Server is ready to receive web requests."
2026-02-04T02:53:08.470941Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:08.470Z level=INFO source=manager.go:202 msg="Starting rule manager..." component="rule manager"
2026-02-04T02:53:08.524419Z  INFO vienna_client::run_history::refresh_run_token{service_endpoint="https://koreacentral.api.azureml.ms" run_id=RunId { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group_name: "8ai-final-team6", workspace_name: "vision", experiment_name: "prepare_image", run_id: "imgbldrun_2d3ca86" }}: vienna_client::run_history: close time.busy=52.8ms time.idle=140ms
2026-02-04T02:53:08.524477Z  INFO metrics_capability: run token refreshed, expiration 2026-02-05 02:53:08.519697100 +00:00
2026-02-04T02:53:08.525862Z  INFO metrics_capability: run token written to file
2026-02-04T02:53:08.677317Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.677209      17 fs.go:130] Filesystem UUIDs: map[03B6-4352:/dev/sdb15 76ad26e1-60f8-449e-8051-e6cd77917d44:/dev/sdb1 9e7dfdc1-a85f-4915-aaf3-f6f0efb32914:/dev/sda1]
2026-02-04T02:53:08.677658Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.677268      17 fs.go:131] Filesystem partitions: map[/dev:{mountpoint:/dev major:0 minor:78 fsType:tmpfs blockSize:0} /dev/log:{mountpoint:/dev/log major:0 minor:26 fsType:tmpfs blockSize:0} /dev/loop0:{mountpoint:/rootfs/snap/core20/2599 major:7 minor:0 fsType:squashfs blockSize:0} /dev/loop1:{mountpoint:/rootfs/snap/lxd/31333 major:7 minor:1 fsType:squashfs blockSize:0} /dev/loop2:{mountpoint:/rootfs/snap/snapd/24792 major:7 minor:2 fsType:squashfs blockSize:0} /dev/loop3:{mountpoint:/rootfs/snap/snapd/25935 major:7 minor:3 fsType:squashfs blockSize:0} /dev/loop4:{mountpoint:/rootfs/snap/lxd/36918 major:7 minor:4 fsType:squashfs blockSize:0} /dev/root:{mountpoint:/var/lib/docker major:8 minor:17 fsType:ext4 blockSize:0} /dev/sda1:{mountpoint:/rootfs/mnt major:8 minor:1 fsType:ext4 blockSize:0} /dev/sdb15:{mountpoint:/rootfs/boot/efi major:8 minor:31 fsType:vfat blockSize:0} /dev/shm:{mountpoint:/dev/shm major:0 minor:67 fsType:tmpfs blockSize:0} /rootfs/dev/shm:{mountpoint:/rootfs/dev/shm major:0 minor:24 fsType:tmpfs blockSize:0} /rootfs/run:{mountpoint:/rootfs/run major:0 minor:26 fsType:tmpfs blockSize:0} /rootfs/run/lock:{mountpoint:/rootfs/run/lock major:0 minor:27 fsType:tmpfs blockSize:0} /rootfs/run/snapd/ns:{mountpoint:/rootfs/run/snapd/ns major:0 minor:26 fsType:tmpfs blockSize:0} /rootfs/sys/fs/cgroup:{mountpoint:/rootfs/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev:{mountpoint:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev major:0 minor:78 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm:{mountpoint:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm major:0 minor:67 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup:{mountpoint:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup major:0 minor:63 fsType:tmpfs blockSize:0} /run/docker.sock:{mountpoint:/run/docker.sock major:0 minor:26 fsType:tmpfs blockSize:0} /sys/fs/cgroup:{mountpoint:/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev major:0 minor:78 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/log:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/log major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm major:0 minor:67 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/dev/shm:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/dev/shm major:0 minor:24 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/lock:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/lock major:0 minor:27 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/snapd/ns:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/snapd/ns major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev major:0 minor:78 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm major:0 minor:67 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup major:0 minor:63 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} overlay_0-47:{mountpoint:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged major:0 minor:47 fsType:overlay blockSize:0} overlay_0-64:{mountpoint:/var/lib/docker/overlay2/814630ae275e1414bfc8b353e7d3c6e598666245539a3948b6b2f54f7e00e715/merged major:0 minor:64 fsType:overlay blockSize:0} overlay_0-68:{mountpoint:/var/lib/docker/overlay2/493b36f32921d51aee96d68f7c0b4b75c2b059c2f66084209b1b6a70ed8c7c62/merged major:0 minor:68 fsType:overlay blockSize:0} overlay_0-69:{mountpoint:/var/lib/docker/overlay2/4d1f145a38d4105e2f2999e8ac1ff50e990c15a2d8d2cb1a8fc10653f82d0812/merged major:0 minor:69 fsType:overlay blockSize:0} overlay_0-74:{mountpoint:/var/lib/docker/overlay2/0497883e7805edff1d248b7031d416dc1557e56df5ce02eca470a0fecaae158a/merged major:0 minor:74 fsType:overlay blockSize:0} overlay_0-75:{mountpoint:/var/lib/docker/overlay2/a52845ae03f90be24b02329f460a981629684f4ab0ab8f7bc86eb70ff8677324/merged major:0 minor:75 fsType:overlay blockSize:0}]
2026-02-04T02:53:08.686440Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.686052      17 manager.go:218] Machine: {Timestamp:2026-02-04 02:53:08.685503125 +0000 UTC m=+0.343102875 CPUVendorID:GenuineIntel NumCores:4 NumPhysicalCores:2 NumSockets:1 NumBooks:0 NumDrawers:0 CpuFrequency:2294683 MemoryCapacity:16773001216 SwapCapacity:0 MemoryByType:map[] NVMInfo:{MemoryModeCapacity:0 AppDirectModeCapacity:0 AvgPowerBudget:0} HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:271616a80e7443399bb849116fcf7890 SystemUUID:812407e2-182a-7545-808f-7b0a5df232ac BootID:03a66a23-a9e3-4934-a8b5-6fb0e5393e7d Filesystems:[{Device:overlay DeviceMajor:0 DeviceMinor:47 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/rootfs/run/lock DeviceMajor:0 DeviceMinor:27 Capacity:5242880 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/loop3 DeviceMajor:7 DeviceMinor:3 Capacity:50462720 Type:vfs Inodes:617 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/snapd/ns DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:overlay_0-68 DeviceMajor:0 DeviceMinor:68 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/rootfs/dev/shm DeviceMajor:0 DeviceMinor:24 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:63 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:overlay_0-47 DeviceMajor:0 DeviceMinor:47 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/rootfs/run/snapd/ns DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/dev/loop1 DeviceMajor:7 DeviceMinor:1 Capacity:93847552 Type:vfs Inodes:961 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm DeviceMajor:0 DeviceMinor:67 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:overlay_0-64 DeviceMajor:0 DeviceMinor:64 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/dev DeviceMajor:0 DeviceMinor:78 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/rootfs/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/dev/sda1 DeviceMajor:8 DeviceMinor:1 Capacity:105087164416 Type:vfs Inodes:6553600 HasInodes:true} {Device:/dev/loop4 DeviceMajor:7 DeviceMinor:4 Capacity:95944704 Type:vfs Inodes:961 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev DeviceMajor:0 DeviceMinor:78 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm DeviceMajor:0 DeviceMinor:67 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/run/docker.sock DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:overlay_0-74 DeviceMajor:0 DeviceMinor:74 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/dev/sdb15 DeviceMajor:8 DeviceMinor:31 Capacity:109395456 Type:vfs Inodes:0 HasInodes:true} {Device:/dev/shm DeviceMajor:0 DeviceMinor:67 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/loop0 DeviceMajor:7 DeviceMinor:0 Capacity:66977792 Type:vfs Inodes:11901 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev DeviceMajor:0 DeviceMinor:78 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/shm DeviceMajor:0 DeviceMinor:67 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/dev/shm DeviceMajor:0 DeviceMinor:24 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run/lock DeviceMajor:0 DeviceMinor:27 Capacity:5242880 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev DeviceMajor:0 DeviceMinor:78 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:63 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/loop2 DeviceMajor:7 DeviceMinor:2 Capacity:51773440 Type:vfs Inodes:616 HasInodes:true} {Device:/dev/root DeviceMajor:8 DeviceMinor:17 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/rootfs/run DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/dev/log DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/dev/log DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/var/lib/docker/overlay2/ca8fed15632a536d5f74dbfd7de01bfa3f6df45daaba61613a19de93fa898e41/merged/rootfs/run DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:overlay_0-75 DeviceMajor:0 DeviceMinor:75 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:overlay_0-69 DeviceMajor:0 DeviceMinor:69 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true}] DiskMap:map[8:0:{Name:sda Major:8 Minor:0 Size:107374182400 Scheduler:mq-deadline} 8:16:{Name:sdb Major:8 Minor:16 Size:137438953472 Scheduler:mq-deadline}] NetworkDevices:[{Name:eth0 MacAddress:00:22:48:cc:3c:17 Speed:40000 Mtu:1500}] Topology:[{Id:0 Memory:16773001216 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] Cores:[{Id:0 Threads:[0 1] Caches:[{Id:0 Size:32768 Type:Data Level:1} {Id:0 Size:32768 Type:Instruction Level:1} {Id:0 Size:262144 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:} {Id:1 Threads:[2 3] Caches:[{Id:1 Size:32768 Type:Data Level:1} {Id:1 Size:32768 Type:Instruction Level:1} {Id:1 Size:262144 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:}] Caches:[{Id:0 Size:52428800 Type:Unified Level:3}] Distances:[10]}] CloudProvider:Azure InstanceType:Unknown InstanceID:812407e2-182a-7545-808f-7b0a5df232ac}
2026-02-04T02:53:08.686554Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.686373      17 manager_no_libpfm.go:28] cAdvisor is build without cgo and/or libpfm support. Perf event counters are not available.
2026-02-04T02:53:08.686583Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.686482      17 manager.go:234] Version: {KernelVersion:6.8.0-1034-azure ContainerOsVersion:Debian GNU/Linux 11 (bullseye) DockerVersion: DockerAPIVersion: CadvisorVersion: CadvisorRevision:e3f6b33}
2026-02-04T02:53:08.686932Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.686867      17 factory.go:55] Registering systemd factory
2026-02-04T02:53:08.686972Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.686889      17 factory.go:222] Registration of the systemd container factory successfully
2026-02-04T02:53:08.687096Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.687041      17 factory.go:220] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
2026-02-04T02:53:08.687159Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.687125      17 factory.go:220] Registration of the containerd container factory failed: unable to create containerd client: containerd: cannot unix dial containerd api service: dial unix /run/containerd/containerd.sock: connect: no such file or directory
2026-02-04T02:53:08.751751Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.751680      17 factory.go:365] Registering Docker factory
2026-02-04T02:53:08.751922Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.751714      17 factory.go:222] Registration of the docker container factory successfully
2026-02-04T02:53:08.752200Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.752165      17 factory.go:220] Registration of the podman container factory failed: failed to validate Podman info: response not present: Get "http://d/v1.0.0/info": dial unix /var/run/podman/podman.sock: connect: no such file or directory
2026-02-04T02:53:08.752457Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.752390      17 factory.go:105] Registering Raw factory
2026-02-04T02:53:08.752642Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.752601      17 manager.go:1211] Started watching for new ooms in manager
2026-02-04T02:53:08.753574Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.753537      17 manager.go:351] Starting recovery of all containers
2026-02-04T02:53:08.810958Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.809871      17 manager.go:356] Recovery completed
2026-02-04T02:53:08.834511Z  INFO metrics_capability: [cadvisor] I0204 02:53:08.834227      17 cadvisor.go:179] Starting cAdvisor version: -e3f6b33 on port 8081
2026-02-04T02:53:10.379304Z  INFO metrics-capability::start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:53:10.379920Z  INFO metrics-capability::start: metrics_capability::capability_service: close time.busy=619µs time.idle=26.6µs
2026-02-04T02:53:15.986893Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:53:15.986Z level=INFO source=watcher.go:538 msg="Done replaying WAL" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post duration=7.525845389s
2026-02-04T02:53:17.690569Z  INFO metrics-capability::end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:53:17.690788Z  INFO metrics-capability::end: metrics_capability::capability_service: close time.busy=221µs time.idle=45.9µs

system_logs/secrets_capability/secrets-capability.log : 
----
2026-02-04T02:53:09.439693Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:35:03.249413
2026-02-04T02:53:09.440190Z  INFO secrets_capability: secret cap config str: {"secrets_configuration":{"_ED9A82DEDF0A4AB7B581482232C899A7":{"workspace_secret_name":"910fb75a-d5c9-4f83-befd-336522390b63","uri":null},"_B3B13C7246024F24AF05655ABC5737FE":{"workspace_secret_name":"fbfd0f4e-33db-4eec-8278-847aaf428135","uri":null},"_E6EDC32B45874E86AF15A74C204ABB18":{"workspace_secret_name":"505d2bfb-d15d-4c8e-8aab-2865be92fed0","uri":null}}}
2026-02-04T02:53:09.440619Z  INFO secrets-capability.parse_config: secrets_capability::config_parser: close time.busy=25.2µs time.idle=42.2µs
2026-02-04T02:53:09.440747Z  INFO secrets_capability: get secrets from credential service service_endpoint="https://koreacentral.api.azureml.ms" secret_names=["910fb75a-d5c9-4f83-befd-336522390b63", "fbfd0f4e-33db-4eec-8278-847aaf428135", "505d2bfb-d15d-4c8e-8aab-2865be92fed0"]
2026-02-04T02:53:09.441048Z  INFO vienna_client::credential::credential: Calling credential service to batch get secrets credential_service_endpoint="https://koreacentral.api.azureml.ms"
2026-02-04T02:53:09.455732Z  INFO vienna_client::http_client: send http request to https://koreacentral.api.azureml.ms/credential/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/secrets:getbatch
2026-02-04T02:53:09.575927Z  INFO vienna_client::credential::credential: get response from credential service response_status=200 OK
2026-02-04T02:53:09.576358Z  INFO secrets_capability::service: serving capability service at address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/secrets-capability:0
2026-02-04T02:53:09.577226Z  INFO serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/secrets-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:10.380484Z  INFO grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:53:10.380602Z  INFO secrets_capability::capability_service: return secrets envs to lifecycler env_keys=["_ED9A82DEDF0A4AB7B581482232C899A7", "_B3B13C7246024F24AF05655ABC5737FE", "_E6EDC32B45874E86AF15A74C204ABB18"]
2026-02-04T02:53:10.697973Z  INFO grpc_utils::server: Got grpc request request_name="teardown" remote_addr=None
2026-02-04T02:53:10.699134Z  INFO serve: grpc_utils::endpoint::serve: close time.busy=666µs time.idle=1.12s
2026-02-04T02:53:10.699185Z  INFO telemetry: Closing telemetry client channel.
2026-02-04T02:53:11.503437Z  INFO telemetry: Telemetry shutdown completed successfully.

system_logs/snapshot_capability/snapshot-capability.log : 
----
2026-02-04T02:53:09.723002Z  INFO telemetry: job_telemetry_init artifact_type= branch= ci_number= ci_name= build_time=
2026-02-04T02:53:09.723278Z  INFO snapshot-capability::do_main:snapshot-capability.parse_config: snapshot_capability::config_parser: Initialized config for snapshot download
2026-02-04T02:53:09.723341Z  INFO snapshot-capability::do_main:snapshot-capability.parse_config: snapshot_capability::config_parser: close time.busy=142µs time.idle=8.20µs
2026-02-04T02:53:09.723389Z  INFO snapshot-capability::do_main: snapshot_capability: snapshot-capability starting service at server_address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0
2026-02-04T02:53:09.723474Z  INFO snapshot-capability::do_main:snapshot-capability::run_service{address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0" snapshot_cap_config=Ok(SnapshotCapConfig { azureml_context: AzureMLContext { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group: "8ai-final-team6", workspace_name: "vision", workspace_id: "375c6882-0301-4d1c-b327-3695ae3932f9", service_endpoint: "https://koreacentral.api.azureml.ms", service_cert_endpoint: "https://koreacentral.cert.api.azureml.ms", discovery_endpoint: "https://koreacentral.api.azureml.ms/discovery", experiment_name: "prepare_image", experiment_id: "31a25d6d-ed6c-48fd-9158-729d8c9abaf0", run_id: "imgbldrun_2d3ca86", root_run_id: "imgbldrun_2d3ca86", run_token-length: 1182, run_history_service_endpoint: "https://koreacentral.api.azureml.ms", data_container_id: "dcid.imgbldrun_2d3ca86", run_uuid: "668dc36a-b7b4-433d-a866-f7070b4a9612" }, snapshots: Some([Snapshot { snapshot_asset_id: None, id: Some("33270855-cf1c-4568-a8b8-cd430a742075"), path_stack: Some(["."]) }]), user_wd: Some("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd"), check_hash: Some(false), enforce_hash_date: Some(2023-01-01), max_retry_duration_in_ms: Some(60000) })}: snapshot_capability::service: snapshot capability serving at address=/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0
2026-02-04T02:53:09.723701Z  INFO snapshot-capability::do_main:snapshot-capability::run_service{address="/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0" snapshot_cap_config=Ok(SnapshotCapConfig { azureml_context: AzureMLContext { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group: "8ai-final-team6", workspace_name: "vision", workspace_id: "375c6882-0301-4d1c-b327-3695ae3932f9", service_endpoint: "https://koreacentral.api.azureml.ms", service_cert_endpoint: "https://koreacentral.cert.api.azureml.ms", discovery_endpoint: "https://koreacentral.api.azureml.ms/discovery", experiment_name: "prepare_image", experiment_id: "31a25d6d-ed6c-48fd-9158-729d8c9abaf0", run_id: "imgbldrun_2d3ca86", root_run_id: "imgbldrun_2d3ca86", run_token-length: 1182, run_history_service_endpoint: "https://koreacentral.api.azureml.ms", data_container_id: "dcid.imgbldrun_2d3ca86", run_uuid: "668dc36a-b7b4-433d-a866-f7070b4a9612" }, snapshots: Some([Snapshot { snapshot_asset_id: None, id: Some("33270855-cf1c-4568-a8b8-cd430a742075"), path_stack: Some(["."]) }]), user_wd: Some("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd"), check_hash: Some(false), enforce_hash_date: Some(2023-01-01), max_retry_duration_in_ms: Some(60000) })}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/.grpc/snapshot-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:53:10.380366Z  INFO snapshot-capability.start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:53:10.380482Z  INFO snapshot-capability.start: snapshot_capability::snapshot_downloader: Using local working directory: /mnt/azureml/cr/j/668dc36ab7b4433da866f7070b4a9612/exe/wd
2026-02-04T02:53:10.380529Z  INFO snapshot-capability.start: snapshot_capability::snapshot_downloader: Fetching snapshot ID: 33270855-cf1c-4568-a8b8-cd430a742075
2026-02-04T02:53:10.434953Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.546850Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Retrieved snapshot metadata
2026-02-04T02:53:10.547010Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.612857Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Preparing to download snapshot files
2026-02-04T02:53:10.612999Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.639019Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.645099Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.651465Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.657142Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.662304Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.684725Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.690310Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:53:10.696051Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Successfully downloaded snapshot with 8 files
2026-02-04T02:53:10.696102Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Snapshot is downloaded, upload_hash = None, check_hash = Some(false)
2026-02-04T02:53:10.696140Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Updating ignore file...
2026-02-04T02:53:10.696169Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Ignore file candidates: ./.amlignore, ./.gitignore
2026-02-04T02:53:10.696211Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: No ignore file found, create new: ./.amlignore
2026-02-04T02:53:10.696334Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Updating ignore file... done
2026-02-04T02:53:10.696398Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: close time.busy=8.69ms time.idle=141ms
2026-02-04T02:53:10.696482Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: close time.busy=67.4ms time.idle=249ms
2026-02-04T02:53:10.696503Z  INFO snapshot-capability.start: snapshot_capability::capability_service: close time.busy=67.7ms time.idle=248ms
2026-02-04T02:53:17.691597Z  INFO snapshot-capability.end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:53:17.691721Z  INFO snapshot-capability.end: snapshot_capability::capability_service: close time.busy=151µs time.idle=60.3µs
