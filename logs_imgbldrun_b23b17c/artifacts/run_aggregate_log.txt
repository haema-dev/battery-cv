======Starting Run on Compute======
The run ID for the run on compute is imgbldrun_b23b17c

Additional logs for the run: https://ml.azure.com/experiments/id/prepare_image/runs/imgbldrun_b23b17c?wsid=/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourcegroups/8ai-final-team6/workspaces/vision&tid=5fb256f0-fbf2-40d2-81d5-bac1b32c419d


user_logs/std_log.txt : 
----
2026-02-04T02:58:17: Logging into Docker registry: 375c688203014d1cb3273695ae3932f9.azurecr.io
2026-02-04T02:58:17: WARNING! Using --password via the CLI is insecure. Use --password-stdin.

2026-02-04T02:58:17: Login Succeeded
2026-02-04T02:58:17: WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.
2026-02-04T02:58:17: Configure a credential helper to remove this warning. See
2026-02-04T02:58:17: https://docs.docker.com/go/credential-store/



2026-02-04T02:58:17: Running: ['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8:1']
2026-02-04T02:58:18: #0 building with "default" instance using docker driver

2026-02-04T02:58:18: #1 [internal] load .dockerignore
2026-02-04T02:58:18: #1 transferring context: 2B done
2026-02-04T02:58:18: #1 DONE 0.1s

2026-02-04T02:58:18: #2 [internal] load build definition from Dockerfile
2026-02-04T02:58:18: #2 transferring dockerfile: 771B done
2026-02-04T02:58:18: #2 DONE 0.2s

2026-02-04T02:58:18: #3 [internal] load metadata for ghcr.io/astral-sh/uv:latest
2026-02-04T02:58:18: #3 DONE 0.6s

2026-02-04T02:58:18: #4 [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
2026-02-04T02:58:19: #4 DONE 1.3s

2026-02-04T02:58:19: #5 [stage-0 1/7] FROM docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04@sha256:f3a7fb39fa3ffbe54da713dd2e93063885e5be2f4586a705c39031b8284d379a
2026-02-04T02:58:19: #5 DONE 0.0s

2026-02-04T02:58:19: #6 FROM ghcr.io/astral-sh/uv:latest@sha256:db9370c2b0b837c74f454bea914343da9f29232035aa7632a1b14dc03add9edb
2026-02-04T02:58:19: #6 DONE 0.0s

2026-02-04T02:58:19: #7 [stage-0 2/7] RUN apt-get update && apt-get install -y     python3.10     python3.10-dev     python3.10-venv     && rm -rf /var/lib/apt/lists/*
2026-02-04T02:58:19: #7 CACHED

2026-02-04T02:58:19: #8 [stage-0 3/7] COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/
2026-02-04T02:58:19: #8 CACHED

2026-02-04T02:58:19: #9 [stage-0 4/7] WORKDIR /app
2026-02-04T02:58:19: #9 CACHED

2026-02-04T02:58:19: #10 [internal] load build context
2026-02-04T02:58:19: #10 transferring context: 1.50kB done
2026-02-04T02:58:19: #10 DONE 0.1s

2026-02-04T02:58:19: #11 [stage-0 5/7] COPY pyproject.toml uv.lock ./
2026-02-04T02:58:19: #11 ERROR: failed to calculate checksum of ref 9ec04c68-912f-4991-82b6-6f05384bf37f::bfgea5s5xbhk8ltvm6z7mxxse: "/uv.lock": not found
2026-02-04T02:58:19: ------
2026-02-04T02:58:19:  > [stage-0 5/7] COPY pyproject.toml uv.lock ./:
2026-02-04T02:58:19: ------
2026-02-04T02:58:19: Dockerfile:16
2026-02-04T02:58:19: --------------------
2026-02-04T02:58:19:   14 |     
2026-02-04T02:58:19:   15 |     # 3. 의존성 파일 복사
2026-02-04T02:58:19:   16 | >>> COPY pyproject.toml uv.lock ./
2026-02-04T02:58:19:   17 |     
2026-02-04T02:58:19:   18 |     # 4. ✅ uv로 모든 의존성 설치 (torch도 포함)
2026-02-04T02:58:19: --------------------
2026-02-04T02:58:19: ERROR: failed to solve: failed to compute cache key: failed to calculate checksum of ref 9ec04c68-912f-4991-82b6-6f05384bf37f::bfgea5s5xbhk8ltvm6z7mxxse: "/uv.lock": not found


2026-02-04T02:58:19: CalledProcessError(1, ['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8:1'])

2026-02-04T02:58:19: Building docker image failed with exit code: 1

2026-02-04T02:58:19: Logging out of Docker registry: 375c688203014d1cb3273695ae3932f9.azurecr.io
2026-02-04T02:58:19: Removing login credentials for https://index.docker.io/v1/


2026-02-04T02:58:19: Traceback (most recent call last):
  File "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py", line 152, in _docker_build_or_error
    docker_execute_function(docker_command, build_command, print_command_args=True)
  File "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py", line 23, in docker_execute_function
    return killable_subprocess.check_call(command_args, *popen_args,
  File "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/killable_subprocess.py", line 261, in check_call
    raise subprocess.CalledProcessError(process.returncode, cmd)
subprocess.CalledProcessError: Command '['docker', 'build', '-f', 'Dockerfile', '.', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8', '-t', '375c688203014d1cb3273695ae3932f9.azurecr.io/azureml/azureml_a4860d653c7759f425719b19ccbe9ff8:1']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "script.py", line 162, in <module>
    docker_utilities._docker_build_or_error(
  File "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py", line 156, in _docker_build_or_error
    _write_error_and_exit(error_msg, error_file_path=error_file_path)
  File "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py", line 217, in _write_error_and_exit
    sys.exit(1)
SystemExit: 1


system_logs/cs_capability/cs-capability.log : 
----
INFO 2026-02-04 02:58:17,018 initializer.py:55 [1] - job_telemetry_init {'artifact_type': 'installed', 'branch': '2385e2bab64', 'build_time': '2026-01-23 10:33:52.893301', 'ci_name': 'CommonRuntime-RuntimeTeam-Linux-Prod-Build', 'ci_number': '20260123.1', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,019 tracer.py:31 [1] - Setting up tracer {'branch': '2385e2bab64', 'commit': '2385e2b', 'component_name': 'cs-capability', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'telemetry_config': '{"collector": {"receiver": null, "exporter": {"appinsights": {"instrumentation_key": "4b76bc22-b2b3-4c36-9f73-ea1500bfc9fb", "endpoint_suffix": "services.visualstudio.com", "ingestion_endpoint": null, "aad_audience": null}, "jaeger": null, "prometheus": null, "timeout_millis": null, "level": null}}, "logger": {"console": {"sink": "stdout", "level": "info", "enabled": true, "ansi": false}, "appinsights": {"instrumentation_key": "4b76bc22-b2b3-4c36-9f73-ea1500bfc9fb", "level": "info", "enabled": true, "endpoint_suffix": "services.visualstudio.com", "ingestion_endpoint": null, "aad_audience": null}, "file": {"extension": "log", "level": "info", "enabled": true}}, "node_rank": null, "node_id": "tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d", "disable_sensitive_scrub": null, "attempt_id": null}', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,033 tracer.py:57 [1] - Setting up appinsights exporter {'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,036 initializer.py:65 [1] - Tracer initialized {'artifact_type': 'installed', 'branch': '2385e2bab64', 'build_time': '2026-01-23 10:33:52.893301', 'ci_name': 'CommonRuntime-RuntimeTeam-Linux-Prod-Build', 'ci_number': '20260123.1', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,036 tracer.py:127 [1] - [tracer][get_ambient_parent_ctx] parent ctx: {'current-span-69e3fc80-3954-444c-b80d-910e24895b47': NonRecordingSpan(SpanContext(trace_id=0xf8be74c3c6663ee1b3e617291feee9f2, span_id=0x78fd1da3e7c47b99, trace_flags=0x01, trace_state=[], is_remote=True))} {'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,041 service.py:317 [1] - [start_services]: starting service {'SpanId': '89a0eaca2862189f', 'TraceFlags': '01', 'TraceId': 'f8be74c3c6663ee1b3e617291feee9f2', 'address': 'unix:///mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'max_workers': 2, 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '89a0eaca2862189f', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'f8be74c3c6663ee1b3e617291feee9f2', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,050 service.py:349 [1] - [start_services]: waiting on end_event {'SpanId': '89a0eaca2862189f', 'TraceFlags': '01', 'TraceId': 'f8be74c3c6663ee1b3e617291feee9f2', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'max_attempts': 3, 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'retry_delay_secs': 5, 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'server_start_attempt': 0, 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '89a0eaca2862189f', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': 'f8be74c3c6663ee1b3e617291feee9f2', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,138 service.py:56 [1] - [start] Extracting Snapshots: None {'SpanId': '47cdafccf09a214b', 'TraceFlags': '01', 'TraceId': '7cc24417a4a7af36c1adfe6dca45564b', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '47cdafccf09a214b', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '7cc24417a4a7af36c1adfe6dca45564b', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,141 service.py:86 [1] - [start] Entering context managers {'SpanId': '47cdafccf09a214b', 'TraceFlags': '01', 'TraceId': '7cc24417a4a7af36c1adfe6dca45564b', 'branch': '2385e2bab64', 'commit': '2385e2b', 'context_managers': [], 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '47cdafccf09a214b', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '7cc24417a4a7af36c1adfe6dca45564b', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:17,142 context_manager.py:71 [1] - enter_contexts {'SpanId': '47cdafccf09a214b', 'TraceFlags': '01', 'TraceId': '7cc24417a4a7af36c1adfe6dca45564b', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '47cdafccf09a214b', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'success': True, 'traceId': '7cc24417a4a7af36c1adfe6dca45564b', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:21,056 service.py:125 [1] - [end] logging run finalizing {'SpanId': '6ae4bff3fe990d12', 'TraceFlags': '01', 'TraceId': '351af8e06ed88ebb397d04f5967864b4', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '6ae4bff3fe990d12', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '351af8e06ed88ebb397d04f5967864b4', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:21,179 context_manager.py:93 [1] - exit_contexts {'SpanId': '6ae4bff3fe990d12', 'TraceFlags': '01', 'TraceId': '351af8e06ed88ebb397d04f5967864b4', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '6ae4bff3fe990d12', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'traceId': '351af8e06ed88ebb397d04f5967864b4', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}
INFO 2026-02-04 02:58:21,180 context_manager.py:100 [1] - exit_contexts {'SpanId': '6ae4bff3fe990d12', 'TraceFlags': '01', 'TraceId': '351af8e06ed88ebb397d04f5967864b4', 'branch': '2385e2bab64', 'commit': '2385e2b', 'correlation_id': 'imgbldrun_b23b17c', 'experiment_name': 'prepare_image', 'node_id': 'tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d', 'node_rank': 'None', 'os': 'linux', 'resource_group': '8ai-final-team6', 'root_run_id': 'imgbldrun_b23b17c', 'run_id': 'imgbldrun_b23b17c', 'session_id': 'd6cf6ea3-31e0-47cb-bc54-46d9774d0e41', 'source': 'common_runtime.cs-capability', 'spanId': '6ae4bff3fe990d12', 'subscription_id': 'b850d62a-25fe-4d3a-9697-ea40449528a9', 'success': True, 'traceId': '351af8e06ed88ebb397d04f5967864b4', 'version': '0.0.1.20260123.1', 'workspace_location': 'koreacentral', 'workspace_name': 'vision'}

system_logs/hosttools_capability/hosttools-capability.log : 
----
2026-02-04T02:58:14.852280Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:31:11.198476
2026-02-04T02:58:14.852494Z  INFO hosttools-capability::do_main: hosttools_capability::resource_limit: Current limit for number of open file: soft=262144, hard=262144 soft_limit=262144 hard_limit=262144
2026-02-04T02:58:14.852632Z  INFO hosttools-capability::do_main: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:58:14.852698Z  INFO hosttools-capability::do_main: hosttools_capability: Hosttools cap config ht_cap_config={"dirs":[{"relative_path":"azureml-logs","environment_name":"AZUREML_CR_HT_CAP_azureml_logs_PATH","streamable":true},{"relative_path":"user_logs","environment_name":"AZUREML_CR_HT_CAP_user_logs_PATH","streamable":true},{"relative_path":"outputs","environment_name":"AZUREML_CR_HT_CAP_outputs_PATH","streamable":false},{"relative_path":"logs","environment_name":"AZUREML_CR_HT_CAP_logs_PATH","streamable":true}],"metrics":{"enabled":false,"polling_interval_sec":30,"send_to_history_interval_sec":60},"use_block_blob_in_blob_streamer":true,"log_filtering_policy":null,"disable_system_log_blob_streaming":false}
2026-02-04T02:58:14.852881Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: cr_core::config_parser: Failed to get distributed config from env exception=GetEnvVarFailed("AZUREML_CR_DISTRIBUTED_CONFIG")
2026-02-04T02:58:14.853150Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: hosttools_capability::config_parser: appinsights instrumentation key is set in telemetry config
2026-02-04T02:58:14.853301Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config:hosttools-capability.add_cert_env_vars_from_file{path="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/cert_info.txt"}: hosttools_capability::config_parser: Cert envs from cert_file was successful
2026-02-04T02:58:14.853358Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config:hosttools-capability.add_cert_env_vars_from_file{path="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/cert_info.txt"}: hosttools_capability::config_parser: close time.busy=137µs time.idle=14.7µs
2026-02-04T02:58:14.853406Z  INFO hosttools-capability::do_main:hosttools-capability.parse_config: hosttools_capability::config_parser: close time.busy=636µs time.idle=15.1µs
2026-02-04T02:58:14.854208Z  INFO hosttools-capability::do_main:hosttools-capability.start_hosttools{task="outputManager"}: grpc_utils::utils: child spawned child=Child { child: Child(ChildDropGuard { inner: Child { pid: 13 }, kill_on_drop: false }), stdin: None, stdout: Some(ChildStdout { inner: PollEvented { io: Some(Pipe { fd: File { fd: 10, path: "pipe:[53962]", read: true, write: false } }) } }), stderr: Some(ChildStderr { inner: PollEvented { io: Some(Pipe { fd: File { fd: 12, path: "pipe:[53963]", read: true, write: false } }) } }) }
2026-02-04T02:58:14.854446Z  INFO hosttools-capability::do_main:hosttools-capability.start_hosttools{task="outputManager"}: hosttools_capability::hosttools: close time.busy=842µs time.idle=4.90µs
2026-02-04T02:58:14.859781Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Error opening env file:  open LS_root/jobs/config/.dynamic_config: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Error opening env file:  open LS_root/jobs/config/.dynamic_config: no such file or directory"
2026-02-04T02:58:14.860757Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Scrubber is not initialize, System Log will be disabled command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Scrubber is not initialize, System Log will be disabled"
2026-02-04T02:58:14.860848Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Starting App Insight Logger for task:  outputManager command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Starting App Insight Logger for task:  outputManager"
2026-02-04T02:58:14.860883Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Version:  Branch:  Commit:  command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Version:  Branch:  Commit: "
2026-02-04T02:58:14.860908Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Is launched from common runtime?: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Is launched from common runtime?: true"
2026-02-04T02:58:14.860932Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Soft rlimit is 262144 command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Soft rlimit is 262144"
2026-02-04T02:58:14.860960Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Setting soft rlimit to 1048576 command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Setting soft rlimit to 1048576"
2026-02-04T02:58:14.860984Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 rlimit is now {262144 262144} command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 rlimit is now {262144 262144}"
2026-02-04T02:58:14.861009Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{"Id":"azureml-logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs","Streamable":true},{"Id":"user_logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs","Streamable":true},{"Id":"outputs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs","Streamable":false},{"Id":"logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs","Streamable":true},{"Id":"lifecycler","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log","Streamable":true},{"Id":"hosttools_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"secrets_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"snapshot_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"cs_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"metrics_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log","Streamable":true}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{\"Id\":\"azureml-logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs\",\"Streamable\":true},{\"Id\":\"user_logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs\",\"Streamable\":true},{\"Id\":\"outputs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs\",\"Streamable\":false},{\"Id\":\"logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs\",\"Streamable\":true},{\"Id\":\"lifecycler\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"hosttools_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"secrets_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"snapshot_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"cs_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"metrics_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log\",\"Streamable\":true}]"
2026-02-04T02:58:14.861070Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{"Id":"azureml-logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs","Streamable":true},{"Id":"user_logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs","Streamable":true},{"Id":"outputs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs","Streamable":false},{"Id":"logs","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs","Streamable":true},{"Id":"lifecycler","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log","Streamable":true},{"Id":"hosttools_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"secrets_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"snapshot_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"cs_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log","Streamable":true},{"Id":"metrics_capability","Path":"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log","Streamable":true}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 AZUREML_CR_HT_OUTPUT_DIRECTORIES: [{\"Id\":\"azureml-logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs\",\"Streamable\":true},{\"Id\":\"user_logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs\",\"Streamable\":true},{\"Id\":\"outputs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs\",\"Streamable\":false},{\"Id\":\"logs\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs\",\"Streamable\":true},{\"Id\":\"lifecycler\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"hosttools_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"secrets_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"snapshot_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"cs_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log\",\"Streamable\":true},{\"Id\":\"metrics_capability\",\"Path\":\"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log\",\"Streamable\":true}]"
2026-02-04T02:58:14.861128Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 AZUREML_CR_HT_LOG_FILTERING_POLICY:  command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 AZUREML_CR_HT_LOG_FILTERING_POLICY: "
2026-02-04T02:58:14.861177Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 AZUREML_CR_HT_LOG_FILTERING_POLICY:  command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 AZUREML_CR_HT_LOG_FILTERING_POLICY: "
2026-02-04T02:58:14.861229Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Failed to Parse Bool on commons.IsDedicatedCompute command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Failed to Parse Bool on commons.IsDedicatedCompute"
2026-02-04T02:58:14.861261Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Skip watching job temp full log cache dir as current output manager is launched by common runtime command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Skip watching job temp full log cache dir as current output manager is launched by common runtime"
2026-02-04T02:58:14.861286Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs, streamable: false command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs, streamable: false"
2026-02-04T02:58:14.861320Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs"
2026-02-04T02:58:14.864884Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.864975Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log"
2026-02-04T02:58:14.865001Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:58:14.865033Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs, streamable: true"
2026-02-04T02:58:14.865069Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs"
2026-02-04T02:58:14.865092Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.865113Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log"
2026-02-04T02:58:14.865152Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log does not exist"
2026-02-04T02:58:14.865175Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.865208Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log"
2026-02-04T02:58:14.865231Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log"
2026-02-04T02:58:14.865273Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Requesting POST: [{system_logs/hosttools_capability/hosttools-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Requesting POST: [{system_logs/hosttools_capability/hosttools-capability.log}]"
2026-02-04T02:58:14.865317Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:14.865341Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.865392Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log"
2026-02-04T02:58:14.865415Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:58:14.867623Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.868407Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log"
2026-02-04T02:58:14.868686Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:58:14.869490Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log, streamable: true"
2026-02-04T02:58:14.869787Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log"
2026-02-04T02:58:14.870089Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log does not exist"
2026-02-04T02:58:14.870343Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory LS_root/jobs/wd/.tmp, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory LS_root/jobs/wd/.tmp, streamable: true"
2026-02-04T02:58:14.870616Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory LS_root/jobs/wd/.tmp command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory LS_root/jobs/wd/.tmp"
2026-02-04T02:58:14.870864Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 file LS_root/jobs/wd/.tmp does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 file LS_root/jobs/wd/.tmp does not exist"
2026-02-04T02:58:14.871133Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Skipping disk check due to err: Ephemeral Disk path not set by Batch. command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Skipping disk check due to err: Ephemeral Disk path not set by Batch."
2026-02-04T02:58:14.871411Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs, streamable: true"
2026-02-04T02:58:14.871661Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs"
2026-02-04T02:58:14.871934Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs, streamable: true command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 start watching directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs, streamable: true"
2026-02-04T02:58:14.872138Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 We have to refresh the dir one more time before we stop the watch Directory /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs"
2026-02-04T02:58:14.874130Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Was not able to read from token file:  open LS_root/jobs/config/.amlcompute.amltoken: no such file or directory"
2026-02-04T02:58:14.876512Z  INFO hosttools-capability::do_main:hosttools-capability.patch_azsecpack_resource_files_on_host: hosttools_capability::patch_azsecpack: close time.busy=22.0ms time.idle=5.40µs
2026-02-04T02:58:14.876566Z  INFO hosttools-capability::do_main: hosttools_capability: Starting gRPC server at server_addr=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0
2026-02-04T02:58:14.876617Z  INFO hosttools-capability::do_main: hosttools_capability::service: serving capability service at address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0
2026-02-04T02:58:14.876846Z  INFO hosttools-capability::do_main:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:14.948192Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Decrypt using CBCDecrypter"
2026-02-04T02:58:14.948343Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:14 Initial token expires at  2026-02-25 04:33:59 +0000 UTC command="/usr/local/bin/hosttools" line="2026/02/04 02:58:14 Initial token expires at  2026-02-25 04:33:59 +0000 UTC"
2026-02-04T02:58:15.875969Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:15 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:15 Decrypt using CBCDecrypter"
2026-02-04T02:58:16.029048Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:16 Succesfully POST artifacts: [{system_logs/hosttools_capability/hosttools-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:16 Succesfully POST artifacts: [{system_logs/hosttools_capability/hosttools-capability.log}]"
2026-02-04T02:58:17.057696Z  INFO hosttools_capability::health: Watched child process is alive
2026-02-04T02:58:17.067032Z  INFO hosttools-capability.start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:58:17.067132Z  INFO hosttools-capability.start: hosttools_capability::capability_service: close time.busy=111µs time.idle=23.3µs
2026-02-04T02:58:17.068348Z  INFO hosttools_capability::health: Watched child process is alive
2026-02-04T02:58:19.860859Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:19 Not exporting to RunHistory as the exporter is either stopped or there is no data.Stopped: false; OriginalData: 6; FilteredData: 0. command="/usr/local/bin/hosttools" line="2026/02/04 02:58:19 Not exporting to RunHistory as the exporter is either stopped or there is no data.Stopped: false; OriginalData: 6; FilteredData: 0."
2026-02-04T02:58:21.055342Z  INFO hosttools-capability.end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:58:21.055453Z  INFO hosttools-capability.end: hosttools_capability::capability_service: Flush and shutdown output manager (end)
2026-02-04T02:58:21.055501Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: Signaling output_manager to flush logs, then terminating after: None flush_timeout=None
2026-02-04T02:58:21.055560Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: send SIGTERM to outputManager child=Child { child: Child(ChildDropGuard { inner: Child { pid: 13 }, kill_on_drop: false }), stdin: None, stdout: None, stderr: None }
2026-02-04T02:58:21.055654Z  INFO hosttools-capability.end:hosttools-capability.flush_and_shutdown_output_manager{flush_timeout_override_s=None}: hosttools_capability::capability_service: waiting for outputManager termination child=Child { child: Child(ChildDropGuard { inner: Child { pid: 13 }, kill_on_drop: false }), stdin: None, stdout: None, stderr: None } timeout_duration=None
2026-02-04T02:58:21.056136Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Received termination signal to shut down output manager. command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Received termination signal to shut down output manager."
2026-02-04T02:58:21.056364Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Exiting filewatcher for streamable file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log. No changes after termination signal. command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Exiting filewatcher for streamable file /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log/hosttools-capability.log. No changes after termination signal."
2026-02-04T02:58:21.056561Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Streamer terminated for system_logs/hosttools_capability/hosttools-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Streamer terminated for system_logs/hosttools_capability/hosttools-capability.log"
2026-02-04T02:58:21.056871Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log/cs-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log/cs-capability.log"
2026-02-04T02:58:21.056939Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : cs-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : cs-capability.log"
2026-02-04T02:58:21.056990Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/cs-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.057018Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{system_logs/cs_capability/cs-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{system_logs/cs_capability/cs-capability.log}]"
2026-02-04T02:58:21.057057Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.062848Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log/secrets-capability.log"
2026-02-04T02:58:21.062903Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : secrets-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : secrets-capability.log"
2026-02-04T02:58:21.062937Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log/snapshot-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log/snapshot-capability.log"
2026-02-04T02:58:21.062960Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : snapshot-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : snapshot-capability.log"
2026-02-04T02:58:21.062989Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/secrets-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.063023Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/logs one more time with 3 s!"
2026-02-04T02:58:21.063047Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/snapshot-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.063067Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{system_logs/secrets_capability/secrets-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{system_logs/secrets_capability/secrets-capability.log}]"
2026-02-04T02:58:21.063091Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{system_logs/snapshot_capability/snapshot-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{system_logs/snapshot_capability/snapshot-capability.log}]"
2026-02-04T02:58:21.063132Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.063157Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.063181Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/hosttools-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.063215Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs/std_log.txt command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs/std_log.txt"
2026-02-04T02:58:21.063236Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : std_log.txt command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : std_log.txt"
2026-02-04T02:58:21.063268Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/user_logs one more time with 3 s!"
2026-02-04T02:58:21.063296Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{user_logs/std_log.txt}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{user_logs/std_log.txt}]"
2026-02-04T02:58:21.063319Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.068358Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"
2026-02-04T02:58:21.068959Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log/execution-wrapper.log"
2026-02-04T02:58:21.069213Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log/lifecycler.log"
2026-02-04T02:58:21.069479Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : execution-wrapper.log,lifecycler.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : execution-wrapper.log,lifecycler.log"
2026-02-04T02:58:21.071920Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.072067Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{system_logs/lifecycler/execution-wrapper.log} {system_logs/lifecycler/lifecycler.log}]"
2026-02-04T02:58:21.072200Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.072443Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"
2026-02-04T02:58:21.072486Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/outputs one more time with 3 s!"
2026-02-04T02:58:21.072626Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/azureml-logs one more time with 3 s!"
2026-02-04T02:58:21.072677Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 file LS_root/jobs/wd/.tmp does not exist command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 file LS_root/jobs/wd/.tmp does not exist"
2026-02-04T02:58:21.072819Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir LS_root/jobs/wd/.tmp one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir LS_root/jobs/wd/.tmp one more time with 3 s!"
2026-02-04T02:58:21.072883Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 New file detected: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log/metrics-capability.log"
2026-02-04T02:58:21.073057Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 After termination signal, we find the list of new file : metrics-capability.log command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 After termination signal, we find the list of new file : metrics-capability.log"
2026-02-04T02:58:21.073095Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log one more time with 3 s! command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 We need to refresh the dir /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/metrics-capability/wd/.azureml_cr_log one more time with 3 s!"
2026-02-04T02:58:21.073120Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Requesting POST: [{system_logs/metrics_capability/metrics-capability.log}] command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Requesting POST: [{system_logs/metrics_capability/metrics-capability.log}]"
2026-02-04T02:58:21.073172Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Attempt 1 of http call to https://koreacentral.api.azureml.ms/artifact/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/artifacts/batch/metadata/ExperimentRun/dcid.imgbldrun_b23b17c"
2026-02-04T02:58:21.073227Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"
2026-02-04T02:58:21.074072Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"
2026-02-04T02:58:21.082561Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"
2026-02-04T02:58:21.082630Z  INFO grpc_utils::utils: stderr: 2026/02/04 02:58:21 Decrypt using CBCDecrypter command="/usr/local/bin/hosttools" line="2026/02/04 02:58:21 Decrypt using CBCDecrypter"

system_logs/lifecycler/execution-wrapper.log : 
----
2026-02-04T02:58:15.666141Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:34:45.198956
2026-02-04T02:58:15.667636Z  INFO run_execution_wrapper: execution_wrapper: Successfully dumped bootstrapping environment to file
2026-02-04T02:58:15.667682Z  INFO run_execution_wrapper: execution_wrapper: Enable std log streaming is not specified in executor configuration, default to not stream logs to stdout and stderr
2026-02-04T02:58:15.667707Z  INFO run_execution_wrapper: execution_wrapper: Enable termination signal handling is not specified in executor configuration, default to ignore termination signals
2026-02-04T02:58:15.667737Z  INFO run_execution_wrapper: execution_wrapper: Executor config not provided, certificates will not be updated.
2026-02-04T02:58:15.667794Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}: execution_wrapper::service: serving execution service at executor_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0
2026-02-04T02:58:15.667946Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:58:15.668004Z  INFO run_execution_wrapper:execution-wrapper::run_service{path_mapping_kind=None error_pattern_json_files_post_execution=None error_pattern_json_file_mid_execution=None enable_std_log_streaming=false skip_user_log_file_generation=false enable_termination_signal_handling=false}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:17.350445Z  INFO ExecutionServicer::run: grpc_utils::server: Got grpc request request_name="run" remote_addr=None
2026-02-04T02:58:17.350686Z  INFO ExecutionServicer::run: execution_wrapper::service: file /opt/microsoft/singularity/unasignal/StopUserNode exists: false path=/opt/microsoft/singularity/unasignal/StopUserNode
2026-02-04T02:58:17.350761Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: spawn_execution request id="b732e841-9a12-4956-84d4-9cb3dbb22dca" client_address=Some("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0")
2026-02-04T02:58:17.350882Z  WARN ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Skip injecting legacy env vars, distributed config is None, setting only the defaults
2026-02-04T02:58:17.350945Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Injecting AZ_BATCHAI_JOB_WORK_DIR=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd working_dir="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd"
2026-02-04T02:58:17.350984Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: Injecting AZUREML_PROCESS_NAME=main as default
2026-02-04T02:58:17.351117Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:get_gpu_count: execution_wrapper::common: Get ComputeContext from env success compute_context=ComputeContext { cluster_name: "990b4522-de30-451c-8db0-8671300409ca", node_id: Literal("tvmps_a1311380332c59dab869916485860205d55f442988cd5fa9d0fc507f958a2a40_d"), vm_id: Some("e2072481-2a18-4575-808f-7b0a5df232ac"), run_attempt_count: 1, gpu_count: Some(0), vm_size: Some("STANDARD_D4_V3"), readable_cluster_name: Some("Serverless"), vm_priority: Some(Dedicated), use_vnet_or_private_link: false }
2026-02-04T02:58:17.351191Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:get_gpu_count: execution_wrapper::common: close time.busy=142µs time.idle=8.00µs
2026-02-04T02:58:17.351225Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_CR_EXECUTOR_CONFIG for spawned process
2026-02-04T02:58:17.351267Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Env var AZUREML_CR_DISTRIBUTED_CONFIG is empty for current process
2026-02-04T02:58:17.351298Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_SERVICE_ENDPOINT for spawned process
2026-02-04T02:58:17.351326Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_SERVICE_CERT_ENDPOINT for spawned process
2026-02-04T02:58:17.351390Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_DISCOVERY_SERVICE_ENDPOINT for spawned process
2026-02-04T02:58:17.351447Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Env var AZUREML_DEV_URL_MLFLOW is empty for current process
2026-02-04T02:58:17.351470Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: Updated env AZUREML_RUN_HISTORY_SERVICE_ENDPOINT for spawned process
2026-02-04T02:58:17.351498Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars:override_dc_env_vars: execution_wrapper::dc_env_vars: close time.busy=274µs time.idle=3.10µs
2026-02-04T02:58:17.351523Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:inject_legacy_env_vars: execution_wrapper::legacy_env_vars: close time.busy=644µs time.idle=10.0µs
2026-02-04T02:58:17.351549Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::infiniband_utils: Is InfiniBand device present: false infiniband_device_path="/dev/infiniband/uverbs0"
2026-02-04T02:58:17.351595Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: Spawning execution
2026-02-04T02:58:17.351998Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::parse_commands: execution_wrapper::execution: close time.busy=94.0µs time.idle=3.90µs
2026-02-04T02:58:17.352507Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: Spawning target process
2026-02-04T02:58:17.353998Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: execution process spawned pid=12
2026-02-04T02:58:17.354414Z  INFO execution_wrapper::execution: start waiting for processes execution to complete num_processes=1
2026-02-04T02:58:17.354549Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from PendingExecution to PendingExecution
2026-02-04T02:58:20.037737Z ERROR Execution::wait_for_completion: execution_wrapper::execution::process_manager: Failed blocking user process detected, process name: python, process pid: 12, code: Some(1) success_return_code=Zero { additional_codes: [] } code=Some(1)
2026-02-04T02:58:20.037888Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from PendingExecution to FailureDetected
2026-02-04T02:58:20.037959Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: [FailureDetected] Successfully started sleeping task
2026-02-04T02:58:20.038024Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from FailureDetected to ExecutionCompleted
2026-02-04T02:58:21.039434Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Start collecting process exit statuses
2026-02-04T02:58:21.039525Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Successfully collected the exit status of user process pid=12 process_name=python killed_by_process_manager=false
2026-02-04T02:58:21.039581Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Process manager successfully collected the exit statuses of all user processes on current node
2026-02-04T02:58:21.039622Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: ProcessManagerExecution state changing from ExecutionCompleted to CleanupStreamingTasks
2026-02-04T02:58:21.039666Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Start cleaning up execution log streaming tasks
2026-02-04T02:58:21.039695Z  INFO Execution::wait_for_completion: execution_wrapper::execution::process_manager: Process manager successfully aborted all streaming tasks for current execution
2026-02-04T02:58:21.039752Z  INFO Execution::wait_for_completion: execution_wrapper::execution: The stderr path is set, starting reading stderr from file. file_path="user_logs/std_log.txt"
2026-02-04T02:58:21.040045Z  INFO Execution::wait_for_completion: execution_wrapper::execution: Gathered execution result for rank 0 process_rank=0 exit_code=1 stderr_path=Some("user_logs/std_log.txt")
2026-02-04T02:58:21.040096Z  INFO Execution::wait_for_completion: execution_wrapper::execution: [wait_for_completion] execution process completed.
2026-02-04T02:58:21.046887Z  WARN Execution::wait_for_completion: execution_wrapper::detect_error: [Execution-wrapper::ErrorDetector] Failed to search OOM error from dmesg logs exception=General("non-zero exit code Some(1) from sh: ")
2026-02-04T02:58:21.047290Z  WARN Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:21.047357Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service: execution_wrapper::service: connecting to callback endpoint: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0 client_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0
2026-02-04T02:58:21.047539Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 600s }
2026-02-04T02:58:21.047868Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0")
2026-02-04T02:58:21.047939Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service:connect: grpc_utils::endpoint::connect: close time.busy=348µs time.idle=58.8µs
2026-02-04T02:58:21.048000Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution:execution-wrapper::connect_to_callback_service: execution_wrapper::service: close time.busy=595µs time.idle=71.9µs
2026-02-04T02:58:21.054163Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: execution_wrapper::service: Completed execution id=b732e841-9a12-4956-84d4-9cb3dbb22dca
2026-02-04T02:58:21.054239Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit:ExecutionFinalizer::complete_execution: execution_wrapper::service: close time.busy=870µs time.idle=6.09ms
2026-02-04T02:58:21.054272Z  INFO Execution::wait_for_completion:ExecutionFinalizer::on_exit: execution_wrapper::service: close time.busy=876µs time.idle=6.13ms
2026-02-04T02:58:21.054296Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}:Execution::spawn{wait_execution_completion=false}: execution_wrapper::execution: close time.busy=1.84ms time.idle=3.70s
2026-02-04T02:58:21.054327Z  INFO ExecutionServicer::run:ExecutionServicer::spawn_execution{wait_execution_completion=false}: execution_wrapper::service: close time.busy=3.25ms time.idle=3.70s
2026-02-04T02:58:21.054352Z  INFO ExecutionServicer::run: execution_wrapper::service: close time.busy=3.59ms time.idle=3.70s
2026-02-04T02:58:21.054387Z  INFO Execution::wait_for_completion: execution_wrapper::execution: close time.busy=2.88ms time.idle=3.70s
2026-02-04T02:58:21.054417Z  INFO execution_wrapper::execution: process execution completed

system_logs/lifecycler/lifecycler.log : 
----
2026-02-04T02:58:15.629780Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:34:38.445489
2026-02-04T02:58:15.630483Z  INFO load_config_from_env: lifecycler::config: Resolved grpc addresses lifecycler_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0 executor_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0
2026-02-04T02:58:15.631389Z  INFO load_config_from_env:load_capability_addresses_from_env{capability_endpoints_from_config={"CS_CAPABILITY": CapabilityEndpoint { name: "CS_CAPABILITY", address: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0", type: Service }, "HOSTTOOLS_CAPABILITY": CapabilityEndpoint { name: "HOSTTOOLS_CAPABILITY", address: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0", type: Service }, "METRICS_CAPABILITY": CapabilityEndpoint { name: "METRICS_CAPABILITY", address: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0", type: Service }, "SECRETS_CAPABILITY": CapabilityEndpoint { name: "SECRETS_CAPABILITY", address: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/secrets-capability:0", type: Operation }, "SNAPSHOT_CAPABILITY": CapabilityEndpoint { name: "SNAPSHOT_CAPABILITY", address: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0", type: Service }}}: lifecycler::config: close time.busy=407µs time.idle=20.8µs
2026-02-04T02:58:15.631701Z  INFO load_config_from_env: lifecycler::config: close time.busy=1.54ms time.idle=25.2µs
2026-02-04T02:58:15.631905Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: lifecycler::lifecycle: distributed config is not specified, skip setting up distributed barrier
2026-02-04T02:58:15.632643Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: lifecycler::lifecycle: Trying to configure lifecycler to ignore termination signals
2026-02-04T02:58:15.634734Z  INFO Lifecycler::run_service{lifecycler_abort_state_writer=Some(LifecyclerAbortStateWriter { lifecycler_wd: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd" })}: lifecycler::service: serving lifecycle service address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0
2026-02-04T02:58:15.635135Z  INFO Lifecycler::run_service{lifecycler_abort_state_writer=Some(LifecyclerAbortStateWriter { lifecycler_wd: "/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/cap/lifecycler/wd" })}:serve_more: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:15.635416Z  INFO run_lifecycler:run_service_and_step_through_lifecycle: cr_core: Successfully configured current process to ignore termination signals
2026-02-04T02:58:15.635645Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.052742Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0")
2026-02-04T02:58:17.052925Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=10.2ms time.idle=1.41s
2026-02-04T02:58:17.053185Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.053575Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/cs-capability:0")
2026-02-04T02:58:17.053655Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=405µs time.idle=73.0µs
2026-02-04T02:58:17.053703Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: CS_CAPABILITY service_name=CS_CAPABILITY timeout=30s
2026-02-04T02:58:17.053764Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.055501Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: CS_CAPABILITY service_name=CS_CAPABILITY health_status=1
2026-02-04T02:58:17.055566Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=CS_CAPABILITY
2026-02-04T02:58:17.055593Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=330µs time.idle=1.57ms
2026-02-04T02:58:17.055782Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.056124Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0")
2026-02-04T02:58:17.056203Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=311µs time.idle=114µs
2026-02-04T02:58:17.056371Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.056796Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/hosttools-capability:0")
2026-02-04T02:58:17.057005Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=413µs time.idle=226µs
2026-02-04T02:58:17.057048Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: HOSTTOOLS_CAPABILITY service_name=HOSTTOOLS_CAPABILITY timeout=30s
2026-02-04T02:58:17.057104Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.058174Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: HOSTTOOLS_CAPABILITY service_name=HOSTTOOLS_CAPABILITY health_status=1
2026-02-04T02:58:17.058243Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=HOSTTOOLS_CAPABILITY
2026-02-04T02:58:17.058289Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=436µs time.idle=810µs
2026-02-04T02:58:17.058448Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.058745Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0")
2026-02-04T02:58:17.058814Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=250µs time.idle=120µs
2026-02-04T02:58:17.058967Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.061245Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0")
2026-02-04T02:58:17.061358Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=306µs time.idle=2.09ms
2026-02-04T02:58:17.061443Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: METRICS_CAPABILITY service_name=METRICS_CAPABILITY timeout=30s
2026-02-04T02:58:17.061548Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.062406Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: METRICS_CAPABILITY service_name=METRICS_CAPABILITY health_status=1
2026-02-04T02:58:17.062475Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=METRICS_CAPABILITY
2026-02-04T02:58:17.062536Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=354µs time.idle=745µs
2026-02-04T02:58:17.062662Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/secrets-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.063060Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/secrets-capability:0")
2026-02-04T02:58:17.063118Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=354µs time.idle=106µs
2026-02-04T02:58:17.063388Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.064025Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0")
2026-02-04T02:58:17.064108Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=268µs time.idle=456µs
2026-02-04T02:58:17.064336Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.064774Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0")
2026-02-04T02:58:17.064864Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:connect: grpc_utils::endpoint::connect: close time.busy=374µs time.idle=158µs
2026-02-04T02:58:17.064908Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: SNAPSHOT_CAPABILITY service_name=SNAPSHOT_CAPABILITY timeout=30s
2026-02-04T02:58:17.064979Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.065760Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_client: Health status for service: SNAPSHOT_CAPABILITY service_name=SNAPSHOT_CAPABILITY health_status=1
2026-02-04T02:58:17.065904Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=SNAPSHOT_CAPABILITY
2026-02-04T02:58:17.065935Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=342µs time.idle=691µs
2026-02-04T02:58:17.065994Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_capabilities: lifecycler::lifecycle: close time.busy=16.9ms time.idle=1.41s
2026-02-04T02:58:17.066044Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066055Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066106Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066123Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066159Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066178Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066187Z  WARN grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066301Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.066388Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.068124Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=HOSTTOOLS_CAPABILITY
2026-02-04T02:58:17.068622Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="HOSTTOOLS_CAPABILITY"}: lifecycler::capability_client: close time.busy=635µs time.idle=1.87ms
2026-02-04T02:58:17.068698Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=SECRETS_CAPABILITY
2026-02-04T02:58:17.068768Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SECRETS_CAPABILITY"}: lifecycler::capability_client: close time.busy=194µs time.idle=2.28ms
2026-02-04T02:58:17.069507Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=METRICS_CAPABILITY
2026-02-04T02:58:17.069666Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="METRICS_CAPABILITY"}: lifecycler::capability_client: close time.busy=309µs time.idle=3.19ms
2026-02-04T02:58:17.143391Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=CS_CAPABILITY
2026-02-04T02:58:17.143501Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="CS_CAPABILITY"}: lifecycler::capability_client: close time.busy=251µs time.idle=77.2ms
2026-02-04T02:58:17.343390Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: Received success code for start cap_name=SNAPSHOT_CAPABILITY
2026-02-04T02:58:17.343525Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities:start{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: close time.busy=274µs time.idle=277ms
2026-02-04T02:58:17.343606Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:start_capabilities: lifecycler::lifecycle: close time.busy=1.95ms time.idle=276ms
2026-02-04T02:58:17.343760Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.345296Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: lifecycler::capability_client: Received success code for teardown cap_name=SECRETS_CAPABILITY
2026-02-04T02:58:17.345393Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}:teardown{name="SECRETS_CAPABILITY" job_result_f=JobResult { job_status: Succeeded, error: None }}: lifecycler::capability_client: close time.busy=626µs time.idle=1.02ms
2026-02-04T02:58:17.345437Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:exit_capabilities{cap_type=Operation job_result=JobResult { job_status: Succeeded, error: None }}: lifecycler::lifecycle: close time.busy=433µs time.idle=1.29ms
2026-02-04T02:58:17.345453Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle: lifecycler::lifecycle: exited operation caps: true
2026-02-04T02:58:17.345750Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.346284Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0")
2026-02-04T02:58:17.346373Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=445µs time.idle=183µs
2026-02-04T02:58:17.346441Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=744µs time.idle=179µs
2026-02-04T02:58:17.346603Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.347142Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0")
2026-02-04T02:58:17.347242Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect:connect: grpc_utils::endpoint::connect: close time.busy=441µs time.idle=202µs
2026-02-04T02:58:17.347280Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: lifecycler::executor_client: close time.busy=611µs time.idle=199µs
2026-02-04T02:58:17.347439Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Connecting to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0") retry=FixedIntervalRetry { attempt_timeout_millis: 50, retry_delay_millis: 10, max_duration: 7200s }
2026-02-04T02:58:17.347761Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: Successfully connected to gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/executor:0")
2026-02-04T02:58:17.347922Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:connect: grpc_utils::endpoint::connect: close time.busy=390µs time.idle=96.7µs
2026-02-04T02:58:17.347962Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: Waiting for service to become healthy: Executor service_name=Executor timeout=30s
2026-02-04T02:58:17.348005Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.348903Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_client: Health status for service: Executor service_name=Executor health_status=1
2026-02-04T02:58:17.348993Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: Service has become healthy service_name=Executor
2026-02-04T02:58:17.349033Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor:wait_for_service_healthy: lifecycler::health_monitor: close time.busy=324µs time.idle=753µs
2026-02-04T02:58:17.349062Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_executor: lifecycler::lifecycle: close time.busy=2.35ms time.idle=1.21ms
2026-02-04T02:58:17.349095Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:connect_lifecyclers{lifecycler_addresses=None}: lifecycler::lifecycle: close time.busy=1.40µs time.idle=6.10µs
2026-02-04T02:58:17.349214Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: entering phase rank=None phase=0 is_leader=true entered_phases=false
2026-02-04T02:58:17.349332Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:barrier_sync: lifecycler::lifecycle: close time.busy=1.30µs time.idle=4.70µs
2026-02-04T02:58:17.349441Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: Successfully got AzureML Context from environment, updating Run History with new run attempt
2026-02-04T02:58:17.349488Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: Skip updating run_attempt since cannot find AZUREML_CR_ENABLE_RUN_ATTEMPT_COUNT_BY_RUN_HISTORY from environment
2026-02-04T02:58:17.349545Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: starting phase execution rank=None phase=0
2026-02-04T02:58:17.349582Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: executing phase commands rank=None phase=0
2026-02-04T02:58:17.349649Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Executing commands
2026-02-04T02:58:17.349868Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:17.349921Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: lifecycler::executor_client: Starting execution execution_id=b732e841-9a12-4956-84d4-9cb3dbb22dca lifecycler_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0
2026-02-04T02:58:17.354736Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::start_execution{lifecycler_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" debug_mode=Some(false) commands_f=Command(Command { executable: Spawn(Spawn { program: "python", args: Some(["-u", "-c", "\nimport json\nimport os\nimport os.path\nimport runpy\nimport sys\nimport traceback\n\nclass NoopContextManager:\n    def __enter__(self):\n        pass\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\nclass ErrorHandlerContextManager:\n    def __init__(self, inner_cm):\n        self.inner_cm = inner_cm\n\n    def __enter__(self):\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__enter__(), 'UserExecution.context_manager.enter')\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if exc_value:\n            write_error('UserExecution.script', 'UserError', exc_value, 'NonCompliant')\n        return ErrorHandlerContextManager.do_op_and_write_error(lambda: self.inner_cm.__exit__(exc_type, exc_value, traceback), 'UserExecution.context_manager.exit')\n\n    @staticmethod\n    def do_op_and_write_error(op, error_code):\n        try:\n            return op()\n        except Exception as e:\n            write_error(error_code, 'SystemError', e, 'Compliant')\n            raise\n\ndef write_error(code, category, error, compliant):\n    try:\n        error_path = os.environ.get('_AZUREML_CR_ERROR_JSON_FILE')\n        dir = os.path.dirname(error_path)\n        os.makedirs(dir, exist_ok=True)\n        with open(error_path, 'x') as f:\n            f.write(json.dumps(to_cr_error(code, category, error, compliant)))\n    except:\n        pass\n\ndef to_cr_error(code, category, error, compliant):\n    known_errors = [\n        'BaseException', 'SystemExit', 'KeyboardInterrupt', 'GeneratorExit', 'Exception', 'StopIteration', 'StopAsyncIteration',\n        'ArithmeticError', 'FloatingPointError', 'OverflowError', 'ZeroDivisionError', 'AssertionError', 'AttributeError',\n        'BufferError', 'EOFError', 'ImportError', 'ModuleNotFoundError', 'LookupError', 'IndexError', 'KeyError', 'MemoryError',\n        'NameError', 'UnboundLocalError', 'OSError', 'BlockingIOError', 'ChildProcessError', 'ConnectionError', 'BrokenPipeError',\n        'ConnectionAbortedError', 'ConnectionRefusedError', 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',\n        'InterruptedError', 'IsADirectoryError', 'NotADirectoryError', 'PermissionError', 'ProcessLookupError', 'TimeoutError',\n        'ReferenceError', 'RuntimeError', 'NotImplementedError', 'RecursionError', 'SyntaxError', 'IndentationError', 'TabError',\n        'SystemError', 'TypeError', 'ValueError', 'UnicodeError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeTranslateError',\n        'Warning', 'DeprecationWarning', 'PendingDeprecationWarning', 'RuntimeWarning', 'SyntaxWarning', 'UserWarning',\n        'FutureWarning', 'ImportWarning', 'UnicodeWarning', 'BytesWarning', 'EncodingWarning', 'ResourceWarning', 'IOError',\n        'EnvironmentError'\n    ]\n    exc_type, exc_val, exc_traceback = sys.exc_info()\n    stack_trace = ''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback))\n    exception_type = type(error).__name__\n    known_error = exception_type in known_errors\n    exception_type_compliance = 'Compliant' if known_error else compliant\n\n    cr_error = {\n        'code': code,\n        'category': category,\n        'message': { compliant: str(error) },\n        'details': [\n            {\n                'name': 'StackTrace',\n                'value': { compliant: stack_trace }\n            },\n            {\n                'name': 'ExceptionType',\n                'value': { exception_type_compliance: exception_type }\n            },\n        ]\n    }\n\n    try:\n        from azureml.exceptions import AzureMLException, UserErrorException\n        if isinstance(error, UserErrorException):\n            cr_error['category'] = 'UserError'\n        if isinstance(error, AzureMLException):\n            cr_error['details'][1]['value'] = { 'Compliant': exception_type }\n    except:\n        pass\n\n    return cr_error\n\n# Copied from context manager injector\ndef strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback):\n    \"\"\"\n        The actual traceback that gets printed when the exception is in the user code is:\n\n        Traceback(most recent call last) :\n            File 'azureml-setup/context_manager_injector.py', line 161, in <module>\n                execute_with_context(cm_objects, options.invocation)\n            File 'azureml-setup/context_manager_injector.py', line 91, in execute_with_context\n                runpy.run_path(sys.argv[0], globals(), run_name= '__main__')\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 263, in run_path\n                pkg_name = pkg_name, script_name = fname)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 96, in _run_module_code\n                mod_name, mod_spec, pkg_name, script_name)\n            File '<USERPROFILE>\\AppData\\Local\\Continuum\\Miniconda3\\envs\\cli_dev\\lib\\runpy.py', line 85, in _run_code\n                exec(code, run_globals)\n            File 'bad_import.py', line 5, in <module>\n                import thisdoesnotexist\n        ModuleNotFoundError: No module named 'thisdoesnotexist'\n\n        however we strip the first 5 layers to give the user a traceback that only contains the user code as part of it\n    \"\"\"\n    traceback_as_list = traceback.format_exception(exc_type, exc_val, exc_traceback)\n    reversed_traceback_list = reversed(traceback_as_list)\n    reversed_trimmed_stack = []\n    # currently the innermost runpy stack occurs inside runpy.py in _run_code and inside the exec(code, run_globals) function\n    # if that changes then the regular stack will be printed\n    keywords_in_innermost_runpy_stack_frame = ['runpy.py', '_run_code', 'exec(code, run_globals)']\n    error_is_in_user_code = False\n    for stack_frame in reversed_traceback_list:\n        if all([keyword in stack_frame for keyword in keywords_in_innermost_runpy_stack_frame]):\n            error_is_in_user_code = True\n            break\n        reversed_trimmed_stack.append(stack_frame)\n    if error_is_in_user_code:\n        # Find the first index of 'Traceback (most recent call last):' in reversed list and append the cause exceptions\n        # This will handle users using 'from with raise' when raising exception\n        reversed_traceback_as_list = traceback_as_list[::-1]\n        traceback_indexes = [idx for idx,stack_frame in enumerate(reversed_traceback_as_list)\n                             if 'Traceback (most recent call last):' in stack_frame]\n        if len(traceback_indexes) > 0:\n            reversed_trimmed_stack.extend(reversed_traceback_as_list[traceback_indexes[0]:])\n\n    return list(reversed(reversed_trimmed_stack))\n\ndef set_tags_for_mlflow_run():\n    # Prepare MLflow integration if supported\n    try:\n        from azureml.core.run import Run\n        from azureml.mlflow import _setup_remote\n        run = Run.get_context()\n        _setup_remote(run)\n    except Exception:\n        return\n\ndef main():\n    # This used to be done in a context_managers.py and context_manager_injector.py where it will add current working\n    # directory and the script's directory to sys.path respectively.\n    # We want to make sure the script's directory is added to the start of sys.path so that it is searched\n    # first and the current working directory is added to the end so that it is searched last.\n    sys.path.insert(0, os.path.dirname(os.path.abspath(sys.argv[1])))\n    sys.path.append(os.getcwd())\n\n    try:\n        # The Run import below is only needed to avoid circular dependency import issue\n        # in the context manager's exit calls\n        from azureml.core import Run\n        from azureml._history.utils.context_managers import SendRunKillSignal\n\n        # Only do this check if AzureML is used\n        if sys.version_info.major != 3 or sys.version_info.minor < 5:\n            raise RuntimeError(f'Python version {str(sys.version_info)} is not supported. Please use python>=3.5')\n\n        # The SendRunKillSignal context manager is misleadingly named. It is actually used to flush metrics of\n        # all the RunHistoryFacade instances. The way it does that is the RunHistoryFacade's constructor registers\n        # a clean up handler that calls flush on the metrics client it has, the handler itself is registered to\n        # a class variable of the RunHistoryFacade class. The SendRunKillSignal context manager's exit method\n        # calls the RunHistoryFacade._kill class method which goes and calls the all of the registered exit handlers\n        # which in turn flushes the metrics. The code below is copied from the run history context manager code.\n        send_kill_signal = not os.environ.get('AZUREML_DISABLE_RUN_KILL_SIGNAL')\n        kill_signal_timeout = float(os.environ.get('AZUREML_RUN_KILL_SIGNAL_TIMEOUT_SEC', '300'))\n        context = SendRunKillSignal(send_kill_signal, kill_signal_timeout)\n    except ImportError:\n        context = NoopContextManager()\n    except RuntimeError:\n        raise\n    except Exception as e:\n        print(f'Warning: Failed to setup Azure Machine Learning system code due to `{e}`. Your job will proceed but if you notice any issues, please contact Azure Support with this exception message.', file=sys.stderr)\n        context = NoopContextManager()\n\n    set_tags_for_mlflow_run()\n\n    context = ErrorHandlerContextManager(context)\n    with context:\n        # when we invoke with `python -c program args`, sys.argv[0] will be -c, args will be the rest (i.e. sys.argv[1:])\n        expanded_argv = []\n        for arg in sys.argv[1:]:\n            arg = os.path.expandvars(arg)\n            expanded_argv.append(arg)\n        sys.argv = expanded_argv\n        runpy.run_path(sys.argv[0], globals(), run_name='__main__')\n\nif __name__ == '__main__':\n    try:\n        main()\n    except SystemExit as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        if ex.code is not None:\n            sys.exit(ex.code)\n    except Exception as ex:\n        # Copied from context manager injector\n        exc_type, exc_val, exc_traceback = sys.exc_info()\n        print(''.join(strip_stack_of_azureml_layers(exc_type, exc_val, exc_traceback)), file=sys.stderr)\n        sys.exit(1)\n", "script.py"]), success_return_code: Zero { additional_codes: [] } }), stderr: None, stdout: Some("user_logs/std_log.txt") }) path_mappings_f={}}: lifecycler::executor_client: close time.busy=347µs time.idle=4.65ms
2026-02-04T02:58:17.354791Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Waiting for execution completion execution_id="b732e841-9a12-4956-84d4-9cb3dbb22dca"
2026-02-04T02:58:21.053423Z  INFO ExecutionCallbackServicer::complete_execution: grpc_utils::server: Got grpc request request_name="complete_execution" remote_addr=None
2026-02-04T02:58:21.053612Z  INFO ExecutionCallbackServicer::complete_execution: lifecycler::service: close time.busy=196µs time.idle=15.0µs
2026-02-04T02:58:21.053663Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}:executor_client::wait_for_execution_completion{execution_id="b732e841-9a12-4956-84d4-9cb3dbb22dca"}: lifecycler::executor_client: close time.busy=8.70µs time.idle=3.70s
2026-02-04T02:58:21.053767Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: Execution completed execution_id="b732e841-9a12-4956-84d4-9cb3dbb22dca"
2026-02-04T02:58:21.053859Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute:executor_client::execute_commands{lifecycle_address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/lifecycler:0" scheduling=None debug_mode=Some(false)}: lifecycler::executor_client: close time.busy=815µs time.idle=3.70s
2026-02-04T02:58:21.053930Z ERROR run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: failed to execute commands exception=ExecutionFailed(ExecutionsFailures([ExecutionFailure { exit_code: 1, error_message: "Execution failed. User process 'python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n  File \"script.py\", line 162, in <module>\n    docker_utilities._docker_build_or_error(\n  File \"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py\", line 156, in _docker_build_or_error\n    _write_error_and_exit(error_msg, error_file_path=error_file_path)\n  File \"/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd/docker_utilities.py\", line 217, in _write_error_and_exit\n    sys.exit(1)\nSystemExit: 1\n\n", process_name: "python", error_file: "user_logs/std_log.txt" }])) rank=None phase=0
2026-02-04T02:58:21.054459Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:execute: lifecycler::lifecycle: close time.busy=1.95ms time.idle=3.70s
2026-02-04T02:58:21.054540Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="CS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:21.054623Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="HOSTTOOLS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:21.054681Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:21.054705Z  WARN run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: grpc_utils::span: failed to inject span context to grpc request
2026-02-04T02:58:21.059500Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: lifecycler::capability_client: Received success code for end cap_name=METRICS_CAPABILITY
2026-02-04T02:58:21.059720Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="METRICS_CAPABILITY"}: lifecycler::capability_client: close time.busy=281µs time.idle=4.76ms
2026-02-04T02:58:21.059836Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: Received success code for end cap_name=SNAPSHOT_CAPABILITY
2026-02-04T02:58:21.060103Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="SNAPSHOT_CAPABILITY"}: lifecycler::capability_client: close time.busy=334µs time.idle=5.07ms
2026-02-04T02:58:21.181902Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="CS_CAPABILITY"}: lifecycler::capability_client: Received success code for end cap_name=CS_CAPABILITY
2026-02-04T02:58:21.182328Z  INFO run_lifecycler:run_service_and_step_through_lifecycle:step_through_lifecycle:end_service_capabilities:end{name="CS_CAPABILITY"}: lifecycler::capability_client: close time.busy=587µs time.idle=127ms

system_logs/metrics_capability/metrics-capability.log : 
----
2026-02-04T02:58:15.636020Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:30:39.546244
2026-02-04T02:58:15.636198Z  INFO metrics-capability::do_main: metrics_capability: metrics cap config cap_config=MetricsCapConfig { polling_interval_sec: 15, send_to_history_interval_sec: 60, enabled_resource_metrics: ["CpuUtilizationPercentage", "GpuUtilizationPercentage", "GpuEnergyJoules", "GpuMemoryUtilizationPercentage", "GpuMemoryUtilizationMegabytes", "GpuMemoryCapacityMegabytes", "CpuMemoryUtilizationPercentage", "CpuMemoryUtilizationMegabytes", "CpuMemoryCapacityMegabytes", "DiskReadMegabytes", "DiskWriteMegabytes", "NetworkInputMegabytes", "NetworkOutputMegabytes", "IBReceiveMegabytes", "IBTransmitMegabytes", "DiskUsedMegabytes", "DiskAvailMegabytes", "StorageAPISuccessCount", "StorageAPIFailureCount"], reserved_disk_space_bytes: 2501743288, additional_scrape_jobs: [], prometheus_push_gateway_port: None, enable_job_cost_metrics: true }
2026-02-04T02:58:15.636345Z  INFO metrics-capability::do_main: metrics_capability: run token file created
2026-02-04T02:58:15.636386Z  INFO metrics-capability::do_main: metrics_capability: embedded file file="prometheus-template.yml"
2026-02-04T02:58:15.672503Z  INFO metrics-capability::do_main: metrics_capability: prometheus config file created
2026-02-04T02:58:15.673110Z  INFO metrics-capability::do_main: metrics_capability: No GPUs found, skipping nvidia-smi instant exporter
2026-02-04T02:58:15.673754Z  INFO metrics-capability::do_main: metrics_capability::additional_scrape_jobs_configer: created additional scrape jobs additional_scrape_jobs="- targets:\n  - localhost:9500\n"
2026-02-04T02:58:15.674089Z  INFO metrics-capability::do_main: metrics_capability: prometheus push gateway not enabled
2026-02-04T02:58:15.674457Z  INFO metrics-capability::do_main: metrics_capability: starting metrics-cap exporter thread, listen on 0.0.0.0:9500
2026-02-04T02:58:15.674462Z  INFO metrics_capability: starting prometheus subprocess watcher task
2026-02-04T02:58:15.674492Z  INFO metrics_capability: starting node-exporter subprocess watcher task
2026-02-04T02:58:15.674559Z  INFO metrics_capability: starting run token updater task
2026-02-04T02:58:15.674605Z  INFO metrics_capability: starting disk full checker, reserved_disk_space_bytes: 2501743288
2026-02-04T02:58:15.674811Z  INFO metrics_capability: starting node-exporter subprocess: node_exporter ["--collector.disable-defaults", "--collector.infiniband", "--collector.diskstats", "--log.level=info", "--web.listen-address=0.0.0.0:9100"] retry_count=1
2026-02-04T02:58:15.674820Z  INFO metrics_capability: starting prometheus subprocess: prometheus ["--storage.tsdb.retention.time=30m", "--log.level=info", "--enable-feature=expand-external-labels", "--config.file=/usr/local/bin/prometheus.yml", "--web.listen-address=0.0.0.0:9090"] retry_count=1
2026-02-04T02:58:15.675040Z  INFO metrics_capability: heartbeat: AZ_BATCH_NODE_ROOT_DIR (node_disk_available_bytes) = 99246931968 metric_name=node_disk_available_bytes value=99246931968 root_dir=/mnt/root_dir
2026-02-04T02:58:15.675111Z  INFO vienna_client::run_history::refresh_run_token{service_endpoint="https://koreacentral.api.azureml.ms" run_id=RunId { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group_name: "8ai-final-team6", workspace_name: "vision", experiment_name: "prepare_image", run_id: "imgbldrun_b23b17c" }}: vienna_client::run_history: Calling service service_endpoint="https://koreacentral.api.azureml.ms"
2026-02-04T02:58:15.675120Z  INFO metrics_capability: heartbeat: starting
2026-02-04T02:58:15.675852Z  INFO metrics-capability::do_main: metrics_capability: metrics capability starting service address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0
2026-02-04T02:58:15.676340Z  INFO metrics-capability::do_main:metrics-capability::run_service{address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0"}: metrics_capability::service: metrics capability starting service address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0
2026-02-04T02:58:15.677096Z  INFO metrics_capability: started prometheus subprocess
2026-02-04T02:58:15.677378Z  INFO metrics_capability: starting cadvisor subprocess watcher task
2026-02-04T02:58:15.677655Z  INFO metrics_capability: starting cadvisor subprocess: cadvisor ["--stderrthreshold=0", "--raw_cgroup_prefix_whitelist=/system.slice/containerd.service", "--listen_ip=0.0.0.0", "--port=8081"] retry_count=1
2026-02-04T02:58:15.677751Z  INFO metrics-capability::do_main:metrics-capability::run_service{address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0"}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/metrics-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:15.679071Z  INFO metrics_capability: started cadvisor subprocess
2026-02-04T02:58:15.682986Z  INFO metrics_capability: started node-exporter subprocess
2026-02-04T02:58:15.697867Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.697Z level=INFO source=node_exporter.go:217 msg="Starting node_exporter" version="(version=, branch=, revision=2d09f79ab64ab699fc518723bcb6eca7711b9046)"
2026-02-04T02:58:15.698167Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.697Z level=INFO source=node_exporter.go:218 msg="Build context" build_context="(go=go1.24.11, platform=linux/amd64, user=, date=, tags=unknown)"
2026-02-04T02:58:15.698252Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.697Z level=WARN source=node_exporter.go:220 msg="Node Exporter is running as root user. This exporter is designed to run as unprivileged user, root is not required."
2026-02-04T02:58:15.700798Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.700Z level=INFO source=diskstats_common.go:108 msg="Parsed flag --collector.diskstats.device-exclude" collector=diskstats flag=^(z?ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\d+n\d+p)\d+$
2026-02-04T02:58:15.702161Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.701Z level=ERROR source=diskstats_linux.go:255 msg="Failed to open directory, disabling udev device properties" collector=diskstats path=/run/udev/data
2026-02-04T02:58:15.707479Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.707Z level=INFO source=node_exporter.go:136 msg="Enabled collectors"
2026-02-04T02:58:15.707923Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.707Z level=INFO source=node_exporter.go:142 msg=diskstats
2026-02-04T02:58:15.708185Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.707Z level=INFO source=node_exporter.go:142 msg=infiniband
2026-02-04T02:58:15.708737Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.708Z level=INFO source=tls_config.go:354 msg="Listening on" address=[::]:9100
2026-02-04T02:58:15.709057Z  INFO metrics_capability: [node-exporter] time=2026-02-04T02:58:15.708Z level=INFO source=tls_config.go:357 msg="TLS is disabled." http2=false address=[::]:9100
2026-02-04T02:58:15.714386Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.714272      21 cadvisor.go:126] enabled metrics: app,cpu,cpuLoad,disk,diskIO,memory,network,oom_event,percpu,perf_event,pressure
2026-02-04T02:58:15.714615Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.714589      21 storagedriver.go:55] Caching stats in memory for 2m0s
2026-02-04T02:58:15.714964Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.714932      21 manager.go:171] cAdvisor running in container: "/system.slice/containerd.service/cr_sys_908df3b09b83400aa7d65f4da9c095c9/305fe7425c9900f85ddb431234e76e5dba0ea276dc27de1f1c1e83d92eb29686"
2026-02-04T02:58:15.741862Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.739Z level=WARN source=main.go:305 msg="Unknown option for --enable-feature" option=expand-external-labels
2026-02-04T02:58:15.746200Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.746Z level=INFO source=main.go:1589 msg="updated GOGC" old=100 new=75
2026-02-04T02:58:15.752805Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.752Z level=INFO source=main.go:704 msg="Leaving GOMAXPROCS=4: CPU quota undefined" component=automaxprocs
2026-02-04T02:58:15.755700Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.755Z level=INFO source=memlimit.go:198 msg="GOMEMLIMIT is updated" component=automemlimit package=github.com/KimMachineGun/automemlimit/memlimit GOMEMLIMIT=15095701094 previous=9223372036854775807
2026-02-04T02:58:15.756142Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.756Z level=INFO source=main.go:803 msg="Starting Prometheus Server" mode=server version="(version=3.8.1, branch=custom-main, revision=e5172d4d12e8a4e5fecda05599ca80a29ecdac90)"
2026-02-04T02:58:15.756527Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.756Z level=INFO source=main.go:808 msg="operational information" build_context="(go=go1.25.5, platform=linux/amd64, user=root@buildkitsandbox, date=20260123-10:33:25, tags=netgo,builtinassets)" host_details="(Linux 6.8.0-1034-azure #39~22.04.1-Ubuntu SMP Wed Aug 13 22:25:47 UTC 2025 x86_64 95c79f3b80034489aaf5f0b3430050cc000000 (none))" fd_limits="(soft=262144, hard=262144)" vm_limits="(soft=unlimited, hard=unlimited)"
2026-02-04T02:58:15.769174Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.769083      21 fs.go:130] Filesystem UUIDs: map[03B6-4352:/dev/sdb15 76ad26e1-60f8-449e-8051-e6cd77917d44:/dev/sdb1 9e7dfdc1-a85f-4915-aaf3-f6f0efb32914:/dev/sda1]
2026-02-04T02:58:15.769478Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.769115      21 fs.go:131] Filesystem partitions: map[/dev:{mountpoint:/dev major:0 minor:91 fsType:tmpfs blockSize:0} /dev/log:{mountpoint:/dev/log major:0 minor:26 fsType:tmpfs blockSize:0} /dev/loop0:{mountpoint:/rootfs/snap/core20/2599 major:7 minor:0 fsType:squashfs blockSize:0} /dev/loop1:{mountpoint:/rootfs/snap/lxd/31333 major:7 minor:1 fsType:squashfs blockSize:0} /dev/loop2:{mountpoint:/rootfs/snap/snapd/24792 major:7 minor:2 fsType:squashfs blockSize:0} /dev/loop3:{mountpoint:/rootfs/snap/snapd/25935 major:7 minor:3 fsType:squashfs blockSize:0} /dev/loop4:{mountpoint:/rootfs/snap/lxd/36918 major:7 minor:4 fsType:squashfs blockSize:0} /dev/root:{mountpoint:/var/lib/docker major:8 minor:17 fsType:ext4 blockSize:0} /dev/sda1:{mountpoint:/rootfs/mnt major:8 minor:1 fsType:ext4 blockSize:0} /dev/sdb15:{mountpoint:/rootfs/boot/efi major:8 minor:31 fsType:vfat blockSize:0} /dev/shm:{mountpoint:/dev/shm major:0 minor:79 fsType:tmpfs blockSize:0} /rootfs/dev/shm:{mountpoint:/rootfs/dev/shm major:0 minor:24 fsType:tmpfs blockSize:0} /rootfs/run:{mountpoint:/rootfs/run major:0 minor:26 fsType:tmpfs blockSize:0} /rootfs/run/lock:{mountpoint:/rootfs/run/lock major:0 minor:27 fsType:tmpfs blockSize:0} /rootfs/run/snapd/ns:{mountpoint:/rootfs/run/snapd/ns major:0 minor:26 fsType:tmpfs blockSize:0} /rootfs/sys/fs/cgroup:{mountpoint:/rootfs/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev:{mountpoint:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev major:0 minor:91 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm:{mountpoint:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm major:0 minor:79 fsType:tmpfs blockSize:0} /rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup:{mountpoint:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup major:0 minor:111 fsType:tmpfs blockSize:0} /run/docker.sock:{mountpoint:/run/docker.sock major:0 minor:26 fsType:tmpfs blockSize:0} /sys/fs/cgroup:{mountpoint:/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev major:0 minor:91 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/log:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/log major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm major:0 minor:79 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/dev/shm:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/dev/shm major:0 minor:24 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/lock:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/lock major:0 minor:27 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/snapd/ns:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/snapd/ns major:0 minor:26 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev major:0 minor:91 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm major:0 minor:79 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup major:0 minor:111 fsType:tmpfs blockSize:0} /var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup major:0 minor:28 fsType:tmpfs blockSize:0} overlay_0-47:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/3da4337d043c945e3a1179b8a9013f39965da272e2ab0205e8c2fbe83de027c6/merged major:0 minor:47 fsType:overlay blockSize:0} overlay_0-63:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged major:0 minor:63 fsType:overlay blockSize:0} overlay_0-65:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/cd49b76cefea16efcf0bc6b17200f67e34a2a2d97e2c3d2bb194031172d187d4/merged major:0 minor:65 fsType:overlay blockSize:0} overlay_0-68:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/be4d29e0bff5cf2e9127decabc18c699502cc1133fc0054172b0d13a7c58ce09/merged major:0 minor:68 fsType:overlay blockSize:0} overlay_0-69:{mountpoint:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/615fa6cbe419ffaace237fb261b91c321be87071cd99d7ac61edc9e717878d73/merged major:0 minor:69 fsType:overlay blockSize:0} overlay_0-75:{mountpoint:/var/lib/docker/overlay2/558bcfbebccae9bc513e15fd506ffc176f722dd9d14d13ce4d77ae1a887ff132/merged major:0 minor:75 fsType:overlay blockSize:0} overlay_0-92:{mountpoint:/var/lib/docker/overlay2/9bfe4bb187063e446dc2a726c817a19b38d25249a484ad48ec96d4c6f91ddd36/merged major:0 minor:92 fsType:overlay blockSize:0}]
2026-02-04T02:58:15.771698Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.771Z level=INFO source=web.go:684 msg="Start listening for connections" component=web address=0.0.0.0:9090
2026-02-04T02:58:15.774125Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.772Z level=INFO source=main.go:1331 msg="Starting TSDB ..."
2026-02-04T02:58:15.777419Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.776910      21 manager.go:218] Machine: {Timestamp:2026-02-04 02:58:15.776253247 +0000 UTC m=+0.092253706 CPUVendorID:GenuineIntel NumCores:4 NumPhysicalCores:2 NumSockets:1 NumBooks:0 NumDrawers:0 CpuFrequency:2294683 MemoryCapacity:16773001216 SwapCapacity:0 MemoryByType:map[] NVMInfo:{MemoryModeCapacity:0 AppDirectModeCapacity:0 AvgPowerBudget:0} HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] MachineID:271616a80e7443399bb849116fcf7890 SystemUUID:812407e2-182a-7545-808f-7b0a5df232ac BootID:03a66a23-a9e3-4934-a8b5-6fb0e5393e7d Filesystems:[{Device:/dev/loop3 DeviceMajor:7 DeviceMinor:3 Capacity:50462720 Type:vfs Inodes:617 HasInodes:true} {Device:overlay_0-69 DeviceMajor:0 DeviceMinor:69 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:overlay DeviceMajor:0 DeviceMinor:63 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/dev/shm DeviceMajor:0 DeviceMinor:79 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/rootfs/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/dev/sda1 DeviceMajor:8 DeviceMinor:1 Capacity:105087164416 Type:vfs Inodes:6553600 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:111 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:111 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/run/docker.sock DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/rootfs/run DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:overlay_0-47 DeviceMajor:0 DeviceMinor:47 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:overlay_0-92 DeviceMajor:0 DeviceMinor:92 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/rootfs/run/lock DeviceMajor:0 DeviceMinor:27 Capacity:5242880 Type:vfs Inodes:2047485 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev DeviceMajor:0 DeviceMinor:91 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:overlay_0-75 DeviceMajor:0 DeviceMinor:75 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/dev/log DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev DeviceMajor:0 DeviceMinor:91 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/loop1 DeviceMajor:7 DeviceMinor:1 Capacity:93847552 Type:vfs Inodes:961 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/snapd/ns DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/sys/fs/cgroup DeviceMajor:0 DeviceMinor:28 Capacity:4194304 Type:vfs Inodes:1024 HasInodes:true} {Device:/rootfs/dev/shm DeviceMajor:0 DeviceMinor:24 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/rootfs/run/snapd/ns DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/dev/loop0 DeviceMajor:7 DeviceMinor:0 Capacity:66977792 Type:vfs Inodes:11901 HasInodes:true} {Device:/dev DeviceMajor:0 DeviceMinor:91 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/loop2 DeviceMajor:7 DeviceMinor:2 Capacity:51773440 Type:vfs Inodes:616 HasInodes:true} {Device:/dev/loop4 DeviceMajor:7 DeviceMinor:4 Capacity:95944704 Type:vfs Inodes:961 HasInodes:true} {Device:overlay_0-65 DeviceMajor:0 DeviceMinor:65 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm DeviceMajor:0 DeviceMinor:79 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm DeviceMajor:0 DeviceMinor:79 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/shm DeviceMajor:0 DeviceMinor:79 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/sdb15 DeviceMajor:8 DeviceMinor:31 Capacity:109395456 Type:vfs Inodes:0 HasInodes:true} {Device:overlay_0-63 DeviceMajor:0 DeviceMinor:63 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:overlay_0-68 DeviceMajor:0 DeviceMinor:68 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev DeviceMajor:0 DeviceMinor:91 Capacity:67108864 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/dev/log DeviceMajor:0 DeviceMinor:26 Capacity:3354603520 Type:vfs Inodes:819200 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/dev/shm DeviceMajor:0 DeviceMinor:24 Capacity:8386498560 Type:vfs Inodes:2047485 HasInodes:true} {Device:/var/lib/docker/overlay2/f301d395fae791ae45040c85376068e8264f6a272aaf006ae7f291feffc05998/merged/rootfs/run/lock DeviceMajor:0 DeviceMinor:27 Capacity:5242880 Type:vfs Inodes:2047485 HasInodes:true} {Device:/dev/root DeviceMajor:8 DeviceMinor:17 Capacity:133003395072 Type:vfs Inodes:16515072 HasInodes:true}] DiskMap:map[8:0:{Name:sda Major:8 Minor:0 Size:107374182400 Scheduler:mq-deadline} 8:16:{Name:sdb Major:8 Minor:16 Size:137438953472 Scheduler:mq-deadline}] NetworkDevices:[{Name:eth0 MacAddress:00:22:48:cc:3c:17 Speed:40000 Mtu:1500}] Topology:[{Id:0 Memory:16773001216 HugePages:[{PageSize:1048576 NumPages:0} {PageSize:2048 NumPages:0}] Cores:[{Id:0 Threads:[0 1] Caches:[{Id:0 Size:32768 Type:Data Level:1} {Id:0 Size:32768 Type:Instruction Level:1} {Id:0 Size:262144 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:} {Id:1 Threads:[2 3] Caches:[{Id:1 Size:32768 Type:Data Level:1} {Id:1 Size:32768 Type:Instruction Level:1} {Id:1 Size:262144 Type:Unified Level:2}] UncoreCaches:[] SocketID:0 BookID: DrawerID:}] Caches:[{Id:0 Size:52428800 Type:Unified Level:3}] Distances:[10]}] CloudProvider:Azure InstanceType:Unknown InstanceID:812407e2-182a-7545-808f-7b0a5df232ac}
2026-02-04T02:58:15.777796Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.777622      21 manager_no_libpfm.go:28] cAdvisor is build without cgo and/or libpfm support. Perf event counters are not available.
2026-02-04T02:58:15.778041Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.777956      21 manager.go:234] Version: {KernelVersion:6.8.0-1034-azure ContainerOsVersion:Debian GNU/Linux 11 (bullseye) DockerVersion: DockerAPIVersion: CadvisorVersion: CadvisorRevision:e3f6b33}
2026-02-04T02:58:15.778959Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.778870      21 factory.go:220] Registration of the containerd container factory failed: unable to create containerd client: containerd: cannot unix dial containerd api service: dial unix /run/containerd/containerd.sock: connect: no such file or directory
2026-02-04T02:58:15.781403Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.781Z level=INFO source=tls_config.go:354 msg="Listening on" component=web address=[::]:9090
2026-02-04T02:58:15.781639Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.781Z level=INFO source=tls_config.go:357 msg="TLS is disabled." component=web http2=false address=[::]:9090
2026-02-04T02:58:15.786645Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.786Z level=INFO source=head.go:681 msg="Replaying on-disk memory mappable chunks if any" component=tsdb
2026-02-04T02:58:15.787005Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.786Z level=INFO source=head.go:767 msg="On-disk memory mappable chunks replay completed" component=tsdb duration=1.8µs
2026-02-04T02:58:15.787204Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.786Z level=INFO source=head.go:775 msg="Replaying WAL, this may take a while" component=tsdb
2026-02-04T02:58:15.787669Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.787Z level=INFO source=head.go:848 msg="WAL segment loaded" component=tsdb segment=0 maxSegment=0 duration=788.704µs
2026-02-04T02:58:15.787713Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.787Z level=INFO source=head.go:885 msg="WAL replay completed" component=tsdb checkpoint_replay_duration=43µs wal_replay_duration=839.205µs wbl_replay_duration=200ns chunk_snapshot_load_duration=0s mmap_chunk_replay_duration=1.8µs total_replay_duration=905.705µs
2026-02-04T02:58:15.791284Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.791Z level=INFO source=main.go:1352 msg="filesystem information" fs_type=794c7630
2026-02-04T02:58:15.791542Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.791Z level=INFO source=main.go:1355 msg="TSDB started"
2026-02-04T02:58:15.791772Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.791Z level=INFO source=main.go:1542 msg="Loading configuration file" filename=/usr/local/bin/prometheus.yml
2026-02-04T02:58:15.799789Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.798Z level=INFO source=watcher.go:240 msg="Starting WAL watcher" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post queue=f2573f
2026-02-04T02:58:15.799928Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.798Z level=INFO source=metadata_watcher.go:90 msg="Starting scraped metadata watcher" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post
2026-02-04T02:58:15.799964Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.799Z level=INFO source=watcher.go:292 msg="Replaying WAL" component=remote remote_name=f2573f url=https://koreacentral.api.azureml.ms/metric/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/api/2.0/prometheus/post queue=f2573f
2026-02-04T02:58:15.802895Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.802808      21 factory.go:365] Registering Docker factory
2026-02-04T02:58:15.803040Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.802860      21 factory.go:222] Registration of the docker container factory successfully
2026-02-04T02:58:15.803472Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.803436      21 factory.go:220] Registration of the podman container factory failed: failed to validate Podman info: response not present: Get "http://d/v1.0.0/info": dial unix /var/run/podman/podman.sock: connect: no such file or directory
2026-02-04T02:58:15.803635Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.803454      21 factory.go:55] Registering systemd factory
2026-02-04T02:58:15.803755Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.803462      21 factory.go:222] Registration of the systemd container factory successfully
2026-02-04T02:58:15.803927Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.803677      21 factory.go:220] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
2026-02-04T02:58:15.804150Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.804078      21 factory.go:105] Registering Raw factory
2026-02-04T02:58:15.804721Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.804479      21 manager.go:1211] Started watching for new ooms in manager
2026-02-04T02:58:15.808870Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.807099      21 manager.go:351] Starting recovery of all containers
2026-02-04T02:58:15.813257Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.813Z level=INFO source=main.go:1582 msg="Completed loading of configuration file" db_storage=1.3µs remote_storage=6.332435ms web_handler=800ns query_engine=1.2µs scrape=8.509646ms scrape_sd=212.502µs notify=2.1µs notify_sd=900ns rules=5.775431ms tracing=39µs filename=/usr/local/bin/prometheus.yml totalDuration=21.911519ms
2026-02-04T02:58:15.813647Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.813Z level=INFO source=manager.go:202 msg="Starting rule manager..." component="rule manager"
2026-02-04T02:58:15.814027Z  INFO metrics_capability: [prometheus] time=2026-02-04T02:58:15.813Z level=INFO source=main.go:1316 msg="Server is ready to receive web requests."
2026-02-04T02:58:15.883712Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.883665      21 manager.go:356] Recovery completed
2026-02-04T02:58:15.894953Z  INFO vienna_client::run_history::refresh_run_token{service_endpoint="https://koreacentral.api.azureml.ms" run_id=RunId { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group_name: "8ai-final-team6", workspace_name: "vision", experiment_name: "prepare_image", run_id: "imgbldrun_b23b17c" }}: vienna_client::run_history: close time.busy=73.5ms time.idle=146ms
2026-02-04T02:58:15.895122Z  INFO metrics_capability: run token refreshed, expiration 2026-02-05 02:58:15.880372 +00:00
2026-02-04T02:58:15.895396Z  INFO metrics_capability: run token written to file
2026-02-04T02:58:15.910352Z  INFO metrics_capability: [cadvisor] I0204 02:58:15.910282      21 cadvisor.go:179] Starting cAdvisor version: -e3f6b33 on port 8081
2026-02-04T02:58:17.067098Z  INFO metrics-capability::start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:58:17.068038Z  INFO metrics-capability::start: metrics_capability::capability_service: close time.busy=959µs time.idle=11.8µs
2026-02-04T02:58:21.059015Z  INFO metrics-capability::end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:58:21.059148Z  INFO metrics-capability::end: metrics_capability::capability_service: close time.busy=133µs time.idle=32.4µs

system_logs/secrets_capability/secrets-capability.log : 
----
2026-02-04T02:58:15.439341Z  INFO telemetry: job_telemetry_init artifact_type=installed branch=2385e2bab64 ci_number=20260123.1 ci_name=CommonRuntime-RuntimeTeam-Linux-Prod-Build build_time=2026-01-23 10:35:03.249413
2026-02-04T02:58:15.440057Z  INFO secrets_capability: secret cap config str: {"secrets_configuration":{"_9EDB952C2AA14D0BBDC3536019616B32":{"workspace_secret_name":"2829c33b-df8f-4b59-83c4-7062a048d8af","uri":null},"_D5FA95C8A7D541CF957D4C905AE760AE":{"workspace_secret_name":"9b0cc91b-e04a-47a7-918a-254d9d982435","uri":null},"_CCF5EB8B9FB14FD2BAEE03DAB4A1E9A9":{"workspace_secret_name":"54f7b50b-67f7-4cb5-954c-f961450f6c7b","uri":null}}}
2026-02-04T02:58:15.440573Z  INFO secrets-capability.parse_config: secrets_capability::config_parser: close time.busy=56.6µs time.idle=36.9µs
2026-02-04T02:58:15.440750Z  INFO secrets_capability: get secrets from credential service service_endpoint="https://koreacentral.api.azureml.ms" secret_names=["2829c33b-df8f-4b59-83c4-7062a048d8af", "9b0cc91b-e04a-47a7-918a-254d9d982435", "54f7b50b-67f7-4cb5-954c-f961450f6c7b"]
2026-02-04T02:58:15.441115Z  INFO vienna_client::credential::credential: Calling credential service to batch get secrets credential_service_endpoint="https://koreacentral.api.azureml.ms"
2026-02-04T02:58:15.456040Z  INFO vienna_client::http_client: send http request to https://koreacentral.api.azureml.ms/credential/v2.0/subscriptions/b850d62a-25fe-4d3a-9697-ea40449528a9/resourceGroups/8ai-final-team6/providers/Microsoft.MachineLearningServices/workspaces/vision/secrets:getbatch
2026-02-04T02:58:15.610279Z  INFO vienna_client::credential::credential: get response from credential service response_status=200 OK
2026-02-04T02:58:15.612418Z  INFO secrets_capability::service: serving capability service at address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/secrets-capability:0
2026-02-04T02:58:15.614366Z  INFO serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/secrets-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:17.067047Z  INFO grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:58:17.067563Z  INFO secrets_capability::capability_service: return secrets envs to lifecycler env_keys=["_9EDB952C2AA14D0BBDC3536019616B32", "_D5FA95C8A7D541CF957D4C905AE760AE", "_CCF5EB8B9FB14FD2BAEE03DAB4A1E9A9"]
2026-02-04T02:58:17.344756Z  INFO grpc_utils::server: Got grpc request request_name="teardown" remote_addr=None
2026-02-04T02:58:17.345406Z  INFO serve: grpc_utils::endpoint::serve: close time.busy=1.12ms time.idle=1.73s
2026-02-04T02:58:17.345466Z  INFO telemetry: Closing telemetry client channel.
2026-02-04T02:58:18.163303Z  INFO telemetry: Telemetry shutdown completed successfully.

system_logs/snapshot_capability/snapshot-capability.log : 
----
2026-02-04T02:58:15.612580Z  INFO telemetry: job_telemetry_init artifact_type= branch= ci_number= ci_name= build_time=
2026-02-04T02:58:15.613274Z  INFO snapshot-capability::do_main:snapshot-capability.parse_config: snapshot_capability::config_parser: Initialized config for snapshot download
2026-02-04T02:58:15.613695Z  INFO snapshot-capability::do_main:snapshot-capability.parse_config: snapshot_capability::config_parser: close time.busy=482µs time.idle=8.90µs
2026-02-04T02:58:15.613800Z  INFO snapshot-capability::do_main: snapshot_capability: snapshot-capability starting service at server_address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0
2026-02-04T02:58:15.614160Z  INFO snapshot-capability::do_main:snapshot-capability::run_service{address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0" snapshot_cap_config=Ok(SnapshotCapConfig { azureml_context: AzureMLContext { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group: "8ai-final-team6", workspace_name: "vision", workspace_id: "375c6882-0301-4d1c-b327-3695ae3932f9", service_endpoint: "https://koreacentral.api.azureml.ms", service_cert_endpoint: "https://koreacentral.cert.api.azureml.ms", discovery_endpoint: "https://koreacentral.api.azureml.ms/discovery", experiment_name: "prepare_image", experiment_id: "31a25d6d-ed6c-48fd-9158-729d8c9abaf0", run_id: "imgbldrun_b23b17c", root_run_id: "imgbldrun_b23b17c", run_token-length: 1182, run_history_service_endpoint: "https://koreacentral.api.azureml.ms", data_container_id: "dcid.imgbldrun_b23b17c", run_uuid: "908df3b0-9b83-400a-a7d6-5f4da9c095c9" }, snapshots: Some([Snapshot { snapshot_asset_id: None, id: Some("142efa39-6781-4d72-bd6e-1ee4db350305"), path_stack: Some(["."]) }]), user_wd: Some("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd"), check_hash: Some(false), enforce_hash_date: Some(2023-01-01), max_retry_duration_in_ms: Some(60000) })}: snapshot_capability::service: snapshot capability serving at address=/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0
2026-02-04T02:58:15.614738Z  INFO snapshot-capability::do_main:snapshot-capability::run_service{address="/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0" snapshot_cap_config=Ok(SnapshotCapConfig { azureml_context: AzureMLContext { subscription_id: "b850d62a-25fe-4d3a-9697-ea40449528a9", resource_group: "8ai-final-team6", workspace_name: "vision", workspace_id: "375c6882-0301-4d1c-b327-3695ae3932f9", service_endpoint: "https://koreacentral.api.azureml.ms", service_cert_endpoint: "https://koreacentral.cert.api.azureml.ms", discovery_endpoint: "https://koreacentral.api.azureml.ms/discovery", experiment_name: "prepare_image", experiment_id: "31a25d6d-ed6c-48fd-9158-729d8c9abaf0", run_id: "imgbldrun_b23b17c", root_run_id: "imgbldrun_b23b17c", run_token-length: 1182, run_history_service_endpoint: "https://koreacentral.api.azureml.ms", data_container_id: "dcid.imgbldrun_b23b17c", run_uuid: "908df3b0-9b83-400a-a7d6-5f4da9c095c9" }, snapshots: Some([Snapshot { snapshot_asset_id: None, id: Some("142efa39-6781-4d72-bd6e-1ee4db350305"), path_stack: Some(["."]) }]), user_wd: Some("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd"), check_hash: Some(false), enforce_hash_date: Some(2023-01-01), max_retry_duration_in_ms: Some(60000) })}:serve: grpc_utils::endpoint::serve: serving gRPC service endpoint=Uds("/mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/.grpc/snapshot-capability:0") retry=ExponentialBackoffRetry { retry_delay_secs: 2, delay_factor: 1000, num_retries: 3 }
2026-02-04T02:58:17.067948Z  INFO snapshot-capability.start: grpc_utils::server: Got grpc request request_name="start" remote_addr=None
2026-02-04T02:58:17.068856Z  INFO snapshot-capability.start: snapshot_capability::snapshot_downloader: Using local working directory: /mnt/azureml/cr/j/908df3b09b83400aa7d65f4da9c095c9/exe/wd
2026-02-04T02:58:17.068944Z  INFO snapshot-capability.start: snapshot_capability::snapshot_downloader: Fetching snapshot ID: 142efa39-6781-4d72-bd6e-1ee4db350305
2026-02-04T02:58:17.134591Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.231367Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Retrieved snapshot metadata
2026-02-04T02:58:17.231505Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.272944Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Preparing to download snapshot files
2026-02-04T02:58:17.273169Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.305026Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.310538Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.315931Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.321550Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.326670Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.332110Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.337201Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Executing request using default client
2026-02-04T02:58:17.342082Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Successfully downloaded snapshot with 8 files
2026-02-04T02:58:17.342143Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Snapshot is downloaded, upload_hash = None, check_hash = Some(false)
2026-02-04T02:58:17.342222Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Updating ignore file...
2026-02-04T02:58:17.342260Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Ignore file candidates: ./.amlignore, ./.gitignore
2026-02-04T02:58:17.342382Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: No ignore file found, create new: ./.amlignore
2026-02-04T02:58:17.342499Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: Updating ignore file... done
2026-02-04T02:58:17.342583Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}:snapshot_capability::fetch_local_files_based_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: close time.busy=9.19ms time.idle=102ms
2026-02-04T02:58:17.342776Z  INFO snapshot-capability.start:snapshot_capability::fetch_snapshot{check_hash=Some(false) enforce_hash_date=Some(2023-01-01) max_retry_duration_in_ms=60000}: snapshot_capability::snapshot_downloader: close time.busy=78.4ms time.idle=195ms
2026-02-04T02:58:17.342808Z  INFO snapshot-capability.start: snapshot_capability::capability_service: close time.busy=80.0ms time.idle=195ms
2026-02-04T02:58:21.055369Z  INFO snapshot-capability.end: grpc_utils::server: Got grpc request request_name="end" remote_addr=None
2026-02-04T02:58:21.055475Z  INFO snapshot-capability.end: snapshot_capability::capability_service: close time.busy=116µs time.idle=27.0µs
