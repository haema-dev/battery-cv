import argparse
import os
from pathlib import Path
import torch
from anomalib.data import Folder
from anomalib.models import Fastflow
from anomalib.engine import Engine

# TorchInferencer consistency
try:
    from anomalib.deploy import TorchInferencer
    HAS_INFERENCER = True
except ImportError:
    HAS_INFERENCER = False

def find_data_root(base_path):
    """'train/good' í´ë”ê°€ í¬í•¨ëœ ìµœì ì˜ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    base = Path(base_path)
    # 1. ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” ê²½ìš°
    if (base / "train/good").exists():
        return base
    
    # 2. datasets/resized/ í•˜ìœ„ì— ìˆëŠ” ê²½ìš° (ì‚¬ìš©ì ìŠ¤í¬ë¦°ìƒ· êµ¬ì¡°)
    possible_sub = base / "datasets/resized"
    if (possible_sub / "train/good").exists():
        return possible_sub
    
    # 3. ë” ê¹Šì´ ìˆëŠ” ê²½ìš° ê²€ìƒ‰
    found = list(base.glob("**/train/good"))
    if found:
        # train/good í´ë”ì˜ ë¶€ëª¨ì˜ ë¶€ëª¨ë¥¼ ë°˜í™˜ (ì˜ˆ: .../resized)
        return found[0].parent.parent
        
    return base

def run_pipeline(data_path, output_dir, epochs):
    print("--------------------------------------------------")
    print(f"ğŸš€ [Stage 1] FastFlow Training Pipeline (v2: 100e)")
    print(f"ğŸ“ Raw Data Path: {data_path}")
    
    # ë°ì´í„° êµ¬ì¡° ìµœì í™” íƒìƒ‰
    optimized_root = find_data_root(data_path)
    print(f"ğŸ“ Optimized Root: {optimized_root}")
    print(f"â²ï¸ Target Epochs: {epochs}")
    print(f"ğŸ› ï¸ Inferencer Ready: {HAS_INFERENCER}")
    print("--------------------------------------------------")

    # 1. ë°ì´í„° ëª¨ë“ˆ ì„¤ì • (Anomalib 1.x ê·œê²©)
    # ë¡œê·¸ í™•ì¸ ê²°ê³¼ 'task' ì¸ìê°€ Folderì—ëŠ” ì§€ì›ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
    datamodule = Folder(
        name="battery",
        root=str(optimized_root),
        normal_dir="train/good",
        normal_test_dir="test",
        test_split_mode="from_dir",
        image_size=(256, 256)
    )

    # 2. ëª¨ë¸ ì„¤ì • (FastFlow)
    model = Fastflow(backbone="resnet18", flow_steps=8)

    # 3. ì—”ì§„ ì„¤ì • (TaskëŠ” ì—¬ê¸°ì„œ ì •ì˜)
    engine = Engine(
        max_epochs=epochs,
        default_root_dir=output_dir,
        devices=1,
        accelerator="auto",
        task="classification"
    )

    # 4. í•™ìŠµ ì‹œì‘
    print("â³ Starting training...")
    engine.fit(model=model, datamodule=datamodule)
    
    # 5. ê²°ê³¼ë¬¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    model_save_path = output_path / "model.pt"
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Training completed. Weights saved: {model_save_path}")

    # 6. ì¼ê´€ì„± ê²€ì¦
    if HAS_INFERENCER:
        try:
            print("ğŸ” Verifying model consistency with TorchInferencer...")
            inferencer = TorchInferencer(path=model_save_path, device="cpu")
            print("âœ¨ Success: Model is compatible with TorchInferencer API.")
        except Exception as e:
            print(f"âš ï¸ Note: Inferencer verification failed: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=100)
    args = parser.parse_args()
    run_pipeline(args.data_path, args.output_dir, args.epochs)