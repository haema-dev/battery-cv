# -*- coding: utf-8 -*-
import os
import torch
import argparse
import mlflow
import json
import time
import cv2
import random
import numpy as np
from loguru import logger
from anomalib.models import Fastflow
from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.loggers import AnomalibMLFlowLogger
from pathlib import Path
from torchvision.transforms.v2 import Resize
from lightning.pytorch.callbacks import EarlyStopping

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def main():
    # ================== 1. Input/Output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=50)
    parser.add_argument("--backbone", type=str, default="resnet18", help="Feature extractor backbone")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")
    parser.add_argument("--lr", type=float, default=0.001, help="Learning rate")
    parser.add_argument("--weight_decay", type=float, default=1e-5, help="Weight decay")

    args = parser.parse_args()
    set_seed(args.seed)
    base_path = Path(args.data_path)
    
    logger.info("==================================================")
    logger.info(" S1_FastFlow_Training: [Production Ready Mode]")
    logger.info(f" ë§ˆìš´íŠ¸ ë£¨íŠ¸: {base_path}")
    logger.info(f" ì„¤ì •: Backbone={args.backbone}, Epochs={args.epochs}, Seed={args.seed}")
    logger.info("==================================================")

    # [ë””ë²„ê¹…] ì‹¤ì œ ë§ˆìš´íŠ¸ëœ íŒŒì¼ êµ¬ì¡°ë¥¼ 2ë‹¨ê³„ê¹Œì§€ ì¶œë ¥ (ls -R ìŠ¤íƒ€ì¼)
    try:
        logger.info(" [Debug] ë§ˆìš´íŠ¸ëœ ë””ë ‰í† ë¦¬ êµ¬ì¡° íƒìƒ‰ ì¤‘...")
        for root, dirs, files in os.walk(base_path):
            level = len(Path(root).relative_to(base_path).parts)
            if level <= 2: # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ 2ë‹¨ê³„ê¹Œì§€ë§Œ
                indent = "  " * level
                logger.info(f"{indent} {Path(root).name}/ ({len(files)} files)")
            if level > 2: continue # ë” ê¹Šì€ ê³³ì€ ìƒëµ
    except Exception as e:
        logger.warning(f" êµ¬ì¡° ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    # [Fail-Fast] í•„ìˆ˜ í´ë” ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    train_path = base_path / "train/good"
    val_path = base_path / "validation"
    
    check_targets = {
        "í•™ìŠµìš© ì •ìƒ ë°ì´í„° (train/good)": train_path,
        "ê²€ì¦ìš© ë°ì´í„° (validation)": val_path
    }
    
    missing_critical = False
    for label, path in check_targets.items():
        if path.exists():
            logger.info(f" {label} í™•ì¸ ì™„ë£Œ: {path}")
        else:
            logger.error(f" {label}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŒ: {path}")
            if label == "í•™ìŠµìš© ì •ìƒ ë°ì´í„° (train/good)":
                missing_critical = True

    if missing_critical:
        raise FileNotFoundError(f" í•„ìˆ˜ í•™ìŠµ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ ë¡œê·¸ë¥¼ ë³´ê³  ë°ì´í„° êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    dataset_root = base_path

    # ================== 2. MLflow & Output ì„¤ì • ==================== #
    mlflow.start_run()
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f" ì‚¬ìš© ì¥ì¹˜: {device}")

    try:
        # ================== 3. Anomalib ë°ì´í„° êµ¬ì„± ==================== #
        logger.info(f" ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {dataset_root}")
        
        # [Dynamic Detection] 'good'ì„ ì œì™¸í•œ ëª¨ë“  í´ë”ë¥¼ ë¶ˆëŸ‰(abnormal) ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        val_root = base_path / "validation"
        abnormal_dirs = []
        if val_root.exists():
            abnormal_dirs = [f"validation/{d.name}" for d in val_root.iterdir() if d.is_dir() and d.name != "good"]
        
        logger.info(f" ê²€ì¦ìš© ë¶ˆëŸ‰ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€: {abnormal_dirs}")

        datamodule = Folder(
            name="battery",
            root=str(dataset_root),
            normal_dir="train/good",
            normal_test_dir="validation/good",
            abnormal_dir=abnormal_dirs if abnormal_dirs else None,
            train_batch_size=32,
            eval_batch_size=8,
            num_workers=4,
            augmentations=Resize((256, 256)),
            seed=args.seed,
            task="classification"
        )

        # ================== 3. ëª¨ë¸ ë° ì½œë°± ì„¤ì • ==================== #
        logger.info(f"ğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘: FastFlow (Backbone: {args.backbone})")
        # evaluator=False prevents internal metric initialization that might expect gt_mask
        model = Fastflow(
            backbone=args.backbone, 
            flow_steps=8, 
            evaluator=False,
            lr=args.lr,
            weight_decay=args.weight_decay
        )
        
        # Early Stopping ì„¤ì •: ì„±ëŠ¥ í–¥ìƒì´ ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ìì› ì ˆì•½
        early_stop = EarlyStopping(
            monitor="image_F1Score", 
            patience=5, 
            mode="max",
            verbose=True
        )

        mlflow_logger = AnomalibMLFlowLogger(experiment_name="Battery_Anomaly", save_dir=str(OUTPUT_DIR))
        
        engine = Engine(
            max_epochs=args.epochs,
            accelerator="auto",
            devices=1,
            default_root_dir=str(OUTPUT_DIR),
            logger=mlflow_logger,
            callbacks=[early_stop],
            image_metrics=["AUROC", "F1Score"],
            pixel_metrics=None,
            task="classification"
        )

        # ================== 4. í•™ìŠµ ë° ì €ì¥ ==================== #
        logger.info(f" Training started (Seed: {args.seed})...")
        engine.fit(model=model, datamodule=datamodule)
        
        # [Threshold Finalization] í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ ì„ê³„ê°’(Threshold)ì„ í™•ì •í•˜ê³  ë¡œê·¸ì— ê¸°ë¡í•©ë‹ˆë‹¤.
        logger.info(" Finalizing threshold and calculating metrics...")
        engine.test(model=model, datamodule=datamodule)
        
        # ìµœì  ì„ê³„ê°’ ë¡œê¹…
        if hasattr(model, "image_threshold"):
            logger.info(f" Calculated Image Threshold: {model.image_threshold.value.item():.4f}")
        if hasattr(model, "pixel_threshold"):
            logger.info(f" Calculated Pixel Threshold: {model.pixel_threshold.value.item():.4f}")

        ckpt_path = OUTPUT_DIR / "model.ckpt"
        engine.trainer.save_checkpoint(ckpt_path)
        
        model_path = OUTPUT_DIR / "model.pt"
        torch.save(model.state_dict(), model_path)
        logger.success(f" Model saved (including thresholds in .ckpt)")

        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            mlflow.log_param("gpu_name", gpu_name)

        # ================== 5. ê²°ê³¼ ê¸°ë¡ ==================== #
        info = {
            "backbone": args.backbone,
            "seed": args.seed,
            "epochs": args.epochs,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(OUTPUT_DIR / "info.json", 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        mlflow.log_params(info)
        mlflow.log_artifact(str(OUTPUT_DIR))
        logger.success(" ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f" í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        mlflow.end_run()

if __name__ == "__main__":
    main()

# success plz
