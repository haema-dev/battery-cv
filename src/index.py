import os, torch, argparse, mlflow, json, time
from loguru import logger
from anomalib.models import Fastflow
from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.models import Patchcore
from pathlib import Path
import numpy as np, cv2
from torchvision.transforms.v2 import Compose, Resize, ToImage, ToDtype
import adlfs
import fsspec


def main():
    # Trigger training for battery-data-CLAHE-gray

    # ================== 1. input/output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, help="Path to mounted data asset")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=10)    
    parser.add_argument("--model", type=str, default="patchcore", choices=["patchcore", "fastflow"], help="Model to train")

    args = parser.parse_args()
    base_path = Path(args.data_path)

    # ==========================================
    # ğŸ” ë§ˆìš´íŠ¸ ê²½ë¡œ í™•ì¸ (ì••ì¶• í•´ì œëœ ì´ë¯¸ì§€ ì‚¬ìš©)
    # ==========================================
    logger.info(f"ğŸ“ ë§ˆìš´íŠ¸ ë£¨íŠ¸ í™•ì¸: {args.data_path}")
    
    if os.path.exists(args.data_path):
        import subprocess
        # í´ë” êµ¬ì¡°ë¥¼ 2ë‹¨ê³„ê¹Œì§€ ì‹¹ í›‘ì–´ì„œ ë¡œê·¸ì— ë‚¨ê¹ë‹ˆë‹¤.
        result = subprocess.run(['ls', '-R', args.data_path], capture_output=True, text=True)
        # logger.info(f"ğŸ“‚ ì‹¤ì œ ë§ˆìš´íŠ¸ëœ íŒŒì¼ êµ¬ì¡°:\n{result.stdout[:2000]}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ í™•ì¸
        image_count = len([f for f in os.listdir(args.data_path) if f.endswith(('.jpg', '.jpeg', '.png'))])
        logger.info(f"ğŸ“· ë§ˆìš´íŠ¸ëœ ì´ë¯¸ì§€ ìˆ˜: {image_count}ê°œ")
    else:
        raise FileNotFoundError(f"ë§ˆìš´íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.data_path}")
    
    # ========================================== Mlflow ==========================================
    mlflow.start_run()
    OUTPUT_DIR = args.output_dir
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    logger.info(f"ğŸ“‚ {os.path.abspath(OUTPUT_DIR)}")
    
    try:
        # ================== 2. ì´ìƒíƒì§€ ì‘ì—… ==================== #
        
        logger.info(f"ğŸ“¥ {args.model.upper()} ëª¨ë¸ ë° ë°ì´í„°ì…‹ êµ¬ì„±")
        
        import anomalib
        logger.info(f"ğŸ“¦ Anomalib Version: {anomalib.__version__}")

        # ë°ì´í„°ì…‹ êµ¬ì„± (ë§ˆìš´íŠ¸ëœ ì••ì¶•í•´ì œ ì´ë¯¸ì§€ ì‚¬ìš©)
        dataset_root = str(base_path)  # ë§ˆìš´íŠ¸ëœ ê²½ë¡œ ì§ì ‘ ì‚¬ìš©
        logger.info(f"ğŸ“‚ í•™ìŠµ ë°ì´í„° ê²½ë¡œ: {dataset_root}")
        
        # Transform ì •ì˜ (Anomalib 2.2.0 í˜¸í™˜)
        # image_size ì¸ì ëŒ€ì‹  explicit transform ì‚¬ìš©
        transform = Compose([
            Resize((1024, 320)),
            ToImage(), 
            ToDtype(torch.float32, scale=True),
        ])

        datamodule = Folder(
            name="battery",
            root=dataset_root,
            normal_dir=".", 
            train_batch_size=4,
            eval_batch_size=8,
            num_workers=4,
            train_augmentations=transform,
            val_augmentations=transform,
            test_augmentations=transform,
        )
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        if args.model == "fastflow":
            model = Fastflow(
                backbone="resnet18",
                pre_trained=True,
                flow_steps=8, # Default flow steps
            )
        else:
            model = Patchcore(
                backbone="resnet18",
                pre_trained=True,
                layers=["layer2", "layer3"],
                coreset_sampling_ratio=0.01,  # Reduced to 0.01 for high-res (320x1024) inputs
            )

        # ---------------------------------------------------------
        # ğŸ”§ [Fix] ëª¨ë¸ ë‚´ë¶€ ë¦¬ì‚¬ì´ì§• ë¡œì§ ê°•ì œ ìˆ˜ì •
        # ëª¨ë¸ì´ ê¸°ë³¸ì ìœ¼ë¡œ 256x256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì§•í•˜ë ¤ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ ,
        # ìš°ë¦¬ê°€ ì „ì²˜ë¦¬í•œ 1024x320 í•´ìƒë„ë¥¼ ìœ ì§€í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.
        # ---------------------------------------------------------
        if hasattr(model, "pre_processor") and hasattr(model.pre_processor, "transform"):
            model.pre_processor.transform = Compose([
                Resize((1024, 320)),
                ToImage(), 
                ToDtype(torch.float32, scale=True),
            ])
            logger.info("ğŸ”§ ëª¨ë¸ ë‚´ë¶€ PreProcessorë¥¼ 1024x320ìœ¼ë¡œ ê°•ì œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
        
        # ì—”ì§„ ì„¤ì • ë° í•™ìŠµ
        engine = Engine(
            max_epochs=args.epochs,
            accelerator="auto",
            devices=1,
            default_root_dir=OUTPUT_DIR,
            enable_checkpointing=True,
            precision="16-mixed", # Mixed Precision for memory optimization
        )
        
        # ğŸ’‰ [Optim] ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê²½ê³  ë©”ì‹œì§€ ë°˜ì˜)
        os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
        
        logger.info("ğŸš€ í•™ìŠµ ì‹œì‘...")
        engine.fit(model=model, datamodule=datamodule)
        logger.success("âœ… í•™ìŠµ ì™„ë£Œ!")
        
        # ================== 3. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥ ==================== #
        
        # ëª¨ë¸ ì €ì¥
        model_path = f"{OUTPUT_DIR}/model.pt"
        torch.save(model.state_dict(), model_path)
        logger.info(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}")
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        info = {
            "model": args.model,
            "backbone": "resnet18",
            "layers": ["layer2", "layer3"],
            "epochs": args.epochs,
            "image_size": (1024, 320),
            "anomalib_version": anomalib.__version__,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(f"{OUTPUT_DIR}/info.json", 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ“„ ë©”íƒ€ë°ì´í„° ì €ì¥: {OUTPUT_DIR}/info.json")

        # MLflow ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
        mlflow.log_artifact(OUTPUT_DIR)
        logger.success("âœ… ê²°ê³¼ Blob ì—…ë¡œë“œ ì™„ë£Œ!")
                
    except Exception as e:
        logger.error(f"âŒ {e}")
        raise

    mlflow.end_run()
    logger.success("ğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__": main()
#ì„±ê³µê¸°ì›