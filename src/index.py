import argparse
import os
import sys
from pathlib import Path
import torch
from anomalib.data import Folder
from anomalib.models import Fastflow
from anomalib.engine import Engine

# v2.2: Comprehensive Path Discovery & Diagnostic Logging
def diagnostic_ls(path, depth=3):
    """ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì¶œë ¥í•˜ì—¬ ë¡œê·¸ì— ë‚¨ê¹ë‹ˆë‹¤."""
    print(f"\nğŸ” [Diagnostic] Listing structure of: {path}")
    base = Path(path)
    if not base.exists():
        print(f"âŒ Error: Path {path} does not exist.")
        return
    
    for p in base.rglob('*'):
        rel = p.relative_to(base)
        if len(rel.parts) > depth:
            continue
        indent = "  " * (len(rel.parts) - 1)
        suffix = "/" if p.is_dir() else ""
        print(f"{indent}- {rel.name}{suffix}")

def find_anomalib_root(base_path):
    """'train/good' í´ë”ê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ì°¾ì•„ Anomalib rootë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    base = Path(base_path)
    print(f"ğŸ” Searching for training data root starting from: {base}")
    
    # 1. ì¬ê·€ì ìœ¼ë¡œ 'train/good' í´ë” ì°¾ê¸° (ìµœëŒ€ ê¹Šì´ ì œí•œìœ¼ë¡œ ì„±ëŠ¥ í™•ë³´)
    for path in base.rglob('train/good'):
        if path.is_dir():
            root = path.parent.parent
            print(f"âœ… Found Anomalib root candidate: {root}")
            # í•´ë‹¹ ìœ„ì¹˜ì— test í´ë”ë„ ìˆëŠ”ì§€ ê°€ë³ê²Œ í™•ì¸
            if (root / "test").exists():
                print(f"âœ¨ Verified root with 'test' folder: {root}")
                return root
            return root
            
    # 2. 'train' í´ë”ë§Œì´ë¼ë„ ì°¾ê¸°
    for path in base.rglob('train'):
        if path.is_dir():
            root = path.parent
            print(f"âš ï¸ Found 'train' but no 'good' subdir? Using root: {root}")
            return root
            
    print("âŒ Failed to find a valid training structure. Falling back to base path.")
    return base

def run_pipeline(data_path, output_dir, epochs):
    print("--------------------------------------------------")
    print(f"ğŸš€ [Stage 1] FastFlow Training Pipeline (v2.2)")
    print(f"ğŸ“ Raw Data Path: {data_path}")
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸: í˜„ì¬ ë§ˆìš´íŠ¸ëœ ë°ì´í„°ì˜ 3ë‹¨ê³„ ê¹Šì´ê¹Œì§€ ì¶œë ¥
    try:
        diagnostic_ls(data_path, depth=3)
    except Exception as e:
        print(f"âš ï¸ Warning: Diagnostic logging failed: {e}")

    # ë°ì´í„° êµ¬ì¡° ìµœì í™” íƒìƒ‰
    optimized_root = find_anomalib_root(data_path)
    print(f"ğŸ“ Final Optimized Root: {optimized_root}")
    print(f"â²ï¸ Target Epochs: {epochs}")
    print("--------------------------------------------------")

    # 1. ë°ì´í„° ëª¨ë“ˆ ì„¤ì •
    # Anomalib 1.1.3 ê¸°ì¤€ ê°€ì¥ ì•ˆì „í•œ ì„¤ì •
    datamodule = Folder(
        name="battery",
        root=str(optimized_root),
        normal_dir="train/good",
        normal_test_dir="test",
        test_split_mode="from_dir"
    )

    # 2. ëª¨ë¸ ì„¤ì • (FastFlow)
    model = Fastflow(backbone="resnet18", flow_steps=8)

    # 3. ì—”ì§„ ì„¤ì •
    engine = Engine(
        max_epochs=epochs,
        default_root_dir=output_dir,
        devices=1,
        accelerator="auto"
    )

    # 4. í•™ìŠµ ì‹œì‘
    print("â³ Starting training (Engine.fit)...")
    try:
        engine.fit(model=model, datamodule=datamodule)
    except Exception as e:
        print("\nâŒ Training Failed during engine.fit!")
        print(f"Error details: {e}")
        # ì‹¤íŒ¨ ì‹œ ë‹¤ì‹œ í•œ ë²ˆ ìƒì„¸ ê²½ë¡œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        diagnostic_ls(optimized_root, depth=4)
        raise e
    
    # 5. ê²°ê³¼ë¬¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    model_save_path = output_path / "model.pt"
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Training completed successfully.")
    print(f"ï¿½ Weights saved: {model_save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=100)
    args = parser.parse_args()
    
    # Azure ML í™˜ê²½ì—ì„œëŠ” ê°„í˜¹ ë¡œê·¸ ì „ë‹¬ì´ ëŠ¦ì–´ì§€ë¯€ë¡œ ì¦‰ì‹œ ì¶œë ¥ ê°•ì œ
    os.environ["PYTHONUNBUFFERED"] = "1"
    
    run_pipeline(args.data_path, args.output_dir, args.epochs)