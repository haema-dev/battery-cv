import argparse
import os
from pathlib import Path
import torch
from anomalib.data import Folder
from anomalib.models import Fastflow
from anomalib.engine import Engine

# TorchInferencer consistency
try:
    from anomalib.deploy import TorchInferencer
    HAS_INFERENCER = True
except ImportError:
    HAS_INFERENCER = False

def find_data_root(base_path):
    """'train/good' í´ë”ê°€ í¬í•¨ëœ ìµœì ì˜ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    base = Path(base_path)
    # 1. ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” ê²½ìš°
    if (base / "train/good").exists():
        return base
    
    # 2. datasets/resized/ í•˜ìœ„ì— ìˆëŠ” ê²½ìš° (ì‚¬ìš©ì ìŠ¤í¬ë¦°ìƒ· êµ¬ì¡°)
    possible_sub = base / "datasets/resized"
    if (possible_sub / "train/good").exists():
        return possible_sub
    
    # 3. ë” ê¹Šì´ ìˆëŠ” ê²½ìš° ê²€ìƒ‰
    found = list(base.glob("**/train/good"))
    if found:
        return found[0].parent.parent
        
    return base

def run_pipeline(data_path, output_dir, epochs):
    print("--------------------------------------------------")
    print(f"ğŸš€ [Stage 1] FastFlow Training Pipeline (v2: 100e)")
    print(f"ğŸ“ Raw Data Path: {data_path}")
    
    optimized_root = find_data_root(data_path)
    print(f"ğŸ“ Optimized Root: {optimized_root}")
    print(f"â²ï¸ Target Epochs: {epochs}")
    print(f"ğŸ› ï¸ Inferencer Ready: {HAS_INFERENCER}")
    print("--------------------------------------------------")

    # 1. ë°ì´í„° ëª¨ë“ˆ ì„¤ì • (Anomalib 1.x ìµœì†Œ ì‚¬ì–‘ ê·œê²©)
    # 'test_dir', 'task'ì— ì´ì–´ 'image_size'ê¹Œì§€ 1.x ìµœì‹  ë²„ì „ì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•ŠìŒ í™•ì¸
    # ê°€ì¥ í•„ìˆ˜ì ì¸ ì¸ìë“¤ë¡œë§Œ êµ¬ì„±í•˜ì—¬ í˜¸í™˜ì„± ê·¹ëŒ€í™”
    datamodule = Folder(
        name="battery",
        root=str(optimized_root),
        normal_dir="train/good",
        normal_test_dir="test",
        test_split_mode="from_dir"
    )

    # 2. ëª¨ë¸ ì„¤ì • (FastFlow)
    # FastFlow ëª¨ë¸ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ 256x256 ë“±ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ ë°ì´í„°ì—ì„œ ëº„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    model = Fastflow(backbone="resnet18", flow_steps=8)

    # 3. ì—”ì§„ ì„¤ì • (T4 GPU ì‚¬ìš©)
    engine = Engine(
        max_epochs=epochs,
        default_root_dir=output_dir,
        devices=1,
        accelerator="auto",
        task="classification"
    )

    # 4. í•™ìŠµ ì‹œì‘
    print("â³ Starting training...")
    engine.fit(model=model, datamodule=datamodule)
    
    # 5. ê²°ê³¼ë¬¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    model_save_path = output_path / "model.pt"
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Training completed. Weights saved: {model_save_path}")

    # 6. ì¼ê´€ì„± ê²€ì¦
    if HAS_INFERENCER:
        try:
            print("ğŸ” Verifying model consistency with TorchInferencer...")
            inferencer = TorchInferencer(path=model_save_path, device="cpu")
            print("âœ¨ Success: Model is compatible with TorchInferencer API.")
        except Exception as e:
            print(f"âš ï¸ Note: Inferencer verification failed: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=100)
    args = parser.parse_args()
    run_pipeline(args.data_path, args.output_dir, args.epochs)