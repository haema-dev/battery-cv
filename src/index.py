# -*- coding: utf-8 -*-
import os
import sys
import torch
import argparse
import mlflow
import json
import time
import cv2
import random
import numpy as np
from loguru import logger
from anomalib.models import Fastflow
from torch import optim
from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.loggers import AnomalibMLFlowLogger
from pathlib import Path
from torchvision.transforms.v2 import Compose, Normalize, Resize
from lightning.pytorch.callbacks import EarlyStopping
from anomalib.metrics import AUROC, F1Score, Evaluator, F1AdaptiveThreshold

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

class TunableFastflow(Fastflow):
    def __init__(self, *args, lr: float = 0.001, weight_decay: float = 1e-5, **kwargs):
        super().__init__(*args, **kwargs)
        self.lr = lr
        self.weight_decay = weight_decay

    def configure_optimizers(self) -> optim.Optimizer:
        return optim.Adam(
            params=self.model.parameters(),
            lr=self.lr,
            weight_decay=self.weight_decay,
        )

    @staticmethod
    def configure_evaluator() -> Evaluator:
        image_auroc = AUROC(fields=["pred_score", "gt_label"], prefix="image_")
        image_f1score = F1Score(fields=["pred_label", "gt_label"], prefix="image_")
        
        # [CRITICAL] 
        # F1AdaptiveThreshold: ê²€ì¦ ë‹¨ê³„ì—ì„œ ìµœì ì˜ ì„ê³„ê°’(Threshold)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        # ì´ ì§€í‘œê°€ ìˆì–´ì•¼ Test ë‹¨ê³„ì—ì„œ 'pred_label'ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        image_threshold = F1AdaptiveThreshold(fields=["pred_score", "gt_label"], prefix="image_")
        
        return Evaluator(
            val_metrics=[image_auroc, image_threshold], 
            test_metrics=[image_auroc, image_f1score]
        )

def main():
    # ================== 1. Input/Output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument("--model_path", type=str, default=None, help="Path to pre-trained model checkpoint (Optional for Eval Mode)")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=50)
    parser.add_argument("--backbone", type=str, default="resnet18", help="Feature extractor backbone")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")
    parser.add_argument("--lr", type=float, default=0.0001, help="Learning rate")
    parser.add_argument("--weight_decay", type=float, default=1e-5, help="Weight decay")

    args = parser.parse_args()
    set_seed(args.seed)
    base_path = Path(args.data_path)
    
    logger.info("==================================================")
    logger.info(" STAGE 2: PM Selection - FastFlow Training/Eval")
    logger.info(f" ë§ˆìš´íŠ¸ ë£¨íŠ¸: {base_path}")
    if args.model_path:
        logger.info(f" ëª¨ë¸ ë¡œë“œ ê²½ë¡œ: {args.model_path}")
    logger.info(f" ì„¤ì •: Backbone={args.backbone}, Epochs={args.epochs}")
    logger.info("==================================================")

    # í•„ìˆ˜ í´ë” ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    train_path = base_path / "train/good"
    val_path = base_path / "validation"
    
    dataset_root = base_path

    # ================== 2. MLflow & Output ì„¤ì • ==================== #
    mlflow.start_run()
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f" ì‚¬ìš© ì¥ì¹˜: {device}")

    try:
        # ================== 3. Anomalib ë°ì´í„° êµ¬ì„± ==================== #
        logger.info(f" ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {dataset_root}")
        
        # [Dynamic Detection] 'good'ì„ ì œì™¸í•œ ëª¨ë“  í´ë”ë¥¼ ë¶ˆëŸ‰ ì¹´í…Œê³ ë¦¬ë¡œ ìˆ˜ì§‘
        abnormal_dirs = []
        if val_path.exists():
            abnormal_dirs = [f"validation/{d.name}" for d in val_path.iterdir() if d.is_dir() and d.name != "good"]
        
        logger.info(f" ê²€ì¦ìš© ë¶ˆëŸ‰ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€: {abnormal_dirs}")

        transform = Compose([
            Resize((256, 256)),
            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        datamodule = Folder(
            name="battery",
            root=str(dataset_root),
            normal_dir="train/good",
            normal_test_dir="validation/good",
            abnormal_dir=abnormal_dirs if abnormal_dirs else None,
            train_batch_size=32,
            eval_batch_size=8,
            num_workers=4,
            augmentations=transform,
            seed=args.seed
        )

        # ================== 4. ëª¨ë¸ ìƒì„± ë° ì´ˆê¸°í™” ==================== #
        logger.info(f"ğŸ—ï¸ ëª¨ë¸ ìƒì„± ì¤‘: FastFlow (Backbone: {args.backbone})")
        
        evaluator = TunableFastflow.configure_evaluator()
        
        model = TunableFastflow(
            backbone=args.backbone, 
            flow_steps=8, 
            evaluator=evaluator,
            lr=args.lr,
            weight_decay=args.weight_decay
        )
        
        # [Stage 2 Integration] ë¡œë“œí•  ëª¨ë¸ íŒŒì¼ì´ ìˆë‹¤ë©´ ê°€ì¤‘ì¹˜ ì£¼ì…
        if args.model_path and os.path.exists(args.model_path):
            logger.info(f"[*] ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ: {args.model_path}")
            ckpt = torch.load(args.model_path, map_location="cpu")
            state_dict = ckpt.get("state_dict", ckpt)
            if isinstance(state_dict, dict) and "model" in state_dict:
                state_dict = state_dict["model"]
            model.load_state_dict(state_dict, strict=False)
            logger.success("[OK] ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")

        # ì½œë°± ì„¤ì •
        early_stop = EarlyStopping(
            monitor="image_AUROC", 
            patience=5, 
            mode="max",
            verbose=True
        )

        mlflow_logger = AnomalibMLFlowLogger(experiment_name="Battery_S1_AnomalyDetection", save_dir=str(OUTPUT_DIR))

        engine = Engine(
            max_epochs=args.epochs,
            accelerator="auto",
            devices=1,
            default_root_dir=str(OUTPUT_DIR),
            logger=mlflow_logger,
            callbacks=[early_stop],
            gradient_clip_val=1.0
        )

        # ================== 5. ì‹¤í–‰ (í•™ìŠµ ë˜ëŠ” í‰ê°€) ==================== #
        if not args.model_path:
            logger.info(" [Mode: Training] í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            engine.fit(model=model, datamodule=datamodule)
        else:
            logger.info(" [Mode: Evaluation] í•™ìŠµì„ ìƒëµí•˜ê³  í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

        # ìµœì¢… ì„±ëŠ¥ ì¸¡ì • ë° ì„ê³„ê°’ í™•ì •
        logger.info(" Calculating final metrics and thresholds...")
        engine.test(model=model, datamodule=datamodule)
        
        # ìµœì  ì„ê³„ê°’ ë¡œê¹…
        if hasattr(model, "image_threshold"):
            logger.info(f" Calculated Image Threshold: {model.image_threshold.value.item():.4f}")

        # ê²°ê³¼ ì €ì¥
        ckpt_path = OUTPUT_DIR / "model.ckpt"
        engine.trainer.save_checkpoint(ckpt_path)
        
        model_pt_path = OUTPUT_DIR / "model.pt"
        torch.save(model.state_dict(), model_pt_path)
        logger.success(f" [FINISH] ëª¨ë“  ê²°ê³¼ê°€ {OUTPUT_DIR}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            mlflow.log_param("gpu_name", gpu_name)

        # ê²°ê³¼ ê¸°ë¡
        info = {
            "backbone": args.backbone,
            "seed": args.seed,
            "epochs": args.epochs,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(OUTPUT_DIR / "info.json", 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        mlflow.log_params(info)
        mlflow.log_artifact(str(OUTPUT_DIR))
        logger.success(" ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f" [FATAL] ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        raise
    finally:
        mlflow.end_run()

if __name__ == "__main__":
    main()