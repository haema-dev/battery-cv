# -*- coding: utf-8 -*-
# Version trigger for Azure ML - v6 (Strict Compliance)
import os
import sys
import torch
import argparse
import mlflow
import json
import time
import cv2
import random
import numpy as np
from loguru import logger
from anomalib.models import Fastflow
from torch import optim
from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.loggers import AnomalibMLFlowLogger
from pathlib import Path
from torchvision.transforms.v2 import Compose, Normalize, Resize, ToImage, ToDtype
from lightning.pytorch.callbacks import EarlyStopping
import lightning

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def load_matched_weights(model_path, model):
    """
    [Definitive Fix] ê°€ì¤‘ì¹˜ë¥¼ ì¶”ì¶œí•˜ê³  ë§¤ì¹­ ì „ëµì— ë”°ë¼ ëª¨ë¸ì— ì§ì ‘ ì£¼ì…í•©ë‹ˆë‹¤.
    - ì—”ì§„ì˜ ckpt_path í”¼ë“œë°± ë£¨í”„ë¥¼ ìš°íšŒí•˜ì—¬ í™•ì‹¤í•œ ì£¼ì…ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    logger.info(f"[*] ê°€ì¤‘ì¹˜ ìˆ˜ë™ ì£¼ì… ì‹œì‘: {model_path}")
    raw_ckpt = torch.load(model_path, map_location="cpu")
    
    if isinstance(raw_ckpt, dict):
        state_dict = raw_ckpt.get("state_dict", raw_ckpt.get("model", raw_ckpt))
    else:
        state_dict = raw_ckpt

    model_state = model.state_dict()
    model_keys = set(model_state.keys())
    
    strategies = [
        ("As-is", lambda d: d),
        ("Add 'model.'", lambda d: {f"model.{k}": v for k, v in d.items()}),
        ("Remove 'model.'", lambda d: {k[6:] if k.startswith("model.") else k: v for k, v in d.items()})
    ]
    
    best_matching_dict = state_dict
    max_matches = 0
    best_strategy = "None"
    
    for name, func in strategies:
        try:
            test_dict = func(state_dict)
            matches = len(model_keys.intersection(test_dict.keys()))
            if matches > max_matches:
                max_matches = matches
                best_strategy = name
                best_matching_dict = test_dict
        except Exception: continue

    logger.info(f"[*] ë§¤ì¹­ ì „ëµ: {best_strategy} (ë§¤ì¹­ë¥ : {(max_matches/len(model_keys))*100:.1f}%)")
    
    # ëª¨ë¸ì— ì¡´ì¬í•˜ëŠ” í‚¤ë§Œ í•„í„°ë§
    final_state_dict = {k: v for k, v in best_matching_dict.items() if k in model_keys}
    
    # ì§ì ‘ ì£¼ì… (Strict=Falseë¡œ ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ë˜, ë§¤ì¹­ë¥  ë¡œê·¸ë¡œ ê²€ì¦)
    model.load_state_dict(final_state_dict, strict=False)
    
    # ì£¼ì… ìƒíƒœ ì§„ë‹¨ (ê°€ì¤‘ì¹˜ê°€ ëª¨ë‘ 0ì€ ì•„ë‹Œì§€ í™•ì¸)
    first_key = list(final_state_dict.keys())[0] if final_state_dict else None
    if first_key:
        weight_mean = final_state_dict[first_key].abs().mean().item()
        logger.info(f"[*] ê°€ì¤‘ì¹˜ ì£¼ì… ìƒ˜í”Œ ê²€ì¦ ({first_key}): Mean Abs = {weight_mean:.6f}")
    
    return True

def main():
    # ================== 1. Input/Output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument("--model_path", type=str, default=None, help="Path to pre-trained model checkpoint")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=50) # ì§„ë‹¨ìš© í‘œì¤€ epoch ì„¤ì •
    parser.add_argument("--backbone", type=str, default="resnet18")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--mode", type=str, default="evaluation", choices=["training", "evaluation", "prediction"])
    parser.add_argument("--batch_size", type=int, default=32, help="Batch size for mass inference")

    args = parser.parse_args()
    set_seed(args.seed)
    
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸš€ MODE: {args.mode.upper()} | BACKBONE: {args.backbone}")

    try:
        # ================== 2. Anomalib ë°ì´í„° ë° ëª¨ë¸ êµ¬ì„± ==================== #
        dataset_root = Path(args.data_path)
        
        transform = Compose([
            ToImage(),
            ToDtype(torch.float32, scale=True),
            Resize((256, 256)),
            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # Prediction ëª¨ë“œì—ì„œëŠ” ì •ë‹µ ë¼ë²¨ ì—†ì´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í›‘ìŠµë‹ˆë‹¤.
        if args.mode == "prediction":
            from anomalib.data import PredictDataset
            # validation í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì „ìˆ˜ ê²€ì‚¬ ì‹¤ì‹œ
            predict_dir = dataset_root / "validation"
            datamodule = PredictDataset(path=predict_dir, transform=transform)
            loader = torch.utils.data.DataLoader(datamodule, batch_size=args.batch_size, shuffle=False)
            logger.info(f"ğŸ“ Prediction ëŒ€ìƒ ê²½ë¡œ: {predict_dir}")
        else:
            val_path = dataset_root / "validation"
            abnormal_dirs = [f"validation/{d.name}" for d in val_path.iterdir() if d.is_dir() and d.name != "good"] if val_path.exists() else []
            datamodule = Folder(
                name="battery", root=str(dataset_root),
                normal_dir="train/good", normal_test_dir="validation/good",
                abnormal_dir=abnormal_dirs if abnormal_dirs else None,
                train_batch_size=args.batch_size, eval_batch_size=args.batch_size,
                train_transform=transform, eval_transform=transform,
                task="classification", seed=args.seed
            )

        model = Fastflow(backbone=args.backbone, flow_steps=8)
        model.setup()

        if args.model_path and os.path.exists(args.model_path):
            load_matched_weights(args.model_path, model)

        # [Critical Fix] Stage 2ì—ì„œ ê²€ì¦ëœ ìµœì  ì„ê³„ê°’(-0.2604) ê°•ì œ ì ìš©
        # ëª¨ë¸ ë¡œë“œ í›„ ì„ê³„ê°’ì´ ì´ˆê¸°í™”ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ ì£¼ì…í•©ë‹ˆë‹¤.
        SAVED_THRESHOLD = -0.2604
        if hasattr(model, "image_threshold"):
            if hasattr(model.image_threshold, "value"):
                model.image_threshold.value = torch.tensor(SAVED_THRESHOLD)
            else:
                model.image_threshold = torch.tensor(SAVED_THRESHOLD)
            logger.info(f"[*] ì„ê³„ê°’ ë³µêµ¬ ì™„ë£Œ: {SAVED_THRESHOLD}")

        # ================== 3. ì—”ì§„ ì„¤ì • ë° ì‹¤í–‰ ==================== #
        early_stop = EarlyStopping(monitor="image_AUROC", patience=10, mode="max", verbose=True)
        mlflow_logger = AnomalibMLFlowLogger(experiment_name="Battery_S2_Diagnostics", save_dir=str(OUTPUT_DIR))
        
        engine = Engine(
            max_epochs=args.epochs,
            devices=1,
            accelerator="auto",
            logger=mlflow_logger,
            callbacks=[early_stop] if args.mode == "training" else [],
            default_root_dir=str(OUTPUT_DIR)
        )

        if args.mode == "training":
            logger.info("ğŸ”¥ [ST5] Training ëª¨ë“œ ì‹œì‘")
            engine.fit(model=model, datamodule=datamodule)
        elif args.mode == "evaluation":
            logger.info("ğŸ” [ST5] Evaluation ëª¨ë“œ ì‹œì‘")
            engine.test(model=model, datamodule=datamodule, ckpt_path=None)
        elif args.mode == "prediction":
            logger.info("ğŸ“¡ [ST5] ì „ìˆ˜ê²€ì‚¬ (Prediction) ëª¨ë“œ ë° Heatmap ìƒì„± ì‹œì‘")
            from anomalib.utils.visualization import ImageVisualizer
            # Anomalib 1.1.3 ì‹œê°í™” ë„êµ¬ ì¤€ë¹„
            visualizer = ImageVisualizer(mode="full", task="classification")
            
            predictions = engine.predict(model=model, dataloaders=loader)
            
            # ê²°ê³¼ ìˆ˜ì§‘ ë° CSV ì €ì¥ (Stage 6 ë¦¬í¬íŒ…ìš©)
            import pandas as pd
            records = []
            
            # íˆíŠ¸ë§µ ì €ì¥ í´ë” ìƒì„±
            vis_dir = OUTPUT_DIR / "visualizations"
            vis_dir.mkdir(parents=True, exist_ok=True)
            
            for batch in predictions:
                # Anomalib 1.1.3 Predict ê²°ê³¼ êµ¬ì¡°ì— ë§ì¶° ë°ì´í„° ì¶”ì¶œ
                paths = batch["image_path"]
                images = batch["image"]
                anomaly_maps = batch["anomaly_maps"]
                scores = batch["pred_scores"].cpu().numpy()
                labels = batch["pred_labels"].cpu().numpy()
                
                for i in range(len(paths)):
                    path = paths[i]
                    score = float(scores[i])
                    label = bool(labels[i])
                    
                    # íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„± (RGB numpy array ë°˜í™˜)
                    res_image = visualizer.visualize(
                        image=images[i],
                        anomaly_map=anomaly_maps[i],
                        score=score,
                        label=label
                    )
                    
                    # íŒŒì¼ ì €ì¥ ë¡œì§ (BGR ë³€í™˜ í›„ OpenCV ì‚¬ìš©)
                    file_name = Path(path).name
                    save_path = vis_dir / f"vis_{file_name}"
                    cv2.imwrite(str(save_path), cv2.cvtColor(res_image, cv2.COLOR_RGB2BGR))
                    
                    records.append({
                        "file_path": path,
                        "file_name": file_name,
                        "parent_dir": Path(path).parent.name,
                        "anomaly_score": score,
                        "is_defect": label,
                        "vis_path": str(save_path)
                    })
            
            df = pd.DataFrame(records)
            csv_path = OUTPUT_DIR / "results.csv"
            df.to_csv(csv_path, index=False)
            logger.success(f"ğŸ“Š ì „ìˆ˜ê²€ì‚¬ ë° íˆíŠ¸ë§µ ì €ì¥ ì™„ë£Œ: {vis_dir} ({len(df)} images)")
            logger.success(f"ğŸ“Š CSV ì™„ë£Œ: {csv_path}")
        
        # ìµœì¢… ê°€ì¤‘ì¹˜ ì €ì¥ ë° ê²°ê³¼ ë³´ê³ 
        torch.save(model.state_dict(), OUTPUT_DIR / "model.pt")
        logger.success(f"[FINISH] Output saved at: {OUTPUT_DIR}")
        logger.success(f"[FINISH] ì‘ì—… ì™„ë£Œ. Stage 5 ì „ìˆ˜ê²€ì‚¬ ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ.")

    except Exception as e:
        logger.error(f"[FATAL] ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        raise

if __name__ == "__main__":
    main()
