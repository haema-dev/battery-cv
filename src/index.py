import argparse
import os
import sys
import inspect
import json
import time
import mlflow
from pathlib import Path
import torch
from loguru import logger
import lightning.pytorch.trainer.trainer as trainer_module

# v3.8: "The Hybrid Grandmaster Surgeon"
# 1. ì‚¬ìš©ìë‹˜ì´ ì§€ì •í•˜ì‹  ê²½ë¡œ(datasets/256x256 fit/train/good) ì •ë°€ ì¡°ì¤€
# 2. Anomalib 1.1.3ì˜ ëª¨ë“  íƒ€ì… ì—ëŸ¬(TypeError)ì™€ ë©”íŠ¸ë¦­ ì—ëŸ¬(gt_mask) ë°•ë©¸
# 3. MLflow ë¡œê¹… ë° ìº¡ì²˜ëœ êµ¬ì¡° íƒìƒ‰ í†µí•©

# [ìˆ˜ìˆ  1] Master Surgeon Patch: Trainer ì¸ì ìœ ì¶œ ë°©ì–´
original_trainer_init = trainer_module.Trainer.__init__
TRAINER_ALLOWED_PARAMS = set(inspect.signature(original_trainer_init).parameters.keys())

def patched_trainer_init(self, *args, **kwargs):
    # Trainerê°€ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ëª¨ë“  ì¸ì(task, pixel_metrics ë“±)ë¥¼ ê±¸ëŸ¬ëƒ…ë‹ˆë‹¤.
    filtered_kwargs = {k: v for k, v in kwargs.items() if k in TRAINER_ALLOWED_PARAMS}
    return original_trainer_init(self, *args, **filtered_kwargs)

trainer_module.Trainer.__init__ = patched_trainer_init

from anomalib.data import Folder
from anomalib.models import Fastflow
from anomalib.engine import Engine

def find_dataset_root(base_path):
    """ì‚¬ìš©ìë‹˜ì´ ê°•ì¡°í•˜ì‹  'datasets/256x256 fit/train/good' ê²½ë¡œë¥¼ ì •ë°€ íƒìƒ‰í•©ë‹ˆë‹¤."""
    base = Path(base_path)
    logger.info(f"ğŸ” ë°ì´í„° íƒìƒ‰ ì¤‘: {base}")
    
    # 1ìˆœìœ„: ì§€ì •í•˜ì‹  '256x256 fit' ê²½ë¡œë¥¼ rglobìœ¼ë¡œ ì°¾ê¸° (ê³µë°± í¬í•¨ ëŒ€ì‘)
    for p in base.rglob("*/train/good"):
        path_str = str(p)
        if "256x256 fit" in path_str:
            root_candidate = p.parent.parent # '256x256 fit' í´ë”
            logger.success(f"âœ… íƒ€ê²Ÿ ë°ì´í„°ì…‹ ë°œê²¬: {root_candidate}")
            return root_candidate
            
    # 2ìˆœìœ„: ì¼ë°˜ì ì¸ train/goodì´ë¼ë„ ì°¾ê¸°
    for p in base.rglob("train/good"):
        logger.warning(f"âš ï¸ ì •í™•í•œ êµ¬ì¡°ëŠ” ì•„ë‹ˆì§€ë§Œ 'train/good' ë°œê²¬: {p.parent.parent}")
        return p.parent.parent
            
    logger.error("âŒ ì§€ì •ëœ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return base

def run_pipeline(data_path, output_dir, epochs):
    logger.info("==================================================")
    logger.info("ğŸš€ STAGE 1: HYBRID GRANDMASTER V3.8 (FINAL)")
    logger.info("==================================================")
    
    mlflow.start_run()
    
    try:
        # 1. ë°ì´í„° ë£¨íŠ¸ íƒìƒ‰
        optimized_root = find_dataset_root(data_path)
        logger.info(f"ğŸ“‚ ìµœì¢… í•™ìŠµ ë£¨íŠ¸: {optimized_root}")

        # 2. ë°ì´í„° ëª¨ë“ˆ ì„¤ì • (ì •ìƒ ë°ì´í„°ë§Œ í•™ìŠµìš©ìœ¼ë¡œ ì‚¬ìš©)
        datamodule = Folder(
            name="battery",
            root=str(optimized_root),
            normal_dir="train/good",
            test_split_mode="from_dir"
        )

        # 3. ëª¨ë¸ ì„¤ì •
        model = Fastflow(backbone="resnet18", flow_steps=8)

        # 4. ì—”ì§„ ì„¤ì •
        # Surgeon íŒ¨ì¹˜ê°€ ìˆì–´ TypeError ê±±ì • ì—†ì´ í•„ìš”í•œ ì¸ì ì „ë‹¬ ê°€ëŠ¥
        engine = Engine(
            max_epochs=epochs,
            default_root_dir=output_dir,
            devices=1,
            accelerator="auto",
            task="classification",
            pixel_metrics=None
        )

        # [ìˆ˜ìˆ  2] ë©”íŠ¸ë¦­ ê°•ì œ ê³ ì • (Hot-Swap) - gt_mask ì—ëŸ¬ ìµœì¢… ë°©í™”ë²½
        if hasattr(engine, "task"): engine.task = "classification"
        if hasattr(engine, "pixel_metrics"): engine.pixel_metrics = None
        if hasattr(model, "task"): model.task = "classification"

        # 5. ì‹¤í–‰
        logger.info(f"â³ í•™ìŠµ ì‹œì‘ (ëª©í‘œ ì—í¬í¬: {epochs})...")
        engine.fit(model=model, datamodule=datamodule)

        # 6. ì €ì¥
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        model_save_path = output_path / "model.pt"
        torch.save(model.state_dict(), model_save_path)
        
        # MLflow ë¡œê¹…
        mlflow.log_params({"epochs": epochs, "model": "FastFlow", "data": "256x256 fit"})
        logger.success(f"âœ… Stage 1 ì„±ê³µ! ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

    except Exception as e:
        logger.error(f"âŒ ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise e
    finally:
        mlflow.end_run()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=100)
    args = parser.parse_args()
    
    sys.stdout.reconfigure(line_buffering=True)
    run_pipeline(args.data_path, args.output_dir, args.epochs)