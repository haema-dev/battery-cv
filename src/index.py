import argparse
import os
from pathlib import Path
import torch
from anomalib.data import Folder
from anomalib.models import Fastflow
from anomalib.engine import Engine

# TorchInferencer consistency
try:
    from anomalib.deploy import TorchInferencer
    HAS_INFERENCER = True
except ImportError:
    HAS_INFERENCER = False

def find_data_root(base_path):
    """'train/good' í´ë”ê°€ í¬í•¨ëœ ìµœì ì˜ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    base = Path(base_path)
    if (base / "train/good").exists():
        return base
    possible_sub = base / "datasets/resized"
    if (possible_sub / "train/good").exists():
        return possible_sub
    found = list(base.glob("**/train/good"))
    if found:
        return found[0].parent.parent
    return base

def run_pipeline(data_path, output_dir, epochs):
    print("--------------------------------------------------")
    print(f"ğŸš€ [Stage 1] FastFlow Training Pipeline (v2: 100e)")
    print(f"ğŸ“ Raw Data Path: {data_path}")
    
    optimized_root = find_data_root(data_path)
    print(f"ğŸ“ Optimized Root: {optimized_root}")
    print(f"â²ï¸ Target Epochs: {epochs}")
    print(f"ğŸ› ï¸ Inferencer Ready: {HAS_INFERENCER}")
    print("--------------------------------------------------")

    # 1. ë°ì´í„° ëª¨ë“ˆ ì„¤ì • (Anomalib 1.x ì´ˆì •ë°€ ë‹¤ì´ì–´íŠ¸)
    # ëª¨ë“  ë²„ì „ ë¯¼ê° ì¸ì(task, image_size, test_dir ë“±)ë¥¼ ì œê±°í•˜ê³  ìµœì†Œ í•„ìˆ˜ê°’ë§Œ ìœ ì§€
    datamodule = Folder(
        name="battery",
        root=str(optimized_root),
        normal_dir="train/good",
        normal_test_dir="test",
        test_split_mode="from_dir"
    )

    # 2. ëª¨ë¸ ì„¤ì • (FastFlow)
    model = Fastflow(backbone="resnet18", flow_steps=8)

    # 3. ì—”ì§„ ì„¤ì •
    # 'task' ì¸ìê°€ Trainerê¹Œì§€ ë„˜ì–´ê°€ ì—ëŸ¬ë¥¼ ìœ ë°œí•˜ë¯€ë¡œ ê³¼ê°íˆ ì œê±° (ê¸°ë³¸ê°’ í™œìš©)
    engine = Engine(
        max_epochs=epochs,
        default_root_dir=output_dir,
        devices=1,
        accelerator="auto"
    )

    # 4. í•™ìŠµ ì‹œì‘
    print("â³ Starting training...")
    # datamoduleì—ì„œ ë°ì´í„° ì…‹ì„ ê°€ì ¸ì˜¤ë©´ ì—”ì§„ì´ ìë™ìœ¼ë¡œ êµ¬ì¡° íŒŒì•…
    engine.fit(model=model, datamodule=datamodule)
    
    # 5. ê²°ê³¼ë¬¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    model_save_path = output_path / "model.pt"
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… Training completed. Weights saved: {model_save_path}")

    # 6. ì¼ê´€ì„± ê²€ì¦
    if HAS_INFERENCER:
        try:
            print("ğŸ” Verifying model consistency with TorchInferencer...")
            inferencer = TorchInferencer(path=model_save_path, device="cpu")
            print("âœ¨ Success: Model is compatible with TorchInferencer API.")
        except Exception as e:
            print(f"âš ï¸ Note: Inferencer verification failed: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=100)
    args = parser.parse_args()
    run_pipeline(args.data_path, args.output_dir, args.epochs)