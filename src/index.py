
import os
import torch
import argparse
import mlflow
import json
import time
import cv2
from loguru import logger
from anomalib.models import Fastflow
from anomalib.data import Folder
from anomalib.engine import Engine
from pathlib import Path
from torchvision.transforms.v2 import Resize

def main():
    # ================== 1. Input/Output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=50)

    args = parser.parse_args()
    base_path = Path(args.data_path)
    
    logger.info("==================================================")
    logger.info("ğŸš€ S1_FastFlow_Training: [Targeted Path Mode]")
    logger.info(f"ğŸ“ ë§ˆìš´íŠ¸ ë£¨íŠ¸: {base_path}")
    logger.info("==================================================")

    # ğŸ“‚ ë°ì´í„° ê²½ë¡œ íƒìƒ‰ ë¡œì§ (ì‚¬ìš©ìë‹˜ì˜ ìš°ë ¤ë¥¼ ë°˜ì˜í•˜ì—¬ ì •ë°€í™”)
    # ì›ë³¸ ë°ì´í„°ì™€ ì„ì´ì§€ ì•Šë„ë¡ 'good' í´ë”ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
    dataset_root = None
    
    # [1ìˆœìœ„] ìš°ë¦¬ê°€ ì´ì „ì— ì„±ê³µí–ˆë˜ ê²½ë¡œ íŒ¨í„´ (train/good)
    for root, dirs, files in os.walk(base_path):
        root_path = Path(root)
        parent_name = root_path.parent.name.lower()
        current_name = root_path.name.lower()
        
        # 'train' í´ë” ì•„ë˜ì˜ 'good' í´ë”ë¥¼ ì°¾ìœ¼ë©´ 256 ë¦¬ì‚¬ì´ì¦ˆ í´ë”ì¼ í™•ë¥ ì´ ë§¤ìš° ë†’ìŒ
        if current_name == "good" and parent_name == "train":
            img_count = len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            if img_count > 0:
                dataset_root = root_path
                logger.info(f"ğŸ¯ [Targeted] ìµœì ì˜ í•™ìŠµ ê²½ë¡œ ë°œê²¬: {dataset_root} ({img_count}ì¥)")
                break

    # [2ìˆœìœ„] 'good'ì´ë¼ëŠ” ì´ë¦„ì´ í¬í•¨ëœ ëª¨ë“  í´ë” ì¤‘ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê³³
    if not dataset_root:
        for root, dirs, files in os.walk(base_path):
            if "good" in root.lower():
                img_count = len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
                if img_count > 0:
                    dataset_root = Path(root)
                    logger.info(f"ğŸ¯ [Fallback] 'good' í‚¤ì›Œë“œ í´ë” ë°œê²¬: {dataset_root} ({img_count}ì¥)")
                    break

    if not dataset_root:
        # ë””ë²„ê¹…ì„ ìœ„í•´ í˜„ì¬ êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ì¶œë ¥
        logger.error("âŒ 'good' í˜¹ì€ 'train/good' êµ¬ì¡°ì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.info(f"í˜„ì¬ ë£¨íŠ¸({base_path})ì˜ ì§ê³„ ìì‹ë“¤: {os.listdir(base_path)}")
        raise FileNotFoundError(f"âŒ '{base_path}' ë‚´ë¶€ì— í•™ìŠµìš© (Good) ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ================== 2. MLflow & Output ì„¤ì • ==================== #
    mlflow.start_run()
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"ğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device}")

    try:
        # ================== 3. Anomalib ë°ì´í„° êµ¬ì„± ==================== #
        logger.info(f"ğŸ“¥ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘: {dataset_root}")
        
        # Anomalibì€ normal_dirì„ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ, rootë¥¼ ì§€ì •í•˜ê³  ë‚´ë¶€ë¥¼ "."ìœ¼ë¡œ ì„¤ì •
        datamodule = Folder(
            name="battery_resized",
            root=str(dataset_root),
            normal_dir=".", 
            train_batch_size=32,
            eval_batch_size=8,
            num_workers=4,
            augmentations=Resize((256, 256)),
        )

        model = Fastflow(backbone="resnet18", flow_steps=8, evaluator=False)
        engine = Engine(max_epochs=args.epochs, accelerator="auto", devices=1, default_root_dir=str(OUTPUT_DIR))

        # ================== 4. ëª¨ë¸ í•™ìŠµ ==================== #
        logger.info(f"ğŸ§¬ S1 ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Target Epochs: {args.epochs})...")
        engine.fit(model=model, datamodule=datamodule)
        logger.success(f"âœ… {args.epochs} ì—í­ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ëë‚¬ìŠµë‹ˆë‹¤!")

        # ================== 5. ê²°ê³¼ ì €ì¥ ==================== #
        torch.save(model.state_dict(), OUTPUT_DIR / "model.pt")
        info = {
            "dataset_path": str(dataset_root),
            "epochs": args.epochs,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(OUTPUT_DIR / "info.json", 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        mlflow.log_params(info)
        mlflow.log_artifact(str(OUTPUT_DIR))
        logger.success("ğŸ‰ ëª¨ë“  ì‚°ì¶œë¬¼ì´ Azure MLì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        mlflow.end_run()

if __name__ == "__main__":
    main()