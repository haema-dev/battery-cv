
import os
import torch
import argparse
import mlflow
import json
import time
from loguru import logger
from anomalib.models import Fastflow
from anomalib.data import Folder
from anomalib.engine import Engine
from pathlib import Path
from torchvision.transforms.v2 import Resize

def main():
    # ================== 1. Input/Output ì„¤ì • ==================== #
    parser = argparse.ArgumentParser()    
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument("--epochs", type=int, default=1)

    args = parser.parse_args()
    
    # ì—ì € ìŠ¤í† ë¦¬ì§€ ì—°ë™ ê²½ë¡œ (ì–‘ì„± ë°ì´í„°ì…‹ ì§‘ì¤‘)
    base_path = Path(args.data_path).resolve()
    dataset_root = base_path / "datasets" / "resized" / "train" / "good"

    logger.info("==================================================")
    logger.info("ğŸš€ S1_FastFlow_Training: [Training Only Mode]")
    logger.info(f"ğŸ“ í•™ìŠµ ë°ì´í„° ê²½ë¡œ: {dataset_root}")
    logger.info("==================================================")

    if not dataset_root.exists():
        logger.warning(f"âš ï¸ {dataset_root} ê²½ë¡œê°€ ì§ì ‘ì ìœ¼ë¡œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        potential = list(base_path.rglob("resized/train/good")) 
        if potential:
            dataset_root = potential[0]
            logger.info(f"âœ… ì‹¤ì œ ê²½ë¡œ ë°œê²¬: {dataset_root}")
        else:
            raise FileNotFoundError(f"âŒ '{base_path}' ë‚´ë¶€ì— 'resized/train/good' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ================== 2. MLflow & Output ì„¤ì • ==================== #
    mlflow.start_run()
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"ğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device}")

    try:
        # ================== 3. Anomalib ë°ì´í„° êµ¬ì„± ==================== #
        logger.info("ğŸ“¥ Anomalib ë°ì´í„° ëª¨ë“ˆ êµ¬ì„± ì¤‘...")
        
        # ì´ë¯¸ ì „ì²˜ë¦¬/ë¦¬ì‚¬ì´ì¦ˆëœ ë°ì´í„°ì´ë¯€ë¡œ ìµœì†Œí•œì˜ transform ì ìš©
        transform = Resize((256, 256))
        
        datamodule = Folder(
            name="battery_resized",
            root=str(dataset_root),
            normal_dir=".",
            train_batch_size=32,
            eval_batch_size=8,
            num_workers=4,
            augmentations=transform,
        )

        # ëª¨ë¸ ì´ˆê¸°í™” (FastFlow)
        model = Fastflow(
            backbone="resnet18",
            flow_steps=8,
            evaluator=False 
        )

        # Engine ì„¤ì •
        engine = Engine(
            max_epochs=args.epochs,
            accelerator="auto",
            devices=1,
            default_root_dir=str(OUTPUT_DIR),
            enable_checkpointing=True,
        )

        # ================== 4. ëª¨ë¸ í•™ìŠµ ==================== #
        logger.info(f"ğŸ§¬ ëª¨ë¸ í•™ìŠµ ì§„í–‰ (Epochs: {args.epochs})...")
        engine.fit(model=model, datamodule=datamodule)
        logger.success("âœ… í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")

        # ================== 5. ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ==================== #
        # ì´ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ë˜ì–´ì•¼ ë‚˜ì¤‘ì— ë³„ë„ì˜ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì¶”ë¡ (íˆíŠ¸ë§µ ìƒì„±)ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        model_save_path = OUTPUT_DIR / "model.pt"
        torch.save(model.state_dict(), model_save_path)
        logger.info(f"ğŸ’¾ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {model_save_path}")

        # ì‘ì—… ì •ë³´ ê¸°ë¡
        info = {
            "experiment": "Battery_S1_AnomalyDetection",
            "mode": "training_only",
            "model": "FastFlow",
            "backbone": "resnet18",
            "dataset_path": str(dataset_root),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(OUTPUT_DIR / "info.json", 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        mlflow.log_params(info)
        mlflow.log_artifact(str(OUTPUT_DIR))
        logger.success("ğŸ‰ Azure ML ê²°ê³¼ ì €ì¥ ë° ì‹¤í—˜ ì¢…ë£Œ!")

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        mlflow.end_run()

if __name__ == "__main__":
    main()