
import os
# Trigger: Phase 2 Heatmap Generation Run
import torch
import argparse
import mlflow
import json
import time
import cv2
import numpy as np
from loguru import logger
from anomalib.models import Fastflow
from pathlib import Path
from torchvision.transforms.v2 import Resize
from PIL import Image

def get_heatmap(anomaly_map):
    """ì§€ë„ë¥¼ ì»¬ëŸ¬ë§µ(Jet)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    # ì •ê·œí™” (0~1)
    anomaly_map = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min() + 1e-8)
    # 0~255 ë³€í™˜
    anomaly_map = (anomaly_map * 255).astype(np.uint8)
    # Jet ì»¬ëŸ¬ë§µ ì ìš©
    heatmap = cv2.applyColorMap(anomaly_map, cv2.COLORMAP_JET)
    return heatmap

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True, help="Path to mounted data asset")
    parser.add_argument("--model_path", type=str, required=True, help="Path to trained model.pt")
    parser.add_argument("--output_dir", type=str, default="./inference_outputs")
    
    args = parser.parse_args()
    base_path = Path(args.data_path)
    model_path = Path(args.model_path)
    output_base = Path(args.output_dir)
    
    logger.info("==================================================")
    logger.info("ğŸ¨ Phase 2: Heatmap Generation (Hyper-Robust Inference)")
    logger.info(f"ğŸ“ ë§ˆìš´íŠ¸ ë£¨íŠ¸: {base_path}")
    logger.info(f"âš–ï¸ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    logger.info("==================================================")

    # 1. ëª¨ë¸ ë¡œë“œ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"ğŸ–¥ï¸ ì‚¬ìš© ì¥ì¹˜: {device}")
    
    model = Fastflow(backbone="resnet18", flow_steps=8)
    try:
        # Azure MLì—ì„œ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œë˜ê±°ë‚˜ ë§ˆìš´íŠ¸ëœ ê²½ë¡œì—ì„œ ë¡œë“œ
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()
        logger.success("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    # 2. í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ íƒìƒ‰ (4ëŒ€ ì¹´í…Œê³ ë¦¬ ê¸°ì )
    # ëª©í‘œ: 'test' í´ë” ì•„ë˜ì˜ {damaged&pollution, damaged, good, pollution} ì°¾ê¸°
    test_root = None
    
    # [ìš°ì„ ìˆœìœ„ 1] ëª…ì‹œì  êµ¬ì¡° (datasets/resized/test)
    explicit_test = base_path / "datasets" / "resized" / "test"
    if explicit_test.exists():
        test_root = explicit_test
        logger.info(f"âœ… [P1] ëª…ì‹œì  í…ŒìŠ¤íŠ¸ ê²½ë¡œ ë°œê²¬: {test_root}")

    # [ìš°ì„ ìˆœìœ„ 2] ì´ë¦„ì´ 'test'ì¸ í´ë” íƒìƒ‰
    if not test_root:
        for root, dirs, files in os.walk(base_path):
            if Path(root).name.lower() == "test":
                test_root = Path(root)
                logger.info(f"ğŸ¯ [P2] íƒìƒ‰ìœ¼ë¡œ 'test' í´ë” ë°œê²¬: {test_root}")
                break

    if not test_root:
        # [ìš°ë¶„ìˆœìœ„ 3] ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¤‘ í•˜ë‚˜ë¼ë„ ë“¤ì–´ìˆëŠ” í´ë” ì°¾ê¸°
        target_cats = ["damaged", "pollution", "good"]
        for root, dirs, files in os.walk(base_path):
            if any(cat in Path(root).name.lower() for cat in target_cats):
                test_root = Path(root).parent
                logger.info(f"ğŸ¯ [P3] ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ë¶€ëª¨ í´ë” ë°œê²¬: {test_root}")
                break

    if not test_root:
        raise FileNotFoundError(f"âŒ '{base_path}' ë‚´ë¶€ì—ì„œ 'test' í´ë” êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    categories = [d for d in os.listdir(test_root) if os.path.isdir(test_root / d)]
    logger.info(f"ğŸ“‚ ê°ì§€ëœ ì¹´í…Œê³ ë¦¬: {categories}")

    transform = Resize((256, 256))

    # 3. ì¸í¼ëŸ°ìŠ¤ ë° íˆíŠ¸ë§µ ìƒì„±
    with torch.no_grad():
        for cat in categories:
            cat_path = test_root / cat
            save_path = output_base / cat
            save_path.mkdir(parents=True, exist_ok=True)
            
            img_files = [f for f in os.listdir(cat_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            if not img_files: continue
            
            logger.info(f"ğŸ–¼ï¸ [{cat}] ì´ë¯¸ì§€ {len(img_files)}ì¥ íˆíŠ¸ë§µ ìƒì„± ì¤‘...")
            
            for f in img_files:
                img_path = cat_path / f
                # ì´ë¯¸ì§€ ë¡œë“œ (RGB)
                input_img = Image.open(img_path).convert("RGB")
                input_tensor = transform(input_img)
                # í…ì„œ ë³€í™˜ ë° ì •ê·œí™”
                input_tensor = (torch.from_numpy(np.array(input_tensor)).permute(2, 0, 1).float() / 255.0).unsqueeze(0).to(device)
                
                # ëª¨ë¸ ì¶”ë¡ 
                output = model(input_tensor)
                anomaly_map = output[0].cpu().numpy().squeeze()
                
                # íˆíŠ¸ë§µ ìƒì„± (ColorMap)
                heatmap = get_heatmap(anomaly_map)
                
                # ì›ë³¸ ì‹œê°í™”ìš© ë³€í™˜ (OpenCV BGR í¬ë§·)
                orig_img_cv = cv2.cvtColor(np.array(input_img.resize((256, 256))), cv2.COLOR_RGB2BGR)
                
                # í•©ì„± (ì˜¤ë²„ë ˆì´)
                overlay = cv2.addWeighted(orig_img_cv, 0.6, heatmap, 0.4, 0)
                
                # ì €ì¥
                cv2.imwrite(str(save_path / f"heatmap_{f}"), overlay)

    logger.success(f"ğŸ‰ ëª¨ë“  íˆíŠ¸ë§µì´ '{output_base}' í´ë”ì— ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
