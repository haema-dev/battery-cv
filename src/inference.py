import os
import argparse
from pathlib import Path
import torch
import cv2
import numpy as np

# Anomalib ê³µì‹ ë¬¸ì„œ ì¶”ì²œ: ì¶”ë¡  ì „ìš©ìœ¼ë¡œ ì„¤ê³„ëœ TorchInferencer ì‚¬ìš©
# Reference: https://anomalib.readthedocs.io/en/latest/guides/inference.html
try:
    from anomalib.deploy import TorchInferencer
    INFERENCER_AVAILABLE = True
except ImportError:
    # v1.x ì¼ë¶€ ë²„ì „ ë˜ëŠ” í™˜ê²½ì— ë”°ë¼ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ ëŒ€ë¹„
    INFERENCER_AVAILABLE = False

def run_inference(data_path, model_path, output_dir):
    """
    Anomalib TorchInferencerë¥¼ ì‚¬ìš©í•œ ê³ ìˆ˜ì¤€ ì¶”ë¡  ë¡œì§.
    ì„ì˜ì˜ ë¡œì§ ëŒ€ì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê³µ ê¸°ëŠ¥ì„ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print("--------------------------------------------------")
    print(f"ğŸš€ [Phase 2] Heatmap Generation Starting")
    print(f"ğŸ“¦ Model: {model_path}")
    print(f"ğŸ“‚ Data: {data_path}")
    print("--------------------------------------------------")

    if not INFERENCER_AVAILABLE:
        print("âŒ Error: 'anomalib.deploy.TorchInferencer'ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 1. Inferencer ì´ˆê¸°í™” (CPU/GPU ìë™ ê°ì§€)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ Using device: {device}")
    
    # .pt íŒŒì¼ì„ ì§ì ‘ ë¡œë“œí•˜ì—¬ ì¶”ë¡  ì¤€ë¹„ (ë‚´ë¶€ì ìœ¼ë¡œ Pre-processing ì„¤ì • í¬í•¨í•¨)
    inferencer = TorchInferencer(
        path=model_path,
        device=device
    )

    data_base = Path(data_path)
    output_base = Path(output_dir)
    
    # 4ëŒ€ ì¹´í…Œê³ ë¦¬ (damaged, good, pollution, damaged&pollution)
    # ë°ì´í„°ì…‹ êµ¬ì¡°: data_path/test/[category]/*.jpg
    test_root = data_base / "test"
    if not test_root.exists():
        # ëŒ€ì²´ ê²½ë¡œ íƒìƒ‰ (resized í´ë” ë“±ì´ í¬í•¨ëœ ê²½ìš°)
        possible_paths = list(data_base.glob("**/test"))
        if possible_paths:
            test_root = possible_paths[0]
        else:
            print(f"âŒ Error: 'test' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Base: {data_path})")
            return

    print(f"ğŸ¯ Found test root: {test_root}")
    
    categories = [d for d in test_root.iterdir() if d.is_dir()]
    
    for cat_dir in categories:
        cat_name = cat_dir.name
        print(f"ğŸ” Processing: {cat_name}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥ í´ë” ìƒì„±
        cat_output = output_base / cat_name
        cat_output.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìŠ¤ìº”
        img_files = list(cat_dir.glob("*.jpg")) + list(cat_dir.glob("*.png")) + list(cat_dir.glob("*.jpeg"))
        
        for img_path in img_files:
            # 2. Prediction ìˆ˜í–‰ (Anomalib í‘œì¤€ API)
            # predict()ëŠ” PredictionResults ê°ì²´ë¥¼ ë°˜í™˜í•˜ë©°, 
            # ì—¬ê¸°ì—ëŠ” ì‹œê°í™”ëœ heatmapImageê°€ í¬í•¨ë©ë‹ˆë‹¤.
            results = inferencer.predict(image=str(img_path))
            
            # 3. íˆíŠ¸ë§µ ì‹œê°í™” ë°ì´í„° ì¶”ì¶œ
            # predictions.heatmapì€ ì˜¤ë²„ë ˆì´ëœ BGR ì´ë¯¸ì§€(numpy)ì…ë‹ˆë‹¤.
            heatmap_img = results.heatmap
            
            # 4. ì €ì¥
            save_name = f"heatmap_{img_path.name}"
            save_path = cat_output / save_name
            cv2.imwrite(str(save_path), heatmap_img)
            
    print(f"\nâœ… All heatmaps generated successfully!")
    print(f"ğŸ“ Location: {output_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_path", type=str, required=True, help="Input data folder")
    parser.add_argument("--model_path", type=str, required=True, help="Trained model (.pt) file")
    parser.add_argument("--output_dir", type=str, required=True, help="Inference results folder")
    
    args = parser.parse_args()
    run_inference(args.data_path, args.model_path, args.output_dir)